schema {
  query: query_root
  mutation: mutation_root
  subscription: subscription_root
}

"""whether this query should be cached (Hasura Cloud only)"""
directive @cached(
  """refresh the cache entry"""
  refresh: Boolean! = false

  """measured in seconds"""
  ttl: Int! = 60
) on QUERY

type Aggregate {
  count: Int!
}

"""Asset system model"""
type Asset implements Entity & Node {
  """The time the document was created"""
  createdAt(
    """
    Variation of DateTime field to return, allows value from base document, current localization, or combined by returning the newer value of both
    """
    variation: SystemDateTimeFieldVariation! = COMBINED
  ): DateTime!

  """User that created this document"""
  createdBy(
    """
    Sets the locale of the resolved parent document as the only locale in the query's subtree.
    
    Note that `createdBy` is a model without localized fields and will not be affected directly by this argument, however the locale will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `createdBy` is a model without localized fields and will not be affected directly by this argument, however the locales will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
  ): User

  """Get the document in other stages"""
  documentInStages(
    """Decides if the current stage should be included or not"""
    includeCurrent: Boolean! = false

    """
    Decides if the documents should match the parent documents locale or should use the fallback order defined in the tree
    """
    inheritLocale: Boolean! = false

    """Potential stages that should be returned"""
    stages: [Stage!]! = [DRAFT, PUBLISHED]
  ): [Asset!]!

  """The file name"""
  fileName: String!

  """The file handle"""
  handle: String!

  """The height of the file"""
  height: Float
  heroImageEvent(
    after: String
    before: String
    first: Int

    """
    Sets the locale of the parent document as the first locale in the fallback locales in the query's subtree.
    
    Note that `heroImageEvent` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, localized entries that do not have the provided locale defined will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean
    last: Int

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `heroImageEvent` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, localized entries that do not have the provided locale defined will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
    orderBy: EventOrderByInput
    skip: Int
    where: EventWhereInput
  ): [Event!]!
  heroImageOrganizer(
    after: String
    before: String
    first: Int

    """
    Sets the locale of the parent document as the first locale in the fallback locales in the query's subtree.
    
    Note that `heroImageOrganizer` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, localized entries that do not have the provided locale defined will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean
    last: Int

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `heroImageOrganizer` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, localized entries that do not have the provided locale defined will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
    orderBy: OrganizerOrderByInput
    skip: Int
    where: OrganizerWhereInput
  ): [Organizer!]!

  """List of Asset versions"""
  history(
    limit: Int! = 10
    skip: Int! = 0

    """
    This is optional and can be used to fetch the document version history for a specific stage instead of the current one
    """
    stageOverride: Stage
  ): [Version!]!

  """The unique identifier"""
  id: ID!
  imageOrganizer(
    after: String
    before: String
    first: Int

    """
    Sets the locale of the parent document as the first locale in the fallback locales in the query's subtree.
    
    Note that `imageOrganizer` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, localized entries that do not have the provided locale defined will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean
    last: Int

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `imageOrganizer` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, localized entries that do not have the provided locale defined will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
    orderBy: OrganizerOrderByInput
    skip: Int
    where: OrganizerWhereInput
  ): [Organizer!]!

  """System Locale field"""
  locale: Locale!

  """Get the other localizations for this document"""
  localizations(
    """Decides if the current locale should be included or not"""
    includeCurrent: Boolean! = false

    """
    Potential locales that should be returned. 
    
    The order of locales will also override locale fall-backing behaviour in the query's subtree.
    
    Note any related model with localized fields in the query's subtree will be affected.
    The first locale matching the provided list will be returned, localized entries that do not have the provided locale defined will be filtered out.
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    
    Consider using this in conjunction with forceParentLocale on the children relation fields.
    """
    locales: [Locale!]! = [en, fr]
  ): [Asset!]!

  """The mime type of the file"""
  mimeType: String
  nftImageEventPass(
    after: String
    before: String
    first: Int

    """
    Sets the locale of the parent document as the first locale in the fallback locales in the query's subtree.
    
    Note that `nftImageEventPass` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, localized entries that do not have the provided locale defined will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean
    last: Int

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `nftImageEventPass` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, localized entries that do not have the provided locale defined will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
    orderBy: EventPassOrderByInput
    skip: Int
    where: EventPassWhereInput
  ): [EventPass!]!
  nftImageEventPassDelayedRevealed(
    after: String
    before: String
    first: Int

    """
    Sets the locale of the parent document as the first locale in the fallback locales in the query's subtree.
    
    Note that `nftImageEventPassDelayedRevealed` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, localized entries that do not have the provided locale defined will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean
    last: Int

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `nftImageEventPassDelayedRevealed` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, localized entries that do not have the provided locale defined will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
    orderBy: EventPassDelayedRevealedOrderByInput
    skip: Int
    where: EventPassDelayedRevealedWhereInput
  ): [EventPassDelayedRevealed!]!

  """The time the document was published. Null on documents in draft stage."""
  publishedAt(
    """
    Variation of DateTime field to return, allows value from base document, current localization, or combined by returning the newer value of both
    """
    variation: SystemDateTimeFieldVariation! = COMBINED
  ): DateTime

  """User that last published this document"""
  publishedBy(
    """
    Sets the locale of the resolved parent document as the only locale in the query's subtree.
    
    Note that `publishedBy` is a model without localized fields and will not be affected directly by this argument, however the locale will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `publishedBy` is a model without localized fields and will not be affected directly by this argument, however the locales will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
  ): User
  scheduledIn(
    after: String
    before: String
    first: Int

    """
    Sets the locale of the resolved parent document as the only locale in the query's subtree.
    
    Note that `scheduledIn` is a model without localized fields and will not be affected directly by this argument, however the locale will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean
    last: Int

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `scheduledIn` is a model without localized fields and will not be affected directly by this argument, however the locales will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
    skip: Int
    where: ScheduledOperationWhereInput
  ): [ScheduledOperation!]!

  """The file size"""
  size: Float

  """System stage field"""
  stage: Stage!

  """The time the document was updated"""
  updatedAt(
    """
    Variation of DateTime field to return, allows value from base document, current localization, or combined by returning the newer value of both
    """
    variation: SystemDateTimeFieldVariation! = COMBINED
  ): DateTime!

  """User that last updated this document"""
  updatedBy(
    """
    Sets the locale of the resolved parent document as the only locale in the query's subtree.
    
    Note that `updatedBy` is a model without localized fields and will not be affected directly by this argument, however the locale will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `updatedBy` is a model without localized fields and will not be affected directly by this argument, however the locales will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
  ): User

  """Get the url for the asset with provided transformations applied."""
  url(transformation: AssetTransformationInput): String!

  """The file width"""
  width: Float
}

"""A connection to a list of items."""
type AssetConnection {
  aggregate: Aggregate!

  """A list of edges."""
  edges: [AssetEdge!]!

  """Information to aid in pagination."""
  pageInfo: PageInfo!
}

input AssetCreateInput {
  createdAt: DateTime
  fileName: String!
  handle: String!
  height: Float
  heroImageEvent: EventCreateManyInlineInput
  heroImageOrganizer: OrganizerCreateManyInlineInput
  imageOrganizer: OrganizerCreateManyInlineInput

  """
  Inline mutations for managing document localizations excluding the default locale
  """
  localizations: AssetCreateLocalizationsInput
  mimeType: String
  nftImageEventPass: EventPassCreateManyInlineInput
  nftImageEventPassDelayedRevealed: EventPassDelayedRevealedCreateManyInlineInput
  size: Float
  updatedAt: DateTime
  width: Float
}

input AssetCreateLocalizationDataInput {
  createdAt: DateTime
  fileName: String!
  handle: String!
  height: Float
  mimeType: String
  size: Float
  updatedAt: DateTime
  width: Float
}

input AssetCreateLocalizationInput {
  """Localization input"""
  data: AssetCreateLocalizationDataInput!
  locale: Locale!
}

input AssetCreateLocalizationsInput {
  """Create localizations for the newly-created document"""
  create: [AssetCreateLocalizationInput!]
}

input AssetCreateOneInlineInput {
  """Connect one existing Asset document"""
  connect: AssetWhereUniqueInput

  """Create and connect one Asset document"""
  create: AssetCreateInput
}

"""An edge in a connection."""
type AssetEdge {
  """A cursor for use in pagination."""
  cursor: String!

  """The item at the end of the edge."""
  node: Asset!
}

"""Identifies documents"""
input AssetManyWhereInput {
  """Logical AND on all given filters."""
  AND: [AssetWhereInput!]

  """Logical NOT on all given filters combined by AND."""
  NOT: [AssetWhereInput!]

  """Logical OR on all given filters."""
  OR: [AssetWhereInput!]

  """Contains search across all appropriate fields."""
  _search: String
  createdAt: DateTime

  """All values greater than the given value."""
  createdAt_gt: DateTime

  """All values greater than or equal the given value."""
  createdAt_gte: DateTime

  """All values that are contained in given list."""
  createdAt_in: [DateTime]

  """All values less than the given value."""
  createdAt_lt: DateTime

  """All values less than or equal the given value."""
  createdAt_lte: DateTime

  """Any other value that exists and is not equal to the given value."""
  createdAt_not: DateTime

  """All values that are not contained in given list."""
  createdAt_not_in: [DateTime]
  createdBy: UserWhereInput
  documentInStages_every: AssetWhereStageInput
  documentInStages_none: AssetWhereStageInput
  documentInStages_some: AssetWhereStageInput
  heroImageEvent_every: EventWhereInput
  heroImageEvent_none: EventWhereInput
  heroImageEvent_some: EventWhereInput
  heroImageOrganizer_every: OrganizerWhereInput
  heroImageOrganizer_none: OrganizerWhereInput
  heroImageOrganizer_some: OrganizerWhereInput
  id: ID

  """All values containing the given string."""
  id_contains: ID

  """All values ending with the given string."""
  id_ends_with: ID

  """All values that are contained in given list."""
  id_in: [ID]

  """Any other value that exists and is not equal to the given value."""
  id_not: ID

  """All values not containing the given string."""
  id_not_contains: ID

  """All values not ending with the given string"""
  id_not_ends_with: ID

  """All values that are not contained in given list."""
  id_not_in: [ID]

  """All values not starting with the given string."""
  id_not_starts_with: ID

  """All values starting with the given string."""
  id_starts_with: ID
  imageOrganizer_every: OrganizerWhereInput
  imageOrganizer_none: OrganizerWhereInput
  imageOrganizer_some: OrganizerWhereInput
  nftImageEventPassDelayedRevealed_every: EventPassDelayedRevealedWhereInput
  nftImageEventPassDelayedRevealed_none: EventPassDelayedRevealedWhereInput
  nftImageEventPassDelayedRevealed_some: EventPassDelayedRevealedWhereInput
  nftImageEventPass_every: EventPassWhereInput
  nftImageEventPass_none: EventPassWhereInput
  nftImageEventPass_some: EventPassWhereInput
  publishedAt: DateTime

  """All values greater than the given value."""
  publishedAt_gt: DateTime

  """All values greater than or equal the given value."""
  publishedAt_gte: DateTime

  """All values that are contained in given list."""
  publishedAt_in: [DateTime]

  """All values less than the given value."""
  publishedAt_lt: DateTime

  """All values less than or equal the given value."""
  publishedAt_lte: DateTime

  """Any other value that exists and is not equal to the given value."""
  publishedAt_not: DateTime

  """All values that are not contained in given list."""
  publishedAt_not_in: [DateTime]
  publishedBy: UserWhereInput
  scheduledIn_every: ScheduledOperationWhereInput
  scheduledIn_none: ScheduledOperationWhereInput
  scheduledIn_some: ScheduledOperationWhereInput
  updatedAt: DateTime

  """All values greater than the given value."""
  updatedAt_gt: DateTime

  """All values greater than or equal the given value."""
  updatedAt_gte: DateTime

  """All values that are contained in given list."""
  updatedAt_in: [DateTime]

  """All values less than the given value."""
  updatedAt_lt: DateTime

  """All values less than or equal the given value."""
  updatedAt_lte: DateTime

  """Any other value that exists and is not equal to the given value."""
  updatedAt_not: DateTime

  """All values that are not contained in given list."""
  updatedAt_not_in: [DateTime]
  updatedBy: UserWhereInput
}

enum AssetOrderByInput {
  createdAt_ASC
  createdAt_DESC
  fileName_ASC
  fileName_DESC
  handle_ASC
  handle_DESC
  height_ASC
  height_DESC
  id_ASC
  id_DESC
  mimeType_ASC
  mimeType_DESC
  publishedAt_ASC
  publishedAt_DESC
  size_ASC
  size_DESC
  updatedAt_ASC
  updatedAt_DESC
  width_ASC
  width_DESC
}

"""Transformations for Assets"""
input AssetTransformationInput {
  document: DocumentTransformationInput
  image: ImageTransformationInput

  """Pass true if you want to validate the passed transformation parameters"""
  validateOptions: Boolean = false
}

input AssetUpdateInput {
  fileName: String
  handle: String
  height: Float
  heroImageEvent: EventUpdateManyInlineInput
  heroImageOrganizer: OrganizerUpdateManyInlineInput
  imageOrganizer: OrganizerUpdateManyInlineInput

  """Manage document localizations"""
  localizations: AssetUpdateLocalizationsInput
  mimeType: String
  nftImageEventPass: EventPassUpdateManyInlineInput
  nftImageEventPassDelayedRevealed: EventPassDelayedRevealedUpdateManyInlineInput
  size: Float
  width: Float
}

input AssetUpdateLocalizationDataInput {
  fileName: String
  handle: String
  height: Float
  mimeType: String
  size: Float
  width: Float
}

input AssetUpdateLocalizationInput {
  data: AssetUpdateLocalizationDataInput!
  locale: Locale!
}

input AssetUpdateLocalizationsInput {
  """Localizations to create"""
  create: [AssetCreateLocalizationInput!]

  """Localizations to delete"""
  delete: [Locale!]

  """Localizations to update"""
  update: [AssetUpdateLocalizationInput!]
  upsert: [AssetUpsertLocalizationInput!]
}

input AssetUpdateManyInput {
  fileName: String
  height: Float

  """Optional updates to localizations"""
  localizations: AssetUpdateManyLocalizationsInput
  mimeType: String
  size: Float
  width: Float
}

input AssetUpdateManyLocalizationDataInput {
  fileName: String
  height: Float
  mimeType: String
  size: Float
  width: Float
}

input AssetUpdateManyLocalizationInput {
  data: AssetUpdateManyLocalizationDataInput!
  locale: Locale!
}

input AssetUpdateManyLocalizationsInput {
  """Localizations to update"""
  update: [AssetUpdateManyLocalizationInput!]
}

input AssetUpdateOneInlineInput {
  """Connect existing Asset document"""
  connect: AssetWhereUniqueInput

  """Create and connect one Asset document"""
  create: AssetCreateInput

  """Delete currently connected Asset document"""
  delete: Boolean

  """Disconnect currently connected Asset document"""
  disconnect: Boolean

  """Update single Asset document"""
  update: AssetUpdateWithNestedWhereUniqueInput

  """Upsert single Asset document"""
  upsert: AssetUpsertWithNestedWhereUniqueInput
}

input AssetUpdateWithNestedWhereUniqueInput {
  """Document to update"""
  data: AssetUpdateInput!

  """Unique document search"""
  where: AssetWhereUniqueInput!
}

input AssetUpsertInput {
  """Create document if it didn't exist"""
  create: AssetCreateInput!

  """Update document if it exists"""
  update: AssetUpdateInput!
}

input AssetUpsertLocalizationInput {
  create: AssetCreateLocalizationDataInput!
  locale: Locale!
  update: AssetUpdateLocalizationDataInput!
}

input AssetUpsertWithNestedWhereUniqueInput {
  """Upsert data"""
  data: AssetUpsertInput!

  """Unique document search"""
  where: AssetWhereUniqueInput!
}

"""
This contains a set of filters that can be used to compare values internally
"""
input AssetWhereComparatorInput {
  """
  This field can be used to request to check if the entry is outdated by internal comparison
  """
  outdated_to: Boolean
}

"""Identifies documents"""
input AssetWhereInput {
  """Logical AND on all given filters."""
  AND: [AssetWhereInput!]

  """Logical NOT on all given filters combined by AND."""
  NOT: [AssetWhereInput!]

  """Logical OR on all given filters."""
  OR: [AssetWhereInput!]

  """Contains search across all appropriate fields."""
  _search: String
  createdAt: DateTime

  """All values greater than the given value."""
  createdAt_gt: DateTime

  """All values greater than or equal the given value."""
  createdAt_gte: DateTime

  """All values that are contained in given list."""
  createdAt_in: [DateTime]

  """All values less than the given value."""
  createdAt_lt: DateTime

  """All values less than or equal the given value."""
  createdAt_lte: DateTime

  """Any other value that exists and is not equal to the given value."""
  createdAt_not: DateTime

  """All values that are not contained in given list."""
  createdAt_not_in: [DateTime]
  createdBy: UserWhereInput
  documentInStages_every: AssetWhereStageInput
  documentInStages_none: AssetWhereStageInput
  documentInStages_some: AssetWhereStageInput
  fileName: String

  """All values containing the given string."""
  fileName_contains: String

  """All values ending with the given string."""
  fileName_ends_with: String

  """All values that are contained in given list."""
  fileName_in: [String]

  """Any other value that exists and is not equal to the given value."""
  fileName_not: String

  """All values not containing the given string."""
  fileName_not_contains: String

  """All values not ending with the given string"""
  fileName_not_ends_with: String

  """All values that are not contained in given list."""
  fileName_not_in: [String]

  """All values not starting with the given string."""
  fileName_not_starts_with: String

  """All values starting with the given string."""
  fileName_starts_with: String
  handle: String

  """All values containing the given string."""
  handle_contains: String

  """All values ending with the given string."""
  handle_ends_with: String

  """All values that are contained in given list."""
  handle_in: [String]

  """Any other value that exists and is not equal to the given value."""
  handle_not: String

  """All values not containing the given string."""
  handle_not_contains: String

  """All values not ending with the given string"""
  handle_not_ends_with: String

  """All values that are not contained in given list."""
  handle_not_in: [String]

  """All values not starting with the given string."""
  handle_not_starts_with: String

  """All values starting with the given string."""
  handle_starts_with: String
  height: Float

  """All values greater than the given value."""
  height_gt: Float

  """All values greater than or equal the given value."""
  height_gte: Float

  """All values that are contained in given list."""
  height_in: [Float]

  """All values less than the given value."""
  height_lt: Float

  """All values less than or equal the given value."""
  height_lte: Float

  """Any other value that exists and is not equal to the given value."""
  height_not: Float

  """All values that are not contained in given list."""
  height_not_in: [Float]
  heroImageEvent_every: EventWhereInput
  heroImageEvent_none: EventWhereInput
  heroImageEvent_some: EventWhereInput
  heroImageOrganizer_every: OrganizerWhereInput
  heroImageOrganizer_none: OrganizerWhereInput
  heroImageOrganizer_some: OrganizerWhereInput
  id: ID

  """All values containing the given string."""
  id_contains: ID

  """All values ending with the given string."""
  id_ends_with: ID

  """All values that are contained in given list."""
  id_in: [ID]

  """Any other value that exists and is not equal to the given value."""
  id_not: ID

  """All values not containing the given string."""
  id_not_contains: ID

  """All values not ending with the given string"""
  id_not_ends_with: ID

  """All values that are not contained in given list."""
  id_not_in: [ID]

  """All values not starting with the given string."""
  id_not_starts_with: ID

  """All values starting with the given string."""
  id_starts_with: ID
  imageOrganizer_every: OrganizerWhereInput
  imageOrganizer_none: OrganizerWhereInput
  imageOrganizer_some: OrganizerWhereInput
  mimeType: String

  """All values containing the given string."""
  mimeType_contains: String

  """All values ending with the given string."""
  mimeType_ends_with: String

  """All values that are contained in given list."""
  mimeType_in: [String]

  """Any other value that exists and is not equal to the given value."""
  mimeType_not: String

  """All values not containing the given string."""
  mimeType_not_contains: String

  """All values not ending with the given string"""
  mimeType_not_ends_with: String

  """All values that are not contained in given list."""
  mimeType_not_in: [String]

  """All values not starting with the given string."""
  mimeType_not_starts_with: String

  """All values starting with the given string."""
  mimeType_starts_with: String
  nftImageEventPassDelayedRevealed_every: EventPassDelayedRevealedWhereInput
  nftImageEventPassDelayedRevealed_none: EventPassDelayedRevealedWhereInput
  nftImageEventPassDelayedRevealed_some: EventPassDelayedRevealedWhereInput
  nftImageEventPass_every: EventPassWhereInput
  nftImageEventPass_none: EventPassWhereInput
  nftImageEventPass_some: EventPassWhereInput
  publishedAt: DateTime

  """All values greater than the given value."""
  publishedAt_gt: DateTime

  """All values greater than or equal the given value."""
  publishedAt_gte: DateTime

  """All values that are contained in given list."""
  publishedAt_in: [DateTime]

  """All values less than the given value."""
  publishedAt_lt: DateTime

  """All values less than or equal the given value."""
  publishedAt_lte: DateTime

  """Any other value that exists and is not equal to the given value."""
  publishedAt_not: DateTime

  """All values that are not contained in given list."""
  publishedAt_not_in: [DateTime]
  publishedBy: UserWhereInput
  scheduledIn_every: ScheduledOperationWhereInput
  scheduledIn_none: ScheduledOperationWhereInput
  scheduledIn_some: ScheduledOperationWhereInput
  size: Float

  """All values greater than the given value."""
  size_gt: Float

  """All values greater than or equal the given value."""
  size_gte: Float

  """All values that are contained in given list."""
  size_in: [Float]

  """All values less than the given value."""
  size_lt: Float

  """All values less than or equal the given value."""
  size_lte: Float

  """Any other value that exists and is not equal to the given value."""
  size_not: Float

  """All values that are not contained in given list."""
  size_not_in: [Float]
  updatedAt: DateTime

  """All values greater than the given value."""
  updatedAt_gt: DateTime

  """All values greater than or equal the given value."""
  updatedAt_gte: DateTime

  """All values that are contained in given list."""
  updatedAt_in: [DateTime]

  """All values less than the given value."""
  updatedAt_lt: DateTime

  """All values less than or equal the given value."""
  updatedAt_lte: DateTime

  """Any other value that exists and is not equal to the given value."""
  updatedAt_not: DateTime

  """All values that are not contained in given list."""
  updatedAt_not_in: [DateTime]
  updatedBy: UserWhereInput
  width: Float

  """All values greater than the given value."""
  width_gt: Float

  """All values greater than or equal the given value."""
  width_gte: Float

  """All values that are contained in given list."""
  width_in: [Float]

  """All values less than the given value."""
  width_lt: Float

  """All values less than or equal the given value."""
  width_lte: Float

  """Any other value that exists and is not equal to the given value."""
  width_not: Float

  """All values that are not contained in given list."""
  width_not_in: [Float]
}

"""
The document in stages filter allows specifying a stage entry to cross compare the same document between different stages
"""
input AssetWhereStageInput {
  """Logical AND on all given filters."""
  AND: [AssetWhereStageInput!]

  """Logical NOT on all given filters combined by AND."""
  NOT: [AssetWhereStageInput!]

  """Logical OR on all given filters."""
  OR: [AssetWhereStageInput!]

  """
  This field contains fields which can be set as true or false to specify an internal comparison
  """
  compareWithParent: AssetWhereComparatorInput

  """Specify the stage to compare with"""
  stage: Stage
}

"""References Asset record uniquely"""
input AssetWhereUniqueInput {
  id: ID
}

type BatchPayload {
  """The number of nodes that have been affected by the Batch operation."""
  count: Long!
}

"""
Boolean expression to compare columns of type "Boolean". All fields are combined with logical 'AND'.
"""
input Boolean_comparison_exp {
  _eq: Boolean
  _gt: Boolean
  _gte: Boolean
  _in: [Boolean!]
  _is_null: Boolean
  _lt: Boolean
  _lte: Boolean
  _neq: Boolean
  _nin: [Boolean!]
}

input ConnectPositionInput {
  """Connect document after specified document"""
  after: ID

  """Connect document before specified document"""
  before: ID

  """Connect document at last position"""
  end: Boolean

  """Connect document at first position"""
  start: Boolean
}

"""
A date-time string at UTC, such as 2007-12-03T10:15:30Z, compliant with the date-timeformat outlined in section 5.6 of the RFC 3339 profile of the ISO 8601 standard for representationof dates and times using the Gregorian calendar.
"""
scalar DateTime

enum DocumentFileTypes {
  doc
  docx
  html
  jpg
  odp
  ods
  odt
  pdf
  png
  ppt
  pptx
  svg
  txt
  webp
  xls
  xlsx
}

input DocumentOutputInput {
  """
  Transforms a document into a desired file type.
  See this matrix for format support:
  
  PDF:	jpg, odp, ods, odt, png, svg, txt, and webp
  DOC:	docx, html, jpg, odt, pdf, png, svg, txt, and webp
  DOCX:	doc, html, jpg, odt, pdf, png, svg, txt, and webp
  ODT:	doc, docx, html, jpg, pdf, png, svg, txt, and webp
  XLS:	jpg, pdf, ods, png, svg, xlsx, and webp
  XLSX:	jpg, pdf, ods, png, svg, xls, and webp
  ODS:	jpg, pdf, png, xls, svg, xlsx, and webp
  PPT:	jpg, odp, pdf, png, svg, pptx, and webp
  PPTX:	jpg, odp, pdf, png, svg, ppt, and webp
  ODP:	jpg, pdf, png, ppt, svg, pptx, and webp
  BMP:	jpg, odp, ods, odt, pdf, png, svg, and webp
  GIF:	jpg, odp, ods, odt, pdf, png, svg, and webp
  JPG:	jpg, odp, ods, odt, pdf, png, svg, and webp
  PNG:	jpg, odp, ods, odt, pdf, png, svg, and webp
  WEBP:	jpg, odp, ods, odt, pdf, png, svg, and webp
  TIFF:	jpg, odp, ods, odt, pdf, png, svg, and webp
  AI:	    jpg, odp, ods, odt, pdf, png, svg, and webp
  PSD:	jpg, odp, ods, odt, pdf, png, svg, and webp
  SVG:	jpg, odp, ods, odt, pdf, png, and webp
  HTML:	jpg, odt, pdf, svg, txt, and webp
  TXT:	jpg, html, odt, pdf, svg, and webp
  """
  format: DocumentFileTypes
}

"""Transformations for Documents"""
input DocumentTransformationInput {
  """Changes the output for the file."""
  output: DocumentOutputInput
}

type DocumentVersion {
  createdAt: DateTime!
  data: Json
  id: ID!
  revision: Int!
  stage: Stage!
}

"""An object with an ID"""
interface Entity {
  """The id of the object."""
  id: ID!

  """The Stage of an object"""
  stage: Stage!
}

"""
This enumeration holds all typenames that implement the Entity interface. Components and models implement the Entity interface.
"""
enum EntityTypeName {
  """Asset system model"""
  Asset

  """Root event model"""
  Event

  """
  Model used to define the different locations and dates of an event. A festival or a tournament for instance could have several.
  """
  EventDateLocation

  """
  Define a pass for an event with different options, price, number of passes etc.
  """
  EventPass

  """
  The EventPassDelayedReveal is a feature in our ticketing system that introduces a timed reveal of certain event pass details. It's designed for special events where additional information about the pass, such as its name, description, and image, is unveiled at a later stage, adding an element of anticipation and exclusivity for attendees. This feature is particularly useful for creating a unique and engaging experience for high-profile events.
  """
  EventPassDelayedRevealed

  """
  A model for location data (point on a map) + additional info such as street, venue etc.
  """
  LocationAddress

  """
  An organizer is an entity that launch events and handle the pass benefits.
  """
  Organizer

  """
  Define the options of an 'Event Pass' on an 'Event Date Location'. You can define severals if the event have multiple locations.
  """
  PassOption

  """Scheduled Operation system model"""
  ScheduledOperation

  """Scheduled Release system model"""
  ScheduledRelease

  """User system model"""
  User
}

"""Allows to specify input to query models and components directly"""
input EntityWhereInput {
  """The ID of an object"""
  id: ID!
  stage: Stage!

  """The Type name of an object"""
  typename: EntityTypeName!
}

"""Root event model"""
type Event implements Entity & Node {
  """The time the document was created"""
  createdAt(
    """
    Variation of DateTime field to return, allows value from base document, current localization, or combined by returning the newer value of both
    """
    variation: SystemDateTimeFieldVariation! = COMBINED
  ): DateTime!

  """User that created this document"""
  createdBy(
    """
    Sets the locale of the resolved parent document as the only locale in the query's subtree.
    
    Note that `createdBy` is a model without localized fields and will not be affected directly by this argument, however the locale will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `createdBy` is a model without localized fields and will not be affected directly by this argument, however the locales will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
  ): User
  description: EventDescriptionRichText!

  """Get the document in other stages"""
  documentInStages(
    """Decides if the current stage should be included or not"""
    includeCurrent: Boolean! = false

    """
    Decides if the documents should match the parent documents locale or should use the fallback order defined in the tree
    """
    inheritLocale: Boolean! = false

    """Potential stages that should be returned"""
    stages: [Stage!]! = [DRAFT, PUBLISHED]
  ): [Event!]!

  """
  Define the different locations and timeframe for your event.
  This is only for information purpose but it should match your 'Event Pass' locations and dates
  """
  eventDateLocations(
    after: String
    before: String
    first: Int

    """
    Sets the locale of the resolved parent document as the only locale in the query's subtree.
    
    Note that `eventDateLocations` is a model without localized fields and will not be affected directly by this argument, however the locale will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean
    last: Int

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `eventDateLocations` is a model without localized fields and will not be affected directly by this argument, however the locales will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
    orderBy: EventDateLocationOrderByInput
    skip: Int
    where: EventDateLocationWhereInput
  ): [EventDateLocation!]!
  eventParameters: eventParameters
  eventPasses(
    after: String
    before: String
    first: Int

    """
    Sets the locale of the parent document as the first locale in the fallback locales in the query's subtree.
    
    Note that `eventPasses` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, localized entries that do not have the provided locale defined will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean
    last: Int

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `eventPasses` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, localized entries that do not have the provided locale defined will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
    orderBy: EventPassOrderByInput
    skip: Int
    where: EventPassWhereInput
  ): [EventPass!]!

  """
  An hero image that will displayed on a rectangular format. The image need to be high quality in order to display well on every screen.
  """
  heroImage(
    """
    Sets the locale of the parent document as the first locale in the fallback locales in the query's subtree.
    
    Note that `heroImage` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, localized entries that do not have the provided locale defined will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `heroImage` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, localized entries that do not have the provided locale defined will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
  ): Asset!

  """
  Optional field used to style your hero image with classes. Every classes from tailwind are supported. This is typically useful to adapt your image with light and dark mode (for instance using filter contrast or invert, https://tailwindcss.com/docs/contrast)
  """
  heroImageClasses: String

  """List of Event versions"""
  history(
    limit: Int! = 10
    skip: Int! = 0

    """
    This is optional and can be used to fetch the document version history for a specific stage instead of the current one
    """
    stageOverride: Stage
  ): [Version!]!

  """The unique identifier"""
  id: ID!

  """System Locale field"""
  locale: Locale!

  """Get the other localizations for this document"""
  localizations(
    """Decides if the current locale should be included or not"""
    includeCurrent: Boolean! = false

    """
    Potential locales that should be returned. 
    
    The order of locales will also override locale fall-backing behaviour in the query's subtree.
    
    Note any related model with localized fields in the query's subtree will be affected.
    The first locale matching the provided list will be returned, localized entries that do not have the provided locale defined will be filtered out.
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    
    Consider using this in conjunction with forceParentLocale on the children relation fields.
    """
    locales: [Locale!]! = [en, fr]
  ): [Event!]!
  organizer(
    """
    Sets the locale of the parent document as the first locale in the fallback locales in the query's subtree.
    
    Note that `organizer` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, localized entries that do not have the provided locale defined will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `organizer` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, localized entries that do not have the provided locale defined will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
  ): Organizer

  """
  Whether the event is public (visible to anyone) or private (for instance visible only to owner of specific NFTs)
  """
  public: Boolean

  """Whether the event is published or not (visible only to organizers)"""
  published: Boolean!

  """The time the document was published. Null on documents in draft stage."""
  publishedAt(
    """
    Variation of DateTime field to return, allows value from base document, current localization, or combined by returning the newer value of both
    """
    variation: SystemDateTimeFieldVariation! = COMBINED
  ): DateTime

  """User that last published this document"""
  publishedBy(
    """
    Sets the locale of the resolved parent document as the only locale in the query's subtree.
    
    Note that `publishedBy` is a model without localized fields and will not be affected directly by this argument, however the locale will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `publishedBy` is a model without localized fields and will not be affected directly by this argument, however the locales will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
  ): User
  scheduledIn(
    after: String
    before: String
    first: Int

    """
    Sets the locale of the resolved parent document as the only locale in the query's subtree.
    
    Note that `scheduledIn` is a model without localized fields and will not be affected directly by this argument, however the locale will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean
    last: Int

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `scheduledIn` is a model without localized fields and will not be affected directly by this argument, however the locales will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
    skip: Int
    where: ScheduledOperationWhereInput
  ): [ScheduledOperation!]!

  """Used in the URL"""
  slug: String!

  """System stage field"""
  stage: Stage!
  title: String!

  """The time the document was updated"""
  updatedAt(
    """
    Variation of DateTime field to return, allows value from base document, current localization, or combined by returning the newer value of both
    """
    variation: SystemDateTimeFieldVariation! = COMBINED
  ): DateTime!

  """User that last updated this document"""
  updatedBy(
    """
    Sets the locale of the resolved parent document as the only locale in the query's subtree.
    
    Note that `updatedBy` is a model without localized fields and will not be affected directly by this argument, however the locale will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `updatedBy` is a model without localized fields and will not be affected directly by this argument, however the locales will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
  ): User
}

input EventConnectInput {
  """
  Allow to specify document position in list of connected documents, will default to appending at end of list
  """
  position: ConnectPositionInput

  """Document to connect"""
  where: EventWhereUniqueInput!
}

"""A connection to a list of items."""
type EventConnection {
  aggregate: Aggregate!

  """A list of edges."""
  edges: [EventEdge!]!

  """Information to aid in pagination."""
  pageInfo: PageInfo!
}

input EventCreateInput {
  createdAt: DateTime

  """description input for default locale (en)"""
  description: RichTextAST!
  eventDateLocations: EventDateLocationCreateManyInlineInput
  eventPasses: EventPassCreateManyInlineInput
  heroImage: AssetCreateOneInlineInput!
  heroImageClasses: String

  """
  Inline mutations for managing document localizations excluding the default locale
  """
  localizations: EventCreateLocalizationsInput
  organizer: OrganizerCreateOneInlineInput
  public: Boolean
  published: Boolean!
  slug: String!

  """title input for default locale (en)"""
  title: String!
  updatedAt: DateTime
}

input EventCreateLocalizationDataInput {
  createdAt: DateTime
  description: RichTextAST!
  title: String!
  updatedAt: DateTime
}

input EventCreateLocalizationInput {
  """Localization input"""
  data: EventCreateLocalizationDataInput!
  locale: Locale!
}

input EventCreateLocalizationsInput {
  """Create localizations for the newly-created document"""
  create: [EventCreateLocalizationInput!]
}

input EventCreateManyInlineInput {
  """Connect multiple existing Event documents"""
  connect: [EventWhereUniqueInput!]

  """Create and connect multiple existing Event documents"""
  create: [EventCreateInput!]
}

input EventCreateOneInlineInput {
  """Connect one existing Event document"""
  connect: EventWhereUniqueInput

  """Create and connect one Event document"""
  create: EventCreateInput
}

"""
Model used to define the different locations and dates of an event. A festival or a tournament for instance could have several.
"""
type EventDateLocation implements Entity {
  """The end date including time on the UTC timezone."""
  dateEnd: DateTime!

  """The start date including time on the UTC timezone."""
  dateStart: DateTime!

  """The unique identifier"""
  id: ID!

  """The location expressed in coordinates on a map and address"""
  locationAddress(
    """
    Sets the locale of the resolved parent document as the only locale in the query's subtree.
    
    Note that `locationAddress` is a model without localized fields and will not be affected directly by this argument, however the locale will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `locationAddress` is a model without localized fields and will not be affected directly by this argument, however the locales will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
  ): LocationAddress!

  """System stage field"""
  stage: Stage!
}

input EventDateLocationCreateInput {
  dateEnd: DateTime!
  dateStart: DateTime!
  locationAddress: LocationAddressCreateOneInlineInput!
}

input EventDateLocationCreateManyInlineInput {
  """Create and connect multiple existing EventDateLocation documents"""
  create: [EventDateLocationCreateInput!]
}

input EventDateLocationCreateOneInlineInput {
  """Create and connect one EventDateLocation document"""
  create: EventDateLocationCreateInput
}

input EventDateLocationCreateWithPositionInput {
  """Document to create"""
  data: EventDateLocationCreateInput!

  """
  Position in the list of existing component instances, will default to appending at the end of list
  """
  position: ConnectPositionInput
}

enum EventDateLocationOrderByInput {
  dateEnd_ASC
  dateEnd_DESC
  dateStart_ASC
  dateStart_DESC
  id_ASC
  id_DESC
}

input EventDateLocationUpdateInput {
  dateEnd: DateTime
  dateStart: DateTime
  locationAddress: LocationAddressUpdateOneInlineInput
}

input EventDateLocationUpdateManyInlineInput {
  """Create and connect multiple EventDateLocation component instances"""
  create: [EventDateLocationCreateWithPositionInput!]

  """Delete multiple EventDateLocation documents"""
  delete: [EventDateLocationWhereUniqueInput!]

  """Update multiple EventDateLocation component instances"""
  update: [EventDateLocationUpdateWithNestedWhereUniqueAndPositionInput!]

  """Upsert multiple EventDateLocation component instances"""
  upsert: [EventDateLocationUpsertWithNestedWhereUniqueAndPositionInput!]
}

input EventDateLocationUpdateOneInlineInput {
  """Create and connect one EventDateLocation document"""
  create: EventDateLocationCreateInput

  """Delete currently connected EventDateLocation document"""
  delete: Boolean

  """Update single EventDateLocation document"""
  update: EventDateLocationUpdateWithNestedWhereUniqueInput

  """Upsert single EventDateLocation document"""
  upsert: EventDateLocationUpsertWithNestedWhereUniqueInput
}

input EventDateLocationUpdateWithNestedWhereUniqueAndPositionInput {
  """Document to update"""
  data: EventDateLocationUpdateInput

  """
  Position in the list of existing component instances, will default to appending at the end of list
  """
  position: ConnectPositionInput

  """Unique component instance search"""
  where: EventDateLocationWhereUniqueInput!
}

input EventDateLocationUpdateWithNestedWhereUniqueInput {
  """Document to update"""
  data: EventDateLocationUpdateInput!

  """Unique document search"""
  where: EventDateLocationWhereUniqueInput!
}

input EventDateLocationUpsertInput {
  """Create document if it didn't exist"""
  create: EventDateLocationCreateInput!

  """Update document if it exists"""
  update: EventDateLocationUpdateInput!
}

input EventDateLocationUpsertWithNestedWhereUniqueAndPositionInput {
  """Document to upsert"""
  data: EventDateLocationUpsertInput

  """
  Position in the list of existing component instances, will default to appending at the end of list
  """
  position: ConnectPositionInput

  """Unique component instance search"""
  where: EventDateLocationWhereUniqueInput!
}

input EventDateLocationUpsertWithNestedWhereUniqueInput {
  """Upsert data"""
  data: EventDateLocationUpsertInput!

  """Unique document search"""
  where: EventDateLocationWhereUniqueInput!
}

"""Identifies documents"""
input EventDateLocationWhereInput {
  """Logical AND on all given filters."""
  AND: [EventDateLocationWhereInput!]

  """Logical NOT on all given filters combined by AND."""
  NOT: [EventDateLocationWhereInput!]

  """Logical OR on all given filters."""
  OR: [EventDateLocationWhereInput!]

  """Contains search across all appropriate fields."""
  _search: String
  dateEnd: DateTime

  """All values greater than the given value."""
  dateEnd_gt: DateTime

  """All values greater than or equal the given value."""
  dateEnd_gte: DateTime

  """All values that are contained in given list."""
  dateEnd_in: [DateTime]

  """All values less than the given value."""
  dateEnd_lt: DateTime

  """All values less than or equal the given value."""
  dateEnd_lte: DateTime

  """Any other value that exists and is not equal to the given value."""
  dateEnd_not: DateTime

  """All values that are not contained in given list."""
  dateEnd_not_in: [DateTime]
  dateStart: DateTime

  """All values greater than the given value."""
  dateStart_gt: DateTime

  """All values greater than or equal the given value."""
  dateStart_gte: DateTime

  """All values that are contained in given list."""
  dateStart_in: [DateTime]

  """All values less than the given value."""
  dateStart_lt: DateTime

  """All values less than or equal the given value."""
  dateStart_lte: DateTime

  """Any other value that exists and is not equal to the given value."""
  dateStart_not: DateTime

  """All values that are not contained in given list."""
  dateStart_not_in: [DateTime]
  id: ID

  """All values containing the given string."""
  id_contains: ID

  """All values ending with the given string."""
  id_ends_with: ID

  """All values that are contained in given list."""
  id_in: [ID]

  """Any other value that exists and is not equal to the given value."""
  id_not: ID

  """All values not containing the given string."""
  id_not_contains: ID

  """All values not ending with the given string"""
  id_not_ends_with: ID

  """All values that are not contained in given list."""
  id_not_in: [ID]

  """All values not starting with the given string."""
  id_not_starts_with: ID

  """All values starting with the given string."""
  id_starts_with: ID
  locationAddress: LocationAddressWhereInput
}

"""References EventDateLocation record uniquely"""
input EventDateLocationWhereUniqueInput {
  id: ID
}

type EventDescriptionRichText {
  """Returns HTMl representation"""
  html: String!
  json: RichTextAST!

  """Returns Markdown representation"""
  markdown: String!
  raw: RichTextAST!
  references(after: String, before: String, first: Int, last: Int, skip: Int): [EventDescriptionRichTextEmbeddedTypes!]!

  """Returns plain-text contents of RichText"""
  text: String!
}

union EventDescriptionRichTextEmbeddedTypes = Asset

"""An edge in a connection."""
type EventEdge {
  """A cursor for use in pagination."""
  cursor: String!

  """The item at the end of the edge."""
  node: Event!
}

"""Identifies documents"""
input EventManyWhereInput {
  """Logical AND on all given filters."""
  AND: [EventWhereInput!]

  """Logical NOT on all given filters combined by AND."""
  NOT: [EventWhereInput!]

  """Logical OR on all given filters."""
  OR: [EventWhereInput!]

  """Contains search across all appropriate fields."""
  _search: String
  createdAt: DateTime

  """All values greater than the given value."""
  createdAt_gt: DateTime

  """All values greater than or equal the given value."""
  createdAt_gte: DateTime

  """All values that are contained in given list."""
  createdAt_in: [DateTime]

  """All values less than the given value."""
  createdAt_lt: DateTime

  """All values less than or equal the given value."""
  createdAt_lte: DateTime

  """Any other value that exists and is not equal to the given value."""
  createdAt_not: DateTime

  """All values that are not contained in given list."""
  createdAt_not_in: [DateTime]
  createdBy: UserWhereInput
  documentInStages_every: EventWhereStageInput
  documentInStages_none: EventWhereStageInput
  documentInStages_some: EventWhereStageInput
  eventDateLocations_every: EventDateLocationWhereInput
  eventDateLocations_none: EventDateLocationWhereInput
  eventDateLocations_some: EventDateLocationWhereInput
  eventPasses_every: EventPassWhereInput
  eventPasses_none: EventPassWhereInput
  eventPasses_some: EventPassWhereInput
  heroImage: AssetWhereInput
  heroImageClasses: String

  """All values containing the given string."""
  heroImageClasses_contains: String

  """All values ending with the given string."""
  heroImageClasses_ends_with: String

  """All values that are contained in given list."""
  heroImageClasses_in: [String]

  """Any other value that exists and is not equal to the given value."""
  heroImageClasses_not: String

  """All values not containing the given string."""
  heroImageClasses_not_contains: String

  """All values not ending with the given string"""
  heroImageClasses_not_ends_with: String

  """All values that are not contained in given list."""
  heroImageClasses_not_in: [String]

  """All values not starting with the given string."""
  heroImageClasses_not_starts_with: String

  """All values starting with the given string."""
  heroImageClasses_starts_with: String
  id: ID

  """All values containing the given string."""
  id_contains: ID

  """All values ending with the given string."""
  id_ends_with: ID

  """All values that are contained in given list."""
  id_in: [ID]

  """Any other value that exists and is not equal to the given value."""
  id_not: ID

  """All values not containing the given string."""
  id_not_contains: ID

  """All values not ending with the given string"""
  id_not_ends_with: ID

  """All values that are not contained in given list."""
  id_not_in: [ID]

  """All values not starting with the given string."""
  id_not_starts_with: ID

  """All values starting with the given string."""
  id_starts_with: ID
  organizer: OrganizerWhereInput
  public: Boolean

  """Any other value that exists and is not equal to the given value."""
  public_not: Boolean
  published: Boolean
  publishedAt: DateTime

  """All values greater than the given value."""
  publishedAt_gt: DateTime

  """All values greater than or equal the given value."""
  publishedAt_gte: DateTime

  """All values that are contained in given list."""
  publishedAt_in: [DateTime]

  """All values less than the given value."""
  publishedAt_lt: DateTime

  """All values less than or equal the given value."""
  publishedAt_lte: DateTime

  """Any other value that exists and is not equal to the given value."""
  publishedAt_not: DateTime

  """All values that are not contained in given list."""
  publishedAt_not_in: [DateTime]
  publishedBy: UserWhereInput

  """Any other value that exists and is not equal to the given value."""
  published_not: Boolean
  scheduledIn_every: ScheduledOperationWhereInput
  scheduledIn_none: ScheduledOperationWhereInput
  scheduledIn_some: ScheduledOperationWhereInput
  slug: String

  """All values containing the given string."""
  slug_contains: String

  """All values ending with the given string."""
  slug_ends_with: String

  """All values that are contained in given list."""
  slug_in: [String]

  """Any other value that exists and is not equal to the given value."""
  slug_not: String

  """All values not containing the given string."""
  slug_not_contains: String

  """All values not ending with the given string"""
  slug_not_ends_with: String

  """All values that are not contained in given list."""
  slug_not_in: [String]

  """All values not starting with the given string."""
  slug_not_starts_with: String

  """All values starting with the given string."""
  slug_starts_with: String
  updatedAt: DateTime

  """All values greater than the given value."""
  updatedAt_gt: DateTime

  """All values greater than or equal the given value."""
  updatedAt_gte: DateTime

  """All values that are contained in given list."""
  updatedAt_in: [DateTime]

  """All values less than the given value."""
  updatedAt_lt: DateTime

  """All values less than or equal the given value."""
  updatedAt_lte: DateTime

  """Any other value that exists and is not equal to the given value."""
  updatedAt_not: DateTime

  """All values that are not contained in given list."""
  updatedAt_not_in: [DateTime]
  updatedBy: UserWhereInput
}

enum EventOrderByInput {
  createdAt_ASC
  createdAt_DESC
  heroImageClasses_ASC
  heroImageClasses_DESC
  id_ASC
  id_DESC
  public_ASC
  public_DESC
  publishedAt_ASC
  publishedAt_DESC
  published_ASC
  published_DESC
  slug_ASC
  slug_DESC
  title_ASC
  title_DESC
  updatedAt_ASC
  updatedAt_DESC
}

"""
Define a pass for an event with different options, price, number of passes etc.
"""
type EventPass implements Entity & Node {
  """The time the document was created"""
  createdAt(
    """
    Variation of DateTime field to return, allows value from base document, current localization, or combined by returning the newer value of both
    """
    variation: SystemDateTimeFieldVariation! = COMBINED
  ): DateTime!

  """User that created this document"""
  createdBy(
    """
    Sets the locale of the resolved parent document as the only locale in the query's subtree.
    
    Note that `createdBy` is a model without localized fields and will not be affected directly by this argument, however the locale will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `createdBy` is a model without localized fields and will not be affected directly by this argument, however the locales will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
  ): User

  """
  Description of the pass, like "Access to the event for 3 days"
  """
  description: String!

  """Get the document in other stages"""
  documentInStages(
    """Decides if the current stage should be included or not"""
    includeCurrent: Boolean! = false

    """
    Decides if the documents should match the parent documents locale or should use the fallback order defined in the tree
    """
    inheritLocale: Boolean! = false

    """Potential stages that should be returned"""
    stages: [Stage!]! = [DRAFT, PUBLISHED]
  ): [EventPass!]!
  event(
    """
    Sets the locale of the parent document as the first locale in the fallback locales in the query's subtree.
    
    Note that `event` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, localized entries that do not have the provided locale defined will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `event` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, localized entries that do not have the provided locale defined will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
  ): Event

  """
  This is a direct link from your `EventPass` to `EventPassDelayedReveal`, enabling access to additional, exclusive details that are revealed afterwards on the back-office.
  """
  eventPassDelayedRevealed(
    """
    Sets the locale of the parent document as the first locale in the fallback locales in the query's subtree.
    
    Note that `eventPassDelayedRevealed` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, localized entries that do not have the provided locale defined will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `eventPassDelayedRevealed` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, localized entries that do not have the provided locale defined will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
  ): EventPassDelayedRevealed
  eventPassNftContract: eventPassNftContract
  eventPassOrderSums: eventPassOrderSums
  eventPassPricing: eventPassPricing

  """List of EventPass versions"""
  history(
    limit: Int! = 10
    skip: Int! = 0

    """
    This is optional and can be used to fetch the document version history for a specific stage instead of the current one
    """
    stageOverride: Stage
  ): [Version!]!

  """The unique identifier"""
  id: ID!

  """System Locale field"""
  locale: Locale!

  """Get the other localizations for this document"""
  localizations(
    """Decides if the current locale should be included or not"""
    includeCurrent: Boolean! = false

    """
    Potential locales that should be returned. 
    
    The order of locales will also override locale fall-backing behaviour in the query's subtree.
    
    Note any related model with localized fields in the query's subtree will be affected.
    The first locale matching the provided list will be returned, localized entries that do not have the provided locale defined will be filtered out.
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    
    Consider using this in conjunction with forceParentLocale on the children relation fields.
    """
    locales: [Locale!]! = [en, fr]
  ): [EventPass!]!

  """
  User-friendly name of the pass, like "VIP 3-Day Pass"
  """
  name: String!

  """
  Fixed description pertaining to the NFT. This content is static and non-localizable.
  """
  nftDescription: String!

  """
  Permanent image representing the NFT. Advised resolution is 350 x 350 pixels. Image content is non-changeable and cannot be localized.
  """
  nftImage(
    """
    Sets the locale of the parent document as the first locale in the fallback locales in the query's subtree.
    
    Note that `nftImage` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, localized entries that do not have the provided locale defined will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `nftImage` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, localized entries that do not have the provided locale defined will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
  ): Asset!

  """
  Permanent name associated with the NFT. Cannot be changed or localized.
  """
  nftName: String!

  """
  Define the different pass options. An option is defined for a specific location and timeframe
  """
  passOptions(
    after: String
    before: String
    first: Int

    """
    Sets the locale of the parent document as the first locale in the fallback locales in the query's subtree.
    
    Note that `passOptions` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, localized entries that do not have the provided locale defined will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean
    last: Int

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `passOptions` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, localized entries that do not have the provided locale defined will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
    orderBy: PassOptionOrderByInput
    skip: Int
    where: PassOptionWhereInput
  ): [PassOption!]!

  """The time the document was published. Null on documents in draft stage."""
  publishedAt(
    """
    Variation of DateTime field to return, allows value from base document, current localization, or combined by returning the newer value of both
    """
    variation: SystemDateTimeFieldVariation! = COMBINED
  ): DateTime

  """User that last published this document"""
  publishedBy(
    """
    Sets the locale of the resolved parent document as the only locale in the query's subtree.
    
    Note that `publishedBy` is a model without localized fields and will not be affected directly by this argument, however the locale will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `publishedBy` is a model without localized fields and will not be affected directly by this argument, however the locales will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
  ): User
  scheduledIn(
    after: String
    before: String
    first: Int

    """
    Sets the locale of the resolved parent document as the only locale in the query's subtree.
    
    Note that `scheduledIn` is a model without localized fields and will not be affected directly by this argument, however the locale will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean
    last: Int

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `scheduledIn` is a model without localized fields and will not be affected directly by this argument, however the locales will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
    skip: Int
    where: ScheduledOperationWhereInput
  ): [ScheduledOperation!]!

  """System stage field"""
  stage: Stage!

  """The time the document was updated"""
  updatedAt(
    """
    Variation of DateTime field to return, allows value from base document, current localization, or combined by returning the newer value of both
    """
    variation: SystemDateTimeFieldVariation! = COMBINED
  ): DateTime!

  """User that last updated this document"""
  updatedBy(
    """
    Sets the locale of the resolved parent document as the only locale in the query's subtree.
    
    Note that `updatedBy` is a model without localized fields and will not be affected directly by this argument, however the locale will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `updatedBy` is a model without localized fields and will not be affected directly by this argument, however the locales will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
  ): User
}

input EventPassConnectInput {
  """
  Allow to specify document position in list of connected documents, will default to appending at end of list
  """
  position: ConnectPositionInput

  """Document to connect"""
  where: EventPassWhereUniqueInput!
}

"""A connection to a list of items."""
type EventPassConnection {
  aggregate: Aggregate!

  """A list of edges."""
  edges: [EventPassEdge!]!

  """Information to aid in pagination."""
  pageInfo: PageInfo!
}

input EventPassCreateInput {
  clptwshsk4wx601usb3uggcu7: EventPassDelayedRevealedCreateManyInlineInput
  createdAt: DateTime

  """description input for default locale (en)"""
  description: String!
  event: EventCreateOneInlineInput
  eventPassDelayedRevealed: EventPassDelayedRevealedCreateOneInlineInput

  """
  Inline mutations for managing document localizations excluding the default locale
  """
  localizations: EventPassCreateLocalizationsInput

  """name input for default locale (en)"""
  name: String!
  nftDescription: String!
  nftImage: AssetCreateOneInlineInput!
  nftName: String!
  passOptions: PassOptionCreateManyInlineInput
  updatedAt: DateTime
}

input EventPassCreateLocalizationDataInput {
  createdAt: DateTime
  description: String!
  name: String!
  updatedAt: DateTime
}

input EventPassCreateLocalizationInput {
  """Localization input"""
  data: EventPassCreateLocalizationDataInput!
  locale: Locale!
}

input EventPassCreateLocalizationsInput {
  """Create localizations for the newly-created document"""
  create: [EventPassCreateLocalizationInput!]
}

input EventPassCreateManyInlineInput {
  """Connect multiple existing EventPass documents"""
  connect: [EventPassWhereUniqueInput!]

  """Create and connect multiple existing EventPass documents"""
  create: [EventPassCreateInput!]
}

input EventPassCreateOneInlineInput {
  """Connect one existing EventPass document"""
  connect: EventPassWhereUniqueInput

  """Create and connect one EventPass document"""
  create: EventPassCreateInput
}

"""
The EventPassDelayedReveal is a feature in our ticketing system that introduces a timed reveal of certain event pass details. It's designed for special events where additional information about the pass, such as its name, description, and image, is unveiled at a later stage, adding an element of anticipation and exclusivity for attendees. This feature is particularly useful for creating a unique and engaging experience for high-profile events.
"""
type EventPassDelayedRevealed implements Entity & Node {
  """The time the document was created"""
  createdAt(
    """
    Variation of DateTime field to return, allows value from base document, current localization, or combined by returning the newer value of both
    """
    variation: SystemDateTimeFieldVariation! = COMBINED
  ): DateTime!

  """User that created this document"""
  createdBy(
    """
    Sets the locale of the resolved parent document as the only locale in the query's subtree.
    
    Note that `createdBy` is a model without localized fields and will not be affected directly by this argument, however the locale will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `createdBy` is a model without localized fields and will not be affected directly by this argument, however the locales will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
  ): User

  """A brief overview or summary of the event pass"""
  description: String!

  """Get the document in other stages"""
  documentInStages(
    """Decides if the current stage should be included or not"""
    includeCurrent: Boolean! = false

    """
    Decides if the documents should match the parent documents locale or should use the fallback order defined in the tree
    """
    inheritLocale: Boolean! = false

    """Potential stages that should be returned"""
    stages: [Stage!]! = [DRAFT, PUBLISHED]
  ): [EventPassDelayedRevealed!]!

  """
  Links directly to `EventPass`, providing initial, temporary details about the NFT until the full reveal occurs.
  """
  eventPass(
    """
    Sets the locale of the parent document as the first locale in the fallback locales in the query's subtree.
    
    Note that `eventPass` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, localized entries that do not have the provided locale defined will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `eventPass` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, localized entries that do not have the provided locale defined will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
  ): EventPass

  """List of EventPassDelayedRevealed versions"""
  history(
    limit: Int! = 10
    skip: Int! = 0

    """
    This is optional and can be used to fetch the document version history for a specific stage instead of the current one
    """
    stageOverride: Stage
  ): [Version!]!

  """The unique identifier"""
  id: ID!

  """System Locale field"""
  locale: Locale!

  """Get the other localizations for this document"""
  localizations(
    """Decides if the current locale should be included or not"""
    includeCurrent: Boolean! = false

    """
    Potential locales that should be returned. 
    
    The order of locales will also override locale fall-backing behaviour in the query's subtree.
    
    Note any related model with localized fields in the query's subtree will be affected.
    The first locale matching the provided list will be returned, localized entries that do not have the provided locale defined will be filtered out.
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    
    Consider using this in conjunction with forceParentLocale on the children relation fields.
    """
    locales: [Locale!]! = [en, fr]
  ): [EventPassDelayedRevealed!]!

  """The official name of the event pass"""
  name: String!

  """
  Fixed description pertaining to the NFT. This content is static and non-localizable.
  """
  nftDescription: String!

  """
  Permanent image representing the NFT. Advised resolution is 350 x 350 pixels. Image content is non-changeable and cannot be localized.
  """
  nftImage(
    """
    Sets the locale of the parent document as the first locale in the fallback locales in the query's subtree.
    
    Note that `nftImage` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, localized entries that do not have the provided locale defined will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `nftImage` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, localized entries that do not have the provided locale defined will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
  ): Asset!

  """
  Permanent name associated with the NFT. Cannot be changed or localized.
  """
  nftName: String!

  """
  Define the different pass options. An option is defined for a specific location and timeframe
  """
  passOptions(
    after: String
    before: String
    first: Int

    """
    Sets the locale of the parent document as the first locale in the fallback locales in the query's subtree.
    
    Note that `passOptions` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, localized entries that do not have the provided locale defined will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean
    last: Int

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `passOptions` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, localized entries that do not have the provided locale defined will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
    orderBy: PassOptionOrderByInput
    skip: Int
    where: PassOptionWhereInput
  ): [PassOption!]!

  """The time the document was published. Null on documents in draft stage."""
  publishedAt(
    """
    Variation of DateTime field to return, allows value from base document, current localization, or combined by returning the newer value of both
    """
    variation: SystemDateTimeFieldVariation! = COMBINED
  ): DateTime

  """User that last published this document"""
  publishedBy(
    """
    Sets the locale of the resolved parent document as the only locale in the query's subtree.
    
    Note that `publishedBy` is a model without localized fields and will not be affected directly by this argument, however the locale will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `publishedBy` is a model without localized fields and will not be affected directly by this argument, however the locales will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
  ): User
  scheduledIn(
    after: String
    before: String
    first: Int

    """
    Sets the locale of the resolved parent document as the only locale in the query's subtree.
    
    Note that `scheduledIn` is a model without localized fields and will not be affected directly by this argument, however the locale will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean
    last: Int

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `scheduledIn` is a model without localized fields and will not be affected directly by this argument, however the locales will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
    skip: Int
    where: ScheduledOperationWhereInput
  ): [ScheduledOperation!]!

  """System stage field"""
  stage: Stage!

  """The time the document was updated"""
  updatedAt(
    """
    Variation of DateTime field to return, allows value from base document, current localization, or combined by returning the newer value of both
    """
    variation: SystemDateTimeFieldVariation! = COMBINED
  ): DateTime!

  """User that last updated this document"""
  updatedBy(
    """
    Sets the locale of the resolved parent document as the only locale in the query's subtree.
    
    Note that `updatedBy` is a model without localized fields and will not be affected directly by this argument, however the locale will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `updatedBy` is a model without localized fields and will not be affected directly by this argument, however the locales will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
  ): User
}

input EventPassDelayedRevealedConnectInput {
  """
  Allow to specify document position in list of connected documents, will default to appending at end of list
  """
  position: ConnectPositionInput

  """Document to connect"""
  where: EventPassDelayedRevealedWhereUniqueInput!
}

"""A connection to a list of items."""
type EventPassDelayedRevealedConnection {
  aggregate: Aggregate!

  """A list of edges."""
  edges: [EventPassDelayedRevealedEdge!]!

  """Information to aid in pagination."""
  pageInfo: PageInfo!
}

input EventPassDelayedRevealedCreateInput {
  clptyt58r52j901t9gkjuht2t: EventPassCreateManyInlineInput
  createdAt: DateTime

  """description input for default locale (en)"""
  description: String!
  eventPass: EventPassCreateOneInlineInput

  """
  Inline mutations for managing document localizations excluding the default locale
  """
  localizations: EventPassDelayedRevealedCreateLocalizationsInput

  """name input for default locale (en)"""
  name: String!
  nftDescription: String!
  nftImage: AssetCreateOneInlineInput!
  nftName: String!
  passOptions: PassOptionCreateManyInlineInput
  updatedAt: DateTime
}

input EventPassDelayedRevealedCreateLocalizationDataInput {
  createdAt: DateTime
  description: String!
  name: String!
  updatedAt: DateTime
}

input EventPassDelayedRevealedCreateLocalizationInput {
  """Localization input"""
  data: EventPassDelayedRevealedCreateLocalizationDataInput!
  locale: Locale!
}

input EventPassDelayedRevealedCreateLocalizationsInput {
  """Create localizations for the newly-created document"""
  create: [EventPassDelayedRevealedCreateLocalizationInput!]
}

input EventPassDelayedRevealedCreateManyInlineInput {
  """Connect multiple existing EventPassDelayedRevealed documents"""
  connect: [EventPassDelayedRevealedWhereUniqueInput!]

  """
  Create and connect multiple existing EventPassDelayedRevealed documents
  """
  create: [EventPassDelayedRevealedCreateInput!]
}

input EventPassDelayedRevealedCreateOneInlineInput {
  """Connect one existing EventPassDelayedRevealed document"""
  connect: EventPassDelayedRevealedWhereUniqueInput

  """Create and connect one EventPassDelayedRevealed document"""
  create: EventPassDelayedRevealedCreateInput
}

"""An edge in a connection."""
type EventPassDelayedRevealedEdge {
  """A cursor for use in pagination."""
  cursor: String!

  """The item at the end of the edge."""
  node: EventPassDelayedRevealed!
}

"""Identifies documents"""
input EventPassDelayedRevealedManyWhereInput {
  """Logical AND on all given filters."""
  AND: [EventPassDelayedRevealedWhereInput!]

  """Logical NOT on all given filters combined by AND."""
  NOT: [EventPassDelayedRevealedWhereInput!]

  """Logical OR on all given filters."""
  OR: [EventPassDelayedRevealedWhereInput!]

  """Contains search across all appropriate fields."""
  _search: String
  createdAt: DateTime

  """All values greater than the given value."""
  createdAt_gt: DateTime

  """All values greater than or equal the given value."""
  createdAt_gte: DateTime

  """All values that are contained in given list."""
  createdAt_in: [DateTime]

  """All values less than the given value."""
  createdAt_lt: DateTime

  """All values less than or equal the given value."""
  createdAt_lte: DateTime

  """Any other value that exists and is not equal to the given value."""
  createdAt_not: DateTime

  """All values that are not contained in given list."""
  createdAt_not_in: [DateTime]
  createdBy: UserWhereInput
  documentInStages_every: EventPassDelayedRevealedWhereStageInput
  documentInStages_none: EventPassDelayedRevealedWhereStageInput
  documentInStages_some: EventPassDelayedRevealedWhereStageInput
  eventPass: EventPassWhereInput
  id: ID

  """All values containing the given string."""
  id_contains: ID

  """All values ending with the given string."""
  id_ends_with: ID

  """All values that are contained in given list."""
  id_in: [ID]

  """Any other value that exists and is not equal to the given value."""
  id_not: ID

  """All values not containing the given string."""
  id_not_contains: ID

  """All values not ending with the given string"""
  id_not_ends_with: ID

  """All values that are not contained in given list."""
  id_not_in: [ID]

  """All values not starting with the given string."""
  id_not_starts_with: ID

  """All values starting with the given string."""
  id_starts_with: ID
  nftDescription: String

  """All values containing the given string."""
  nftDescription_contains: String

  """All values ending with the given string."""
  nftDescription_ends_with: String

  """All values that are contained in given list."""
  nftDescription_in: [String]

  """Any other value that exists and is not equal to the given value."""
  nftDescription_not: String

  """All values not containing the given string."""
  nftDescription_not_contains: String

  """All values not ending with the given string"""
  nftDescription_not_ends_with: String

  """All values that are not contained in given list."""
  nftDescription_not_in: [String]

  """All values not starting with the given string."""
  nftDescription_not_starts_with: String

  """All values starting with the given string."""
  nftDescription_starts_with: String
  nftImage: AssetWhereInput
  nftName: String

  """All values containing the given string."""
  nftName_contains: String

  """All values ending with the given string."""
  nftName_ends_with: String

  """All values that are contained in given list."""
  nftName_in: [String]

  """Any other value that exists and is not equal to the given value."""
  nftName_not: String

  """All values not containing the given string."""
  nftName_not_contains: String

  """All values not ending with the given string"""
  nftName_not_ends_with: String

  """All values that are not contained in given list."""
  nftName_not_in: [String]

  """All values not starting with the given string."""
  nftName_not_starts_with: String

  """All values starting with the given string."""
  nftName_starts_with: String
  passOptions_every: PassOptionWhereInput
  passOptions_none: PassOptionWhereInput
  passOptions_some: PassOptionWhereInput
  publishedAt: DateTime

  """All values greater than the given value."""
  publishedAt_gt: DateTime

  """All values greater than or equal the given value."""
  publishedAt_gte: DateTime

  """All values that are contained in given list."""
  publishedAt_in: [DateTime]

  """All values less than the given value."""
  publishedAt_lt: DateTime

  """All values less than or equal the given value."""
  publishedAt_lte: DateTime

  """Any other value that exists and is not equal to the given value."""
  publishedAt_not: DateTime

  """All values that are not contained in given list."""
  publishedAt_not_in: [DateTime]
  publishedBy: UserWhereInput
  scheduledIn_every: ScheduledOperationWhereInput
  scheduledIn_none: ScheduledOperationWhereInput
  scheduledIn_some: ScheduledOperationWhereInput
  updatedAt: DateTime

  """All values greater than the given value."""
  updatedAt_gt: DateTime

  """All values greater than or equal the given value."""
  updatedAt_gte: DateTime

  """All values that are contained in given list."""
  updatedAt_in: [DateTime]

  """All values less than the given value."""
  updatedAt_lt: DateTime

  """All values less than or equal the given value."""
  updatedAt_lte: DateTime

  """Any other value that exists and is not equal to the given value."""
  updatedAt_not: DateTime

  """All values that are not contained in given list."""
  updatedAt_not_in: [DateTime]
  updatedBy: UserWhereInput
}

enum EventPassDelayedRevealedOrderByInput {
  createdAt_ASC
  createdAt_DESC
  description_ASC
  description_DESC
  id_ASC
  id_DESC
  name_ASC
  name_DESC
  nftDescription_ASC
  nftDescription_DESC
  nftName_ASC
  nftName_DESC
  publishedAt_ASC
  publishedAt_DESC
  updatedAt_ASC
  updatedAt_DESC
}

input EventPassDelayedRevealedUpdateInput {
  clptyt58r52j901t9gkjuht2t: EventPassUpdateManyInlineInput

  """description input for default locale (en)"""
  description: String
  eventPass: EventPassUpdateOneInlineInput

  """Manage document localizations"""
  localizations: EventPassDelayedRevealedUpdateLocalizationsInput

  """name input for default locale (en)"""
  name: String
  nftDescription: String
  nftImage: AssetUpdateOneInlineInput
  nftName: String
  passOptions: PassOptionUpdateManyInlineInput
}

input EventPassDelayedRevealedUpdateLocalizationDataInput {
  description: String
  name: String
}

input EventPassDelayedRevealedUpdateLocalizationInput {
  data: EventPassDelayedRevealedUpdateLocalizationDataInput!
  locale: Locale!
}

input EventPassDelayedRevealedUpdateLocalizationsInput {
  """Localizations to create"""
  create: [EventPassDelayedRevealedCreateLocalizationInput!]

  """Localizations to delete"""
  delete: [Locale!]

  """Localizations to update"""
  update: [EventPassDelayedRevealedUpdateLocalizationInput!]
  upsert: [EventPassDelayedRevealedUpsertLocalizationInput!]
}

input EventPassDelayedRevealedUpdateManyInlineInput {
  """Connect multiple existing EventPassDelayedRevealed documents"""
  connect: [EventPassDelayedRevealedConnectInput!]

  """Create and connect multiple EventPassDelayedRevealed documents"""
  create: [EventPassDelayedRevealedCreateInput!]

  """Delete multiple EventPassDelayedRevealed documents"""
  delete: [EventPassDelayedRevealedWhereUniqueInput!]

  """Disconnect multiple EventPassDelayedRevealed documents"""
  disconnect: [EventPassDelayedRevealedWhereUniqueInput!]

  """
  Override currently-connected documents with multiple existing EventPassDelayedRevealed documents
  """
  set: [EventPassDelayedRevealedWhereUniqueInput!]

  """Update multiple EventPassDelayedRevealed documents"""
  update: [EventPassDelayedRevealedUpdateWithNestedWhereUniqueInput!]

  """Upsert multiple EventPassDelayedRevealed documents"""
  upsert: [EventPassDelayedRevealedUpsertWithNestedWhereUniqueInput!]
}

input EventPassDelayedRevealedUpdateManyInput {
  """description input for default locale (en)"""
  description: String

  """Optional updates to localizations"""
  localizations: EventPassDelayedRevealedUpdateManyLocalizationsInput

  """name input for default locale (en)"""
  name: String
  nftDescription: String
  nftName: String
}

input EventPassDelayedRevealedUpdateManyLocalizationDataInput {
  description: String
  name: String
}

input EventPassDelayedRevealedUpdateManyLocalizationInput {
  data: EventPassDelayedRevealedUpdateManyLocalizationDataInput!
  locale: Locale!
}

input EventPassDelayedRevealedUpdateManyLocalizationsInput {
  """Localizations to update"""
  update: [EventPassDelayedRevealedUpdateManyLocalizationInput!]
}

input EventPassDelayedRevealedUpdateOneInlineInput {
  """Connect existing EventPassDelayedRevealed document"""
  connect: EventPassDelayedRevealedWhereUniqueInput

  """Create and connect one EventPassDelayedRevealed document"""
  create: EventPassDelayedRevealedCreateInput

  """Delete currently connected EventPassDelayedRevealed document"""
  delete: Boolean

  """Disconnect currently connected EventPassDelayedRevealed document"""
  disconnect: Boolean

  """Update single EventPassDelayedRevealed document"""
  update: EventPassDelayedRevealedUpdateWithNestedWhereUniqueInput

  """Upsert single EventPassDelayedRevealed document"""
  upsert: EventPassDelayedRevealedUpsertWithNestedWhereUniqueInput
}

input EventPassDelayedRevealedUpdateWithNestedWhereUniqueInput {
  """Document to update"""
  data: EventPassDelayedRevealedUpdateInput!

  """Unique document search"""
  where: EventPassDelayedRevealedWhereUniqueInput!
}

input EventPassDelayedRevealedUpsertInput {
  """Create document if it didn't exist"""
  create: EventPassDelayedRevealedCreateInput!

  """Update document if it exists"""
  update: EventPassDelayedRevealedUpdateInput!
}

input EventPassDelayedRevealedUpsertLocalizationInput {
  create: EventPassDelayedRevealedCreateLocalizationDataInput!
  locale: Locale!
  update: EventPassDelayedRevealedUpdateLocalizationDataInput!
}

input EventPassDelayedRevealedUpsertWithNestedWhereUniqueInput {
  """Upsert data"""
  data: EventPassDelayedRevealedUpsertInput!

  """Unique document search"""
  where: EventPassDelayedRevealedWhereUniqueInput!
}

"""
This contains a set of filters that can be used to compare values internally
"""
input EventPassDelayedRevealedWhereComparatorInput {
  """
  This field can be used to request to check if the entry is outdated by internal comparison
  """
  outdated_to: Boolean
}

"""Identifies documents"""
input EventPassDelayedRevealedWhereInput {
  """Logical AND on all given filters."""
  AND: [EventPassDelayedRevealedWhereInput!]

  """Logical NOT on all given filters combined by AND."""
  NOT: [EventPassDelayedRevealedWhereInput!]

  """Logical OR on all given filters."""
  OR: [EventPassDelayedRevealedWhereInput!]

  """Contains search across all appropriate fields."""
  _search: String
  createdAt: DateTime

  """All values greater than the given value."""
  createdAt_gt: DateTime

  """All values greater than or equal the given value."""
  createdAt_gte: DateTime

  """All values that are contained in given list."""
  createdAt_in: [DateTime]

  """All values less than the given value."""
  createdAt_lt: DateTime

  """All values less than or equal the given value."""
  createdAt_lte: DateTime

  """Any other value that exists and is not equal to the given value."""
  createdAt_not: DateTime

  """All values that are not contained in given list."""
  createdAt_not_in: [DateTime]
  createdBy: UserWhereInput
  description: String

  """All values containing the given string."""
  description_contains: String

  """All values ending with the given string."""
  description_ends_with: String

  """All values that are contained in given list."""
  description_in: [String]

  """Any other value that exists and is not equal to the given value."""
  description_not: String

  """All values not containing the given string."""
  description_not_contains: String

  """All values not ending with the given string"""
  description_not_ends_with: String

  """All values that are not contained in given list."""
  description_not_in: [String]

  """All values not starting with the given string."""
  description_not_starts_with: String

  """All values starting with the given string."""
  description_starts_with: String
  documentInStages_every: EventPassDelayedRevealedWhereStageInput
  documentInStages_none: EventPassDelayedRevealedWhereStageInput
  documentInStages_some: EventPassDelayedRevealedWhereStageInput
  eventPass: EventPassWhereInput
  id: ID

  """All values containing the given string."""
  id_contains: ID

  """All values ending with the given string."""
  id_ends_with: ID

  """All values that are contained in given list."""
  id_in: [ID]

  """Any other value that exists and is not equal to the given value."""
  id_not: ID

  """All values not containing the given string."""
  id_not_contains: ID

  """All values not ending with the given string"""
  id_not_ends_with: ID

  """All values that are not contained in given list."""
  id_not_in: [ID]

  """All values not starting with the given string."""
  id_not_starts_with: ID

  """All values starting with the given string."""
  id_starts_with: ID
  name: String

  """All values containing the given string."""
  name_contains: String

  """All values ending with the given string."""
  name_ends_with: String

  """All values that are contained in given list."""
  name_in: [String]

  """Any other value that exists and is not equal to the given value."""
  name_not: String

  """All values not containing the given string."""
  name_not_contains: String

  """All values not ending with the given string"""
  name_not_ends_with: String

  """All values that are not contained in given list."""
  name_not_in: [String]

  """All values not starting with the given string."""
  name_not_starts_with: String

  """All values starting with the given string."""
  name_starts_with: String
  nftDescription: String

  """All values containing the given string."""
  nftDescription_contains: String

  """All values ending with the given string."""
  nftDescription_ends_with: String

  """All values that are contained in given list."""
  nftDescription_in: [String]

  """Any other value that exists and is not equal to the given value."""
  nftDescription_not: String

  """All values not containing the given string."""
  nftDescription_not_contains: String

  """All values not ending with the given string"""
  nftDescription_not_ends_with: String

  """All values that are not contained in given list."""
  nftDescription_not_in: [String]

  """All values not starting with the given string."""
  nftDescription_not_starts_with: String

  """All values starting with the given string."""
  nftDescription_starts_with: String
  nftImage: AssetWhereInput
  nftName: String

  """All values containing the given string."""
  nftName_contains: String

  """All values ending with the given string."""
  nftName_ends_with: String

  """All values that are contained in given list."""
  nftName_in: [String]

  """Any other value that exists and is not equal to the given value."""
  nftName_not: String

  """All values not containing the given string."""
  nftName_not_contains: String

  """All values not ending with the given string"""
  nftName_not_ends_with: String

  """All values that are not contained in given list."""
  nftName_not_in: [String]

  """All values not starting with the given string."""
  nftName_not_starts_with: String

  """All values starting with the given string."""
  nftName_starts_with: String
  passOptions_every: PassOptionWhereInput
  passOptions_none: PassOptionWhereInput
  passOptions_some: PassOptionWhereInput
  publishedAt: DateTime

  """All values greater than the given value."""
  publishedAt_gt: DateTime

  """All values greater than or equal the given value."""
  publishedAt_gte: DateTime

  """All values that are contained in given list."""
  publishedAt_in: [DateTime]

  """All values less than the given value."""
  publishedAt_lt: DateTime

  """All values less than or equal the given value."""
  publishedAt_lte: DateTime

  """Any other value that exists and is not equal to the given value."""
  publishedAt_not: DateTime

  """All values that are not contained in given list."""
  publishedAt_not_in: [DateTime]
  publishedBy: UserWhereInput
  scheduledIn_every: ScheduledOperationWhereInput
  scheduledIn_none: ScheduledOperationWhereInput
  scheduledIn_some: ScheduledOperationWhereInput
  updatedAt: DateTime

  """All values greater than the given value."""
  updatedAt_gt: DateTime

  """All values greater than or equal the given value."""
  updatedAt_gte: DateTime

  """All values that are contained in given list."""
  updatedAt_in: [DateTime]

  """All values less than the given value."""
  updatedAt_lt: DateTime

  """All values less than or equal the given value."""
  updatedAt_lte: DateTime

  """Any other value that exists and is not equal to the given value."""
  updatedAt_not: DateTime

  """All values that are not contained in given list."""
  updatedAt_not_in: [DateTime]
  updatedBy: UserWhereInput
}

"""
The document in stages filter allows specifying a stage entry to cross compare the same document between different stages
"""
input EventPassDelayedRevealedWhereStageInput {
  """Logical AND on all given filters."""
  AND: [EventPassDelayedRevealedWhereStageInput!]

  """Logical NOT on all given filters combined by AND."""
  NOT: [EventPassDelayedRevealedWhereStageInput!]

  """Logical OR on all given filters."""
  OR: [EventPassDelayedRevealedWhereStageInput!]

  """
  This field contains fields which can be set as true or false to specify an internal comparison
  """
  compareWithParent: EventPassDelayedRevealedWhereComparatorInput

  """Specify the stage to compare with"""
  stage: Stage
}

"""References EventPassDelayedRevealed record uniquely"""
input EventPassDelayedRevealedWhereUniqueInput {
  id: ID
}

"""An edge in a connection."""
type EventPassEdge {
  """A cursor for use in pagination."""
  cursor: String!

  """The item at the end of the edge."""
  node: EventPass!
}

"""Identifies documents"""
input EventPassManyWhereInput {
  """Logical AND on all given filters."""
  AND: [EventPassWhereInput!]

  """Logical NOT on all given filters combined by AND."""
  NOT: [EventPassWhereInput!]

  """Logical OR on all given filters."""
  OR: [EventPassWhereInput!]

  """Contains search across all appropriate fields."""
  _search: String
  createdAt: DateTime

  """All values greater than the given value."""
  createdAt_gt: DateTime

  """All values greater than or equal the given value."""
  createdAt_gte: DateTime

  """All values that are contained in given list."""
  createdAt_in: [DateTime]

  """All values less than the given value."""
  createdAt_lt: DateTime

  """All values less than or equal the given value."""
  createdAt_lte: DateTime

  """Any other value that exists and is not equal to the given value."""
  createdAt_not: DateTime

  """All values that are not contained in given list."""
  createdAt_not_in: [DateTime]
  createdBy: UserWhereInput
  documentInStages_every: EventPassWhereStageInput
  documentInStages_none: EventPassWhereStageInput
  documentInStages_some: EventPassWhereStageInput
  event: EventWhereInput
  eventPassDelayedRevealed: EventPassDelayedRevealedWhereInput
  id: ID

  """All values containing the given string."""
  id_contains: ID

  """All values ending with the given string."""
  id_ends_with: ID

  """All values that are contained in given list."""
  id_in: [ID]

  """Any other value that exists and is not equal to the given value."""
  id_not: ID

  """All values not containing the given string."""
  id_not_contains: ID

  """All values not ending with the given string"""
  id_not_ends_with: ID

  """All values that are not contained in given list."""
  id_not_in: [ID]

  """All values not starting with the given string."""
  id_not_starts_with: ID

  """All values starting with the given string."""
  id_starts_with: ID
  nftDescription: String

  """All values containing the given string."""
  nftDescription_contains: String

  """All values ending with the given string."""
  nftDescription_ends_with: String

  """All values that are contained in given list."""
  nftDescription_in: [String]

  """Any other value that exists and is not equal to the given value."""
  nftDescription_not: String

  """All values not containing the given string."""
  nftDescription_not_contains: String

  """All values not ending with the given string"""
  nftDescription_not_ends_with: String

  """All values that are not contained in given list."""
  nftDescription_not_in: [String]

  """All values not starting with the given string."""
  nftDescription_not_starts_with: String

  """All values starting with the given string."""
  nftDescription_starts_with: String
  nftImage: AssetWhereInput
  nftName: String

  """All values containing the given string."""
  nftName_contains: String

  """All values ending with the given string."""
  nftName_ends_with: String

  """All values that are contained in given list."""
  nftName_in: [String]

  """Any other value that exists and is not equal to the given value."""
  nftName_not: String

  """All values not containing the given string."""
  nftName_not_contains: String

  """All values not ending with the given string"""
  nftName_not_ends_with: String

  """All values that are not contained in given list."""
  nftName_not_in: [String]

  """All values not starting with the given string."""
  nftName_not_starts_with: String

  """All values starting with the given string."""
  nftName_starts_with: String
  passOptions_every: PassOptionWhereInput
  passOptions_none: PassOptionWhereInput
  passOptions_some: PassOptionWhereInput
  publishedAt: DateTime

  """All values greater than the given value."""
  publishedAt_gt: DateTime

  """All values greater than or equal the given value."""
  publishedAt_gte: DateTime

  """All values that are contained in given list."""
  publishedAt_in: [DateTime]

  """All values less than the given value."""
  publishedAt_lt: DateTime

  """All values less than or equal the given value."""
  publishedAt_lte: DateTime

  """Any other value that exists and is not equal to the given value."""
  publishedAt_not: DateTime

  """All values that are not contained in given list."""
  publishedAt_not_in: [DateTime]
  publishedBy: UserWhereInput
  scheduledIn_every: ScheduledOperationWhereInput
  scheduledIn_none: ScheduledOperationWhereInput
  scheduledIn_some: ScheduledOperationWhereInput
  updatedAt: DateTime

  """All values greater than the given value."""
  updatedAt_gt: DateTime

  """All values greater than or equal the given value."""
  updatedAt_gte: DateTime

  """All values that are contained in given list."""
  updatedAt_in: [DateTime]

  """All values less than the given value."""
  updatedAt_lt: DateTime

  """All values less than or equal the given value."""
  updatedAt_lte: DateTime

  """Any other value that exists and is not equal to the given value."""
  updatedAt_not: DateTime

  """All values that are not contained in given list."""
  updatedAt_not_in: [DateTime]
  updatedBy: UserWhereInput
}

enum EventPassOrderByInput {
  createdAt_ASC
  createdAt_DESC
  description_ASC
  description_DESC
  id_ASC
  id_DESC
  name_ASC
  name_DESC
  nftDescription_ASC
  nftDescription_DESC
  nftName_ASC
  nftName_DESC
  publishedAt_ASC
  publishedAt_DESC
  updatedAt_ASC
  updatedAt_DESC
}

input EventPassUpdateInput {
  clptwshsk4wx601usb3uggcu7: EventPassDelayedRevealedUpdateManyInlineInput

  """description input for default locale (en)"""
  description: String
  event: EventUpdateOneInlineInput
  eventPassDelayedRevealed: EventPassDelayedRevealedUpdateOneInlineInput

  """Manage document localizations"""
  localizations: EventPassUpdateLocalizationsInput

  """name input for default locale (en)"""
  name: String
  nftDescription: String
  nftImage: AssetUpdateOneInlineInput
  nftName: String
  passOptions: PassOptionUpdateManyInlineInput
}

input EventPassUpdateLocalizationDataInput {
  description: String
  name: String
}

input EventPassUpdateLocalizationInput {
  data: EventPassUpdateLocalizationDataInput!
  locale: Locale!
}

input EventPassUpdateLocalizationsInput {
  """Localizations to create"""
  create: [EventPassCreateLocalizationInput!]

  """Localizations to delete"""
  delete: [Locale!]

  """Localizations to update"""
  update: [EventPassUpdateLocalizationInput!]
  upsert: [EventPassUpsertLocalizationInput!]
}

input EventPassUpdateManyInlineInput {
  """Connect multiple existing EventPass documents"""
  connect: [EventPassConnectInput!]

  """Create and connect multiple EventPass documents"""
  create: [EventPassCreateInput!]

  """Delete multiple EventPass documents"""
  delete: [EventPassWhereUniqueInput!]

  """Disconnect multiple EventPass documents"""
  disconnect: [EventPassWhereUniqueInput!]

  """
  Override currently-connected documents with multiple existing EventPass documents
  """
  set: [EventPassWhereUniqueInput!]

  """Update multiple EventPass documents"""
  update: [EventPassUpdateWithNestedWhereUniqueInput!]

  """Upsert multiple EventPass documents"""
  upsert: [EventPassUpsertWithNestedWhereUniqueInput!]
}

input EventPassUpdateManyInput {
  """description input for default locale (en)"""
  description: String

  """Optional updates to localizations"""
  localizations: EventPassUpdateManyLocalizationsInput

  """name input for default locale (en)"""
  name: String
  nftDescription: String
  nftName: String
}

input EventPassUpdateManyLocalizationDataInput {
  description: String
  name: String
}

input EventPassUpdateManyLocalizationInput {
  data: EventPassUpdateManyLocalizationDataInput!
  locale: Locale!
}

input EventPassUpdateManyLocalizationsInput {
  """Localizations to update"""
  update: [EventPassUpdateManyLocalizationInput!]
}

input EventPassUpdateOneInlineInput {
  """Connect existing EventPass document"""
  connect: EventPassWhereUniqueInput

  """Create and connect one EventPass document"""
  create: EventPassCreateInput

  """Delete currently connected EventPass document"""
  delete: Boolean

  """Disconnect currently connected EventPass document"""
  disconnect: Boolean

  """Update single EventPass document"""
  update: EventPassUpdateWithNestedWhereUniqueInput

  """Upsert single EventPass document"""
  upsert: EventPassUpsertWithNestedWhereUniqueInput
}

input EventPassUpdateWithNestedWhereUniqueInput {
  """Document to update"""
  data: EventPassUpdateInput!

  """Unique document search"""
  where: EventPassWhereUniqueInput!
}

input EventPassUpsertInput {
  """Create document if it didn't exist"""
  create: EventPassCreateInput!

  """Update document if it exists"""
  update: EventPassUpdateInput!
}

input EventPassUpsertLocalizationInput {
  create: EventPassCreateLocalizationDataInput!
  locale: Locale!
  update: EventPassUpdateLocalizationDataInput!
}

input EventPassUpsertWithNestedWhereUniqueInput {
  """Upsert data"""
  data: EventPassUpsertInput!

  """Unique document search"""
  where: EventPassWhereUniqueInput!
}

"""
This contains a set of filters that can be used to compare values internally
"""
input EventPassWhereComparatorInput {
  """
  This field can be used to request to check if the entry is outdated by internal comparison
  """
  outdated_to: Boolean
}

"""Identifies documents"""
input EventPassWhereInput {
  """Logical AND on all given filters."""
  AND: [EventPassWhereInput!]

  """Logical NOT on all given filters combined by AND."""
  NOT: [EventPassWhereInput!]

  """Logical OR on all given filters."""
  OR: [EventPassWhereInput!]

  """Contains search across all appropriate fields."""
  _search: String
  createdAt: DateTime

  """All values greater than the given value."""
  createdAt_gt: DateTime

  """All values greater than or equal the given value."""
  createdAt_gte: DateTime

  """All values that are contained in given list."""
  createdAt_in: [DateTime]

  """All values less than the given value."""
  createdAt_lt: DateTime

  """All values less than or equal the given value."""
  createdAt_lte: DateTime

  """Any other value that exists and is not equal to the given value."""
  createdAt_not: DateTime

  """All values that are not contained in given list."""
  createdAt_not_in: [DateTime]
  createdBy: UserWhereInput
  description: String

  """All values containing the given string."""
  description_contains: String

  """All values ending with the given string."""
  description_ends_with: String

  """All values that are contained in given list."""
  description_in: [String]

  """Any other value that exists and is not equal to the given value."""
  description_not: String

  """All values not containing the given string."""
  description_not_contains: String

  """All values not ending with the given string"""
  description_not_ends_with: String

  """All values that are not contained in given list."""
  description_not_in: [String]

  """All values not starting with the given string."""
  description_not_starts_with: String

  """All values starting with the given string."""
  description_starts_with: String
  documentInStages_every: EventPassWhereStageInput
  documentInStages_none: EventPassWhereStageInput
  documentInStages_some: EventPassWhereStageInput
  event: EventWhereInput
  eventPassDelayedRevealed: EventPassDelayedRevealedWhereInput
  id: ID

  """All values containing the given string."""
  id_contains: ID

  """All values ending with the given string."""
  id_ends_with: ID

  """All values that are contained in given list."""
  id_in: [ID]

  """Any other value that exists and is not equal to the given value."""
  id_not: ID

  """All values not containing the given string."""
  id_not_contains: ID

  """All values not ending with the given string"""
  id_not_ends_with: ID

  """All values that are not contained in given list."""
  id_not_in: [ID]

  """All values not starting with the given string."""
  id_not_starts_with: ID

  """All values starting with the given string."""
  id_starts_with: ID
  name: String

  """All values containing the given string."""
  name_contains: String

  """All values ending with the given string."""
  name_ends_with: String

  """All values that are contained in given list."""
  name_in: [String]

  """Any other value that exists and is not equal to the given value."""
  name_not: String

  """All values not containing the given string."""
  name_not_contains: String

  """All values not ending with the given string"""
  name_not_ends_with: String

  """All values that are not contained in given list."""
  name_not_in: [String]

  """All values not starting with the given string."""
  name_not_starts_with: String

  """All values starting with the given string."""
  name_starts_with: String
  nftDescription: String

  """All values containing the given string."""
  nftDescription_contains: String

  """All values ending with the given string."""
  nftDescription_ends_with: String

  """All values that are contained in given list."""
  nftDescription_in: [String]

  """Any other value that exists and is not equal to the given value."""
  nftDescription_not: String

  """All values not containing the given string."""
  nftDescription_not_contains: String

  """All values not ending with the given string"""
  nftDescription_not_ends_with: String

  """All values that are not contained in given list."""
  nftDescription_not_in: [String]

  """All values not starting with the given string."""
  nftDescription_not_starts_with: String

  """All values starting with the given string."""
  nftDescription_starts_with: String
  nftImage: AssetWhereInput
  nftName: String

  """All values containing the given string."""
  nftName_contains: String

  """All values ending with the given string."""
  nftName_ends_with: String

  """All values that are contained in given list."""
  nftName_in: [String]

  """Any other value that exists and is not equal to the given value."""
  nftName_not: String

  """All values not containing the given string."""
  nftName_not_contains: String

  """All values not ending with the given string"""
  nftName_not_ends_with: String

  """All values that are not contained in given list."""
  nftName_not_in: [String]

  """All values not starting with the given string."""
  nftName_not_starts_with: String

  """All values starting with the given string."""
  nftName_starts_with: String
  passOptions_every: PassOptionWhereInput
  passOptions_none: PassOptionWhereInput
  passOptions_some: PassOptionWhereInput
  publishedAt: DateTime

  """All values greater than the given value."""
  publishedAt_gt: DateTime

  """All values greater than or equal the given value."""
  publishedAt_gte: DateTime

  """All values that are contained in given list."""
  publishedAt_in: [DateTime]

  """All values less than the given value."""
  publishedAt_lt: DateTime

  """All values less than or equal the given value."""
  publishedAt_lte: DateTime

  """Any other value that exists and is not equal to the given value."""
  publishedAt_not: DateTime

  """All values that are not contained in given list."""
  publishedAt_not_in: [DateTime]
  publishedBy: UserWhereInput
  scheduledIn_every: ScheduledOperationWhereInput
  scheduledIn_none: ScheduledOperationWhereInput
  scheduledIn_some: ScheduledOperationWhereInput
  updatedAt: DateTime

  """All values greater than the given value."""
  updatedAt_gt: DateTime

  """All values greater than or equal the given value."""
  updatedAt_gte: DateTime

  """All values that are contained in given list."""
  updatedAt_in: [DateTime]

  """All values less than the given value."""
  updatedAt_lt: DateTime

  """All values less than or equal the given value."""
  updatedAt_lte: DateTime

  """Any other value that exists and is not equal to the given value."""
  updatedAt_not: DateTime

  """All values that are not contained in given list."""
  updatedAt_not_in: [DateTime]
  updatedBy: UserWhereInput
}

"""
The document in stages filter allows specifying a stage entry to cross compare the same document between different stages
"""
input EventPassWhereStageInput {
  """Logical AND on all given filters."""
  AND: [EventPassWhereStageInput!]

  """Logical NOT on all given filters combined by AND."""
  NOT: [EventPassWhereStageInput!]

  """Logical OR on all given filters."""
  OR: [EventPassWhereStageInput!]

  """
  This field contains fields which can be set as true or false to specify an internal comparison
  """
  compareWithParent: EventPassWhereComparatorInput

  """Specify the stage to compare with"""
  stage: Stage
}

"""References EventPass record uniquely"""
input EventPassWhereUniqueInput {
  id: ID
}

input EventUpdateInput {
  """description input for default locale (en)"""
  description: RichTextAST
  eventDateLocations: EventDateLocationUpdateManyInlineInput
  eventPasses: EventPassUpdateManyInlineInput
  heroImage: AssetUpdateOneInlineInput
  heroImageClasses: String

  """Manage document localizations"""
  localizations: EventUpdateLocalizationsInput
  organizer: OrganizerUpdateOneInlineInput
  public: Boolean
  published: Boolean
  slug: String

  """title input for default locale (en)"""
  title: String
}

input EventUpdateLocalizationDataInput {
  description: RichTextAST
  title: String
}

input EventUpdateLocalizationInput {
  data: EventUpdateLocalizationDataInput!
  locale: Locale!
}

input EventUpdateLocalizationsInput {
  """Localizations to create"""
  create: [EventCreateLocalizationInput!]

  """Localizations to delete"""
  delete: [Locale!]

  """Localizations to update"""
  update: [EventUpdateLocalizationInput!]
  upsert: [EventUpsertLocalizationInput!]
}

input EventUpdateManyInlineInput {
  """Connect multiple existing Event documents"""
  connect: [EventConnectInput!]

  """Create and connect multiple Event documents"""
  create: [EventCreateInput!]

  """Delete multiple Event documents"""
  delete: [EventWhereUniqueInput!]

  """Disconnect multiple Event documents"""
  disconnect: [EventWhereUniqueInput!]

  """
  Override currently-connected documents with multiple existing Event documents
  """
  set: [EventWhereUniqueInput!]

  """Update multiple Event documents"""
  update: [EventUpdateWithNestedWhereUniqueInput!]

  """Upsert multiple Event documents"""
  upsert: [EventUpsertWithNestedWhereUniqueInput!]
}

input EventUpdateManyInput {
  """description input for default locale (en)"""
  description: RichTextAST
  heroImageClasses: String

  """Optional updates to localizations"""
  localizations: EventUpdateManyLocalizationsInput
  public: Boolean
  published: Boolean

  """title input for default locale (en)"""
  title: String
}

input EventUpdateManyLocalizationDataInput {
  description: RichTextAST
  title: String
}

input EventUpdateManyLocalizationInput {
  data: EventUpdateManyLocalizationDataInput!
  locale: Locale!
}

input EventUpdateManyLocalizationsInput {
  """Localizations to update"""
  update: [EventUpdateManyLocalizationInput!]
}

input EventUpdateOneInlineInput {
  """Connect existing Event document"""
  connect: EventWhereUniqueInput

  """Create and connect one Event document"""
  create: EventCreateInput

  """Delete currently connected Event document"""
  delete: Boolean

  """Disconnect currently connected Event document"""
  disconnect: Boolean

  """Update single Event document"""
  update: EventUpdateWithNestedWhereUniqueInput

  """Upsert single Event document"""
  upsert: EventUpsertWithNestedWhereUniqueInput
}

input EventUpdateWithNestedWhereUniqueInput {
  """Document to update"""
  data: EventUpdateInput!

  """Unique document search"""
  where: EventWhereUniqueInput!
}

input EventUpsertInput {
  """Create document if it didn't exist"""
  create: EventCreateInput!

  """Update document if it exists"""
  update: EventUpdateInput!
}

input EventUpsertLocalizationInput {
  create: EventCreateLocalizationDataInput!
  locale: Locale!
  update: EventUpdateLocalizationDataInput!
}

input EventUpsertWithNestedWhereUniqueInput {
  """Upsert data"""
  data: EventUpsertInput!

  """Unique document search"""
  where: EventWhereUniqueInput!
}

"""
This contains a set of filters that can be used to compare values internally
"""
input EventWhereComparatorInput {
  """
  This field can be used to request to check if the entry is outdated by internal comparison
  """
  outdated_to: Boolean
}

"""Identifies documents"""
input EventWhereInput {
  """Logical AND on all given filters."""
  AND: [EventWhereInput!]

  """Logical NOT on all given filters combined by AND."""
  NOT: [EventWhereInput!]

  """Logical OR on all given filters."""
  OR: [EventWhereInput!]

  """Contains search across all appropriate fields."""
  _search: String
  createdAt: DateTime

  """All values greater than the given value."""
  createdAt_gt: DateTime

  """All values greater than or equal the given value."""
  createdAt_gte: DateTime

  """All values that are contained in given list."""
  createdAt_in: [DateTime]

  """All values less than the given value."""
  createdAt_lt: DateTime

  """All values less than or equal the given value."""
  createdAt_lte: DateTime

  """Any other value that exists and is not equal to the given value."""
  createdAt_not: DateTime

  """All values that are not contained in given list."""
  createdAt_not_in: [DateTime]
  createdBy: UserWhereInput
  documentInStages_every: EventWhereStageInput
  documentInStages_none: EventWhereStageInput
  documentInStages_some: EventWhereStageInput
  eventDateLocations_every: EventDateLocationWhereInput
  eventDateLocations_none: EventDateLocationWhereInput
  eventDateLocations_some: EventDateLocationWhereInput
  eventPasses_every: EventPassWhereInput
  eventPasses_none: EventPassWhereInput
  eventPasses_some: EventPassWhereInput
  heroImage: AssetWhereInput
  heroImageClasses: String

  """All values containing the given string."""
  heroImageClasses_contains: String

  """All values ending with the given string."""
  heroImageClasses_ends_with: String

  """All values that are contained in given list."""
  heroImageClasses_in: [String]

  """Any other value that exists and is not equal to the given value."""
  heroImageClasses_not: String

  """All values not containing the given string."""
  heroImageClasses_not_contains: String

  """All values not ending with the given string"""
  heroImageClasses_not_ends_with: String

  """All values that are not contained in given list."""
  heroImageClasses_not_in: [String]

  """All values not starting with the given string."""
  heroImageClasses_not_starts_with: String

  """All values starting with the given string."""
  heroImageClasses_starts_with: String
  id: ID

  """All values containing the given string."""
  id_contains: ID

  """All values ending with the given string."""
  id_ends_with: ID

  """All values that are contained in given list."""
  id_in: [ID]

  """Any other value that exists and is not equal to the given value."""
  id_not: ID

  """All values not containing the given string."""
  id_not_contains: ID

  """All values not ending with the given string"""
  id_not_ends_with: ID

  """All values that are not contained in given list."""
  id_not_in: [ID]

  """All values not starting with the given string."""
  id_not_starts_with: ID

  """All values starting with the given string."""
  id_starts_with: ID
  organizer: OrganizerWhereInput
  public: Boolean

  """Any other value that exists and is not equal to the given value."""
  public_not: Boolean
  published: Boolean
  publishedAt: DateTime

  """All values greater than the given value."""
  publishedAt_gt: DateTime

  """All values greater than or equal the given value."""
  publishedAt_gte: DateTime

  """All values that are contained in given list."""
  publishedAt_in: [DateTime]

  """All values less than the given value."""
  publishedAt_lt: DateTime

  """All values less than or equal the given value."""
  publishedAt_lte: DateTime

  """Any other value that exists and is not equal to the given value."""
  publishedAt_not: DateTime

  """All values that are not contained in given list."""
  publishedAt_not_in: [DateTime]
  publishedBy: UserWhereInput

  """Any other value that exists and is not equal to the given value."""
  published_not: Boolean
  scheduledIn_every: ScheduledOperationWhereInput
  scheduledIn_none: ScheduledOperationWhereInput
  scheduledIn_some: ScheduledOperationWhereInput
  slug: String

  """All values containing the given string."""
  slug_contains: String

  """All values ending with the given string."""
  slug_ends_with: String

  """All values that are contained in given list."""
  slug_in: [String]

  """Any other value that exists and is not equal to the given value."""
  slug_not: String

  """All values not containing the given string."""
  slug_not_contains: String

  """All values not ending with the given string"""
  slug_not_ends_with: String

  """All values that are not contained in given list."""
  slug_not_in: [String]

  """All values not starting with the given string."""
  slug_not_starts_with: String

  """All values starting with the given string."""
  slug_starts_with: String
  title: String

  """All values containing the given string."""
  title_contains: String

  """All values ending with the given string."""
  title_ends_with: String

  """All values that are contained in given list."""
  title_in: [String]

  """Any other value that exists and is not equal to the given value."""
  title_not: String

  """All values not containing the given string."""
  title_not_contains: String

  """All values not ending with the given string"""
  title_not_ends_with: String

  """All values that are not contained in given list."""
  title_not_in: [String]

  """All values not starting with the given string."""
  title_not_starts_with: String

  """All values starting with the given string."""
  title_starts_with: String
  updatedAt: DateTime

  """All values greater than the given value."""
  updatedAt_gt: DateTime

  """All values greater than or equal the given value."""
  updatedAt_gte: DateTime

  """All values that are contained in given list."""
  updatedAt_in: [DateTime]

  """All values less than the given value."""
  updatedAt_lt: DateTime

  """All values less than or equal the given value."""
  updatedAt_lte: DateTime

  """Any other value that exists and is not equal to the given value."""
  updatedAt_not: DateTime

  """All values that are not contained in given list."""
  updatedAt_not_in: [DateTime]
  updatedBy: UserWhereInput
}

"""
The document in stages filter allows specifying a stage entry to cross compare the same document between different stages
"""
input EventWhereStageInput {
  """Logical AND on all given filters."""
  AND: [EventWhereStageInput!]

  """Logical NOT on all given filters combined by AND."""
  NOT: [EventWhereStageInput!]

  """Logical OR on all given filters."""
  OR: [EventWhereStageInput!]

  """
  This field contains fields which can be set as true or false to specify an internal comparison
  """
  compareWithParent: EventWhereComparatorInput

  """Specify the stage to compare with"""
  stage: Stage
}

"""References Event record uniquely"""
input EventWhereUniqueInput {
  id: ID
  slug: String
}

"""References Event record uniquely"""
input EventWhereUniqueInput_remote_rel_eventParametersevent {
  slug: String
}

"""References Event record uniquely"""
input EventWhereUniqueInput_remote_rel_eventPassNftevent {
  slug: String
}

enum ImageFit {
  """
  Resizes the image to fit within the specified parameters without distorting, cropping, or changing the aspect ratio.
  """
  clip

  """
  Resizes the image to fit the specified parameters exactly by removing any parts of the image that don't fit within the boundaries.
  """
  crop

  """
  Resizes the image to fit within the parameters, but as opposed to 'fit:clip' will not scale the image if the image is smaller than the output size.
  """
  max

  """
  Resizes the image to fit the specified parameters exactly by scaling the image to the desired size. The aspect ratio of the image is not respected and the image can be distorted using this method.
  """
  scale
}

input ImageResizeInput {
  """The default value for the fit parameter is fit:clip."""
  fit: ImageFit

  """
  The height in pixels to resize the image to. The value must be an integer from 1 to 10000.
  """
  height: Int

  """
  The width in pixels to resize the image to. The value must be an integer from 1 to 10000.
  """
  width: Int
}

"""Transformations for Images"""
input ImageTransformationInput {
  """Resizes the image"""
  resize: ImageResizeInput
}

"""
Boolean expression to compare columns of type "Int". All fields are combined with logical 'AND'.
"""
input Int_comparison_exp {
  _eq: Int
  _gt: Int
  _gte: Int
  _in: [Int!]
  _is_null: Boolean
  _lt: Int
  _lte: Int
  _neq: Int
  _nin: [Int!]
}

"""Raw JSON value"""
scalar Json

"""Locale system enumeration"""
enum Locale {
  """System locale"""
  en
  fr
}

"""Representing a geolocation point with latitude and longitude"""
type Location {
  distance(from: LocationInput!): Float!
  latitude: Float!
  longitude: Float!
}

"""
A model for location data (point on a map) + additional info such as street, venue etc.
"""
type LocationAddress implements Entity {
  """Name of the city"""
  city: String!

  """Point into the map where the event is happening"""
  coordinates: Location!

  """The name of the country"""
  country: String!

  """The unique identifier"""
  id: ID!

  """
  Place ID from google maps. Use this tool to retrieve the correct Place ID from the location you want to open on google maps while clicking on the address provided: https://developers.google.com/maps/documentation/places/web-service/place-id#find-id
  """
  placeId: String
  postalCode: String!

  """System stage field"""
  stage: Stage!

  """The name of the state if it exist"""
  state: String

  """Name of the street"""
  street: String

  """Name of the venue, useful if the address doesn't apply"""
  venue: String
}

input LocationAddressCreateInput {
  city: String!
  coordinates: LocationInput!
  country: String!
  placeId: String
  postalCode: String!
  state: String
  street: String
  venue: String
}

input LocationAddressCreateOneInlineInput {
  """Create and connect one LocationAddress document"""
  create: LocationAddressCreateInput
}

input LocationAddressUpdateInput {
  city: String
  coordinates: LocationInput
  country: String
  placeId: String
  postalCode: String
  state: String
  street: String
  venue: String
}

input LocationAddressUpdateOneInlineInput {
  """Create and connect one LocationAddress document"""
  create: LocationAddressCreateInput

  """Delete currently connected LocationAddress document"""
  delete: Boolean

  """Update single LocationAddress document"""
  update: LocationAddressUpdateWithNestedWhereUniqueInput

  """Upsert single LocationAddress document"""
  upsert: LocationAddressUpsertWithNestedWhereUniqueInput
}

input LocationAddressUpdateWithNestedWhereUniqueInput {
  """Document to update"""
  data: LocationAddressUpdateInput!

  """Unique document search"""
  where: LocationAddressWhereUniqueInput!
}

input LocationAddressUpsertInput {
  """Create document if it didn't exist"""
  create: LocationAddressCreateInput!

  """Update document if it exists"""
  update: LocationAddressUpdateInput!
}

input LocationAddressUpsertWithNestedWhereUniqueInput {
  """Upsert data"""
  data: LocationAddressUpsertInput!

  """Unique document search"""
  where: LocationAddressWhereUniqueInput!
}

"""Identifies documents"""
input LocationAddressWhereInput {
  """Logical AND on all given filters."""
  AND: [LocationAddressWhereInput!]

  """Logical NOT on all given filters combined by AND."""
  NOT: [LocationAddressWhereInput!]

  """Logical OR on all given filters."""
  OR: [LocationAddressWhereInput!]

  """Contains search across all appropriate fields."""
  _search: String
  city: String

  """All values containing the given string."""
  city_contains: String

  """All values ending with the given string."""
  city_ends_with: String

  """All values that are contained in given list."""
  city_in: [String]

  """Any other value that exists and is not equal to the given value."""
  city_not: String

  """All values not containing the given string."""
  city_not_contains: String

  """All values not ending with the given string"""
  city_not_ends_with: String

  """All values that are not contained in given list."""
  city_not_in: [String]

  """All values not starting with the given string."""
  city_not_starts_with: String

  """All values starting with the given string."""
  city_starts_with: String
  country: String

  """All values containing the given string."""
  country_contains: String

  """All values ending with the given string."""
  country_ends_with: String

  """All values that are contained in given list."""
  country_in: [String]

  """Any other value that exists and is not equal to the given value."""
  country_not: String

  """All values not containing the given string."""
  country_not_contains: String

  """All values not ending with the given string"""
  country_not_ends_with: String

  """All values that are not contained in given list."""
  country_not_in: [String]

  """All values not starting with the given string."""
  country_not_starts_with: String

  """All values starting with the given string."""
  country_starts_with: String
  id: ID

  """All values containing the given string."""
  id_contains: ID

  """All values ending with the given string."""
  id_ends_with: ID

  """All values that are contained in given list."""
  id_in: [ID]

  """Any other value that exists and is not equal to the given value."""
  id_not: ID

  """All values not containing the given string."""
  id_not_contains: ID

  """All values not ending with the given string"""
  id_not_ends_with: ID

  """All values that are not contained in given list."""
  id_not_in: [ID]

  """All values not starting with the given string."""
  id_not_starts_with: ID

  """All values starting with the given string."""
  id_starts_with: ID
  placeId: String

  """All values containing the given string."""
  placeId_contains: String

  """All values ending with the given string."""
  placeId_ends_with: String

  """All values that are contained in given list."""
  placeId_in: [String]

  """Any other value that exists and is not equal to the given value."""
  placeId_not: String

  """All values not containing the given string."""
  placeId_not_contains: String

  """All values not ending with the given string"""
  placeId_not_ends_with: String

  """All values that are not contained in given list."""
  placeId_not_in: [String]

  """All values not starting with the given string."""
  placeId_not_starts_with: String

  """All values starting with the given string."""
  placeId_starts_with: String
  postalCode: String

  """All values containing the given string."""
  postalCode_contains: String

  """All values ending with the given string."""
  postalCode_ends_with: String

  """All values that are contained in given list."""
  postalCode_in: [String]

  """Any other value that exists and is not equal to the given value."""
  postalCode_not: String

  """All values not containing the given string."""
  postalCode_not_contains: String

  """All values not ending with the given string"""
  postalCode_not_ends_with: String

  """All values that are not contained in given list."""
  postalCode_not_in: [String]

  """All values not starting with the given string."""
  postalCode_not_starts_with: String

  """All values starting with the given string."""
  postalCode_starts_with: String
  state: String

  """All values containing the given string."""
  state_contains: String

  """All values ending with the given string."""
  state_ends_with: String

  """All values that are contained in given list."""
  state_in: [String]

  """Any other value that exists and is not equal to the given value."""
  state_not: String

  """All values not containing the given string."""
  state_not_contains: String

  """All values not ending with the given string"""
  state_not_ends_with: String

  """All values that are not contained in given list."""
  state_not_in: [String]

  """All values not starting with the given string."""
  state_not_starts_with: String

  """All values starting with the given string."""
  state_starts_with: String
  street: String

  """All values containing the given string."""
  street_contains: String

  """All values ending with the given string."""
  street_ends_with: String

  """All values that are contained in given list."""
  street_in: [String]

  """Any other value that exists and is not equal to the given value."""
  street_not: String

  """All values not containing the given string."""
  street_not_contains: String

  """All values not ending with the given string"""
  street_not_ends_with: String

  """All values that are not contained in given list."""
  street_not_in: [String]

  """All values not starting with the given string."""
  street_not_starts_with: String

  """All values starting with the given string."""
  street_starts_with: String
  venue: String

  """All values containing the given string."""
  venue_contains: String

  """All values ending with the given string."""
  venue_ends_with: String

  """All values that are contained in given list."""
  venue_in: [String]

  """Any other value that exists and is not equal to the given value."""
  venue_not: String

  """All values not containing the given string."""
  venue_not_contains: String

  """All values not ending with the given string"""
  venue_not_ends_with: String

  """All values that are not contained in given list."""
  venue_not_in: [String]

  """All values not starting with the given string."""
  venue_not_starts_with: String

  """All values starting with the given string."""
  venue_starts_with: String
}

"""References LocationAddress record uniquely"""
input LocationAddressWhereUniqueInput {
  id: ID
}

"""Input for a geolocation point with latitude and longitude"""
input LocationInput {
  latitude: Float!
  longitude: Float!
}

"""
The Long scalar type represents non-fractional signed whole numeric values. Long can represent values between -(2^63) and 2^63 - 1.
"""
scalar Long

"""An object with an ID"""
interface Node {
  """The id of the object."""
  id: ID!

  """The Stage of an object"""
  stage: Stage!
}

"""
An organizer is an entity that launch events and handle the pass benefits.
"""
type Organizer implements Entity & Node {
  """The time the document was created"""
  createdAt(
    """
    Variation of DateTime field to return, allows value from base document, current localization, or combined by returning the newer value of both
    """
    variation: SystemDateTimeFieldVariation! = COMBINED
  ): DateTime!

  """User that created this document"""
  createdBy(
    """
    Sets the locale of the resolved parent document as the only locale in the query's subtree.
    
    Note that `createdBy` is a model without localized fields and will not be affected directly by this argument, however the locale will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `createdBy` is a model without localized fields and will not be affected directly by this argument, however the locales will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
  ): User
  description: OrganizerDescriptionRichText

  """
  The discord widge id of the organizer. You need to enable the widget in your discord server and copy the value in `server id`. For details instruction of how to enable and find the id, refer to this section https://dev.fandom.com/wiki/DiscordIntegrator#Enabling_the_widget
  """
  discordWidgetId: String

  """Get the document in other stages"""
  documentInStages(
    """Decides if the current stage should be included or not"""
    includeCurrent: Boolean! = false

    """
    Decides if the documents should match the parent documents locale or should use the fallback order defined in the tree
    """
    inheritLocale: Boolean! = false

    """Potential stages that should be returned"""
    stages: [Stage!]! = [DRAFT, PUBLISHED]
  ): [Organizer!]!
  events(
    after: String
    before: String
    first: Int

    """
    Sets the locale of the parent document as the first locale in the fallback locales in the query's subtree.
    
    Note that `events` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, localized entries that do not have the provided locale defined will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean
    last: Int

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `events` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, localized entries that do not have the provided locale defined will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
    orderBy: EventOrderByInput
    skip: Int
    where: EventWhereInput
  ): [Event!]!

  """
  The facebook handle (username) of the organizer. You can just copy the text on your facebook landing page on the URL, like 'johndoe' for 'https://www.facebook.com/johndoe'.
  """
  facebookHandle: String

  """
  An hero image that will displayed on a rectangular format. The image need to be high quality in order to display well on every screen.
  """
  heroImage(
    """
    Sets the locale of the parent document as the first locale in the fallback locales in the query's subtree.
    
    Note that `heroImage` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, localized entries that do not have the provided locale defined will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `heroImage` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, localized entries that do not have the provided locale defined will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
  ): Asset!

  """
  Optional field used to style your image with classes. Every classes from tailwind are supported. This is typically useful to adapt your image with light and dark mode (for instance using filter contrast or invert, https://tailwindcss.com/docs/contrast)
  """
  heroImageClasses: String

  """List of Organizer versions"""
  history(
    limit: Int! = 10
    skip: Int! = 0

    """
    This is optional and can be used to fetch the document version history for a specific stage instead of the current one
    """
    stageOverride: Stage
  ): [Version!]!

  """The unique identifier"""
  id: ID!

  """
  Image that represent the organizer, typically its logo. Advised resolution is 350 x 350 pixels, in square format with transparency (for ex: svg or png but not jpg) so that the image always look good either on light or dark mode.
  """
  image(
    """
    Sets the locale of the parent document as the first locale in the fallback locales in the query's subtree.
    
    Note that `image` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, localized entries that do not have the provided locale defined will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `image` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, localized entries that do not have the provided locale defined will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
  ): Asset!

  """
  Optional field used to style your image with classes. Every classes from tailwind are supported. This is typically useful to adapt your image with light and dark mode (for instance using filter contrast or invert, https://tailwindcss.com/docs/contrast)
  """
  imageClasses: String

  """
  The instagram handle (username) of the organizer. You can just copy the name on your instagram landing page next to the follow button.
  """
  instagramHandle: String

  """System Locale field"""
  locale: Locale!

  """Get the other localizations for this document"""
  localizations(
    """Decides if the current locale should be included or not"""
    includeCurrent: Boolean! = false

    """
    Potential locales that should be returned. 
    
    The order of locales will also override locale fall-backing behaviour in the query's subtree.
    
    Note any related model with localized fields in the query's subtree will be affected.
    The first locale matching the provided list will be returned, localized entries that do not have the provided locale defined will be filtered out.
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    
    Consider using this in conjunction with forceParentLocale on the children relation fields.
    """
    locales: [Locale!]! = [en, fr]
  ): [Organizer!]!

  """Name of the organizer"""
  name: String!

  """The time the document was published. Null on documents in draft stage."""
  publishedAt(
    """
    Variation of DateTime field to return, allows value from base document, current localization, or combined by returning the newer value of both
    """
    variation: SystemDateTimeFieldVariation! = COMBINED
  ): DateTime

  """User that last published this document"""
  publishedBy(
    """
    Sets the locale of the resolved parent document as the only locale in the query's subtree.
    
    Note that `publishedBy` is a model without localized fields and will not be affected directly by this argument, however the locale will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `publishedBy` is a model without localized fields and will not be affected directly by this argument, however the locales will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
  ): User
  scheduledIn(
    after: String
    before: String
    first: Int

    """
    Sets the locale of the resolved parent document as the only locale in the query's subtree.
    
    Note that `scheduledIn` is a model without localized fields and will not be affected directly by this argument, however the locale will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean
    last: Int

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `scheduledIn` is a model without localized fields and will not be affected directly by this argument, however the locales will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
    skip: Int
    where: ScheduledOperationWhereInput
  ): [ScheduledOperation!]!

  """Used in URL"""
  slug: String!

  """System stage field"""
  stage: Stage!

  """
  The telegram handle (username) of the organizer. You can just copy the text on your telegram profile page in parameters after the @, like 'johndoe' for '@johndoe'.
  """
  telegramHandle: String

  """
  The tiktok handle (username) of the organizer. You can just copy the name on your tiktok landing page.
  """
  tiktokHandle: String

  """
  The twitter (X) handle (username) of the organizer. You can just copy the text on your twitter landing page after the @, like 'johndoe' for '@johndoe'.
  """
  twitterHandle: String

  """The time the document was updated"""
  updatedAt(
    """
    Variation of DateTime field to return, allows value from base document, current localization, or combined by returning the newer value of both
    """
    variation: SystemDateTimeFieldVariation! = COMBINED
  ): DateTime!

  """User that last updated this document"""
  updatedBy(
    """
    Sets the locale of the resolved parent document as the only locale in the query's subtree.
    
    Note that `updatedBy` is a model without localized fields and will not be affected directly by this argument, however the locale will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `updatedBy` is a model without localized fields and will not be affected directly by this argument, however the locales will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
  ): User

  """
  The youtube handle (username) of the organizer. YYou can just copy the text on your youtube landing page after the @, like 'johndoe' for '@johndoe'.
  """
  youtubeHandle: String
}

input OrganizerConnectInput {
  """
  Allow to specify document position in list of connected documents, will default to appending at end of list
  """
  position: ConnectPositionInput

  """Document to connect"""
  where: OrganizerWhereUniqueInput!
}

"""A connection to a list of items."""
type OrganizerConnection {
  aggregate: Aggregate!

  """A list of edges."""
  edges: [OrganizerEdge!]!

  """Information to aid in pagination."""
  pageInfo: PageInfo!
}

input OrganizerCreateInput {
  createdAt: DateTime

  """description input for default locale (en)"""
  description: RichTextAST
  discordWidgetId: String
  events: EventCreateManyInlineInput
  facebookHandle: String
  heroImage: AssetCreateOneInlineInput!
  heroImageClasses: String
  image: AssetCreateOneInlineInput!
  imageClasses: String
  instagramHandle: String

  """
  Inline mutations for managing document localizations excluding the default locale
  """
  localizations: OrganizerCreateLocalizationsInput
  name: String!
  slug: String!
  telegramHandle: String
  tiktokHandle: String
  twitterHandle: String
  updatedAt: DateTime
  youtubeHandle: String
}

input OrganizerCreateLocalizationDataInput {
  createdAt: DateTime
  description: RichTextAST
  updatedAt: DateTime
}

input OrganizerCreateLocalizationInput {
  """Localization input"""
  data: OrganizerCreateLocalizationDataInput!
  locale: Locale!
}

input OrganizerCreateLocalizationsInput {
  """Create localizations for the newly-created document"""
  create: [OrganizerCreateLocalizationInput!]
}

input OrganizerCreateManyInlineInput {
  """Connect multiple existing Organizer documents"""
  connect: [OrganizerWhereUniqueInput!]

  """Create and connect multiple existing Organizer documents"""
  create: [OrganizerCreateInput!]
}

input OrganizerCreateOneInlineInput {
  """Connect one existing Organizer document"""
  connect: OrganizerWhereUniqueInput

  """Create and connect one Organizer document"""
  create: OrganizerCreateInput
}

type OrganizerDescriptionRichText {
  """Returns HTMl representation"""
  html: String!
  json: RichTextAST!

  """Returns Markdown representation"""
  markdown: String!
  raw: RichTextAST!
  references(after: String, before: String, first: Int, last: Int, skip: Int): [OrganizerDescriptionRichTextEmbeddedTypes!]!

  """Returns plain-text contents of RichText"""
  text: String!
}

union OrganizerDescriptionRichTextEmbeddedTypes = Asset

"""An edge in a connection."""
type OrganizerEdge {
  """A cursor for use in pagination."""
  cursor: String!

  """The item at the end of the edge."""
  node: Organizer!
}

"""Identifies documents"""
input OrganizerManyWhereInput {
  """Logical AND on all given filters."""
  AND: [OrganizerWhereInput!]

  """Logical NOT on all given filters combined by AND."""
  NOT: [OrganizerWhereInput!]

  """Logical OR on all given filters."""
  OR: [OrganizerWhereInput!]

  """Contains search across all appropriate fields."""
  _search: String
  createdAt: DateTime

  """All values greater than the given value."""
  createdAt_gt: DateTime

  """All values greater than or equal the given value."""
  createdAt_gte: DateTime

  """All values that are contained in given list."""
  createdAt_in: [DateTime]

  """All values less than the given value."""
  createdAt_lt: DateTime

  """All values less than or equal the given value."""
  createdAt_lte: DateTime

  """Any other value that exists and is not equal to the given value."""
  createdAt_not: DateTime

  """All values that are not contained in given list."""
  createdAt_not_in: [DateTime]
  createdBy: UserWhereInput
  discordWidgetId: String

  """All values containing the given string."""
  discordWidgetId_contains: String

  """All values ending with the given string."""
  discordWidgetId_ends_with: String

  """All values that are contained in given list."""
  discordWidgetId_in: [String]

  """Any other value that exists and is not equal to the given value."""
  discordWidgetId_not: String

  """All values not containing the given string."""
  discordWidgetId_not_contains: String

  """All values not ending with the given string"""
  discordWidgetId_not_ends_with: String

  """All values that are not contained in given list."""
  discordWidgetId_not_in: [String]

  """All values not starting with the given string."""
  discordWidgetId_not_starts_with: String

  """All values starting with the given string."""
  discordWidgetId_starts_with: String
  documentInStages_every: OrganizerWhereStageInput
  documentInStages_none: OrganizerWhereStageInput
  documentInStages_some: OrganizerWhereStageInput
  events_every: EventWhereInput
  events_none: EventWhereInput
  events_some: EventWhereInput
  facebookHandle: String

  """All values containing the given string."""
  facebookHandle_contains: String

  """All values ending with the given string."""
  facebookHandle_ends_with: String

  """All values that are contained in given list."""
  facebookHandle_in: [String]

  """Any other value that exists and is not equal to the given value."""
  facebookHandle_not: String

  """All values not containing the given string."""
  facebookHandle_not_contains: String

  """All values not ending with the given string"""
  facebookHandle_not_ends_with: String

  """All values that are not contained in given list."""
  facebookHandle_not_in: [String]

  """All values not starting with the given string."""
  facebookHandle_not_starts_with: String

  """All values starting with the given string."""
  facebookHandle_starts_with: String
  heroImage: AssetWhereInput
  heroImageClasses: String

  """All values containing the given string."""
  heroImageClasses_contains: String

  """All values ending with the given string."""
  heroImageClasses_ends_with: String

  """All values that are contained in given list."""
  heroImageClasses_in: [String]

  """Any other value that exists and is not equal to the given value."""
  heroImageClasses_not: String

  """All values not containing the given string."""
  heroImageClasses_not_contains: String

  """All values not ending with the given string"""
  heroImageClasses_not_ends_with: String

  """All values that are not contained in given list."""
  heroImageClasses_not_in: [String]

  """All values not starting with the given string."""
  heroImageClasses_not_starts_with: String

  """All values starting with the given string."""
  heroImageClasses_starts_with: String
  id: ID

  """All values containing the given string."""
  id_contains: ID

  """All values ending with the given string."""
  id_ends_with: ID

  """All values that are contained in given list."""
  id_in: [ID]

  """Any other value that exists and is not equal to the given value."""
  id_not: ID

  """All values not containing the given string."""
  id_not_contains: ID

  """All values not ending with the given string"""
  id_not_ends_with: ID

  """All values that are not contained in given list."""
  id_not_in: [ID]

  """All values not starting with the given string."""
  id_not_starts_with: ID

  """All values starting with the given string."""
  id_starts_with: ID
  image: AssetWhereInput
  imageClasses: String

  """All values containing the given string."""
  imageClasses_contains: String

  """All values ending with the given string."""
  imageClasses_ends_with: String

  """All values that are contained in given list."""
  imageClasses_in: [String]

  """Any other value that exists and is not equal to the given value."""
  imageClasses_not: String

  """All values not containing the given string."""
  imageClasses_not_contains: String

  """All values not ending with the given string"""
  imageClasses_not_ends_with: String

  """All values that are not contained in given list."""
  imageClasses_not_in: [String]

  """All values not starting with the given string."""
  imageClasses_not_starts_with: String

  """All values starting with the given string."""
  imageClasses_starts_with: String
  instagramHandle: String

  """All values containing the given string."""
  instagramHandle_contains: String

  """All values ending with the given string."""
  instagramHandle_ends_with: String

  """All values that are contained in given list."""
  instagramHandle_in: [String]

  """Any other value that exists and is not equal to the given value."""
  instagramHandle_not: String

  """All values not containing the given string."""
  instagramHandle_not_contains: String

  """All values not ending with the given string"""
  instagramHandle_not_ends_with: String

  """All values that are not contained in given list."""
  instagramHandle_not_in: [String]

  """All values not starting with the given string."""
  instagramHandle_not_starts_with: String

  """All values starting with the given string."""
  instagramHandle_starts_with: String
  name: String

  """All values containing the given string."""
  name_contains: String

  """All values ending with the given string."""
  name_ends_with: String

  """All values that are contained in given list."""
  name_in: [String]

  """Any other value that exists and is not equal to the given value."""
  name_not: String

  """All values not containing the given string."""
  name_not_contains: String

  """All values not ending with the given string"""
  name_not_ends_with: String

  """All values that are not contained in given list."""
  name_not_in: [String]

  """All values not starting with the given string."""
  name_not_starts_with: String

  """All values starting with the given string."""
  name_starts_with: String
  publishedAt: DateTime

  """All values greater than the given value."""
  publishedAt_gt: DateTime

  """All values greater than or equal the given value."""
  publishedAt_gte: DateTime

  """All values that are contained in given list."""
  publishedAt_in: [DateTime]

  """All values less than the given value."""
  publishedAt_lt: DateTime

  """All values less than or equal the given value."""
  publishedAt_lte: DateTime

  """Any other value that exists and is not equal to the given value."""
  publishedAt_not: DateTime

  """All values that are not contained in given list."""
  publishedAt_not_in: [DateTime]
  publishedBy: UserWhereInput
  scheduledIn_every: ScheduledOperationWhereInput
  scheduledIn_none: ScheduledOperationWhereInput
  scheduledIn_some: ScheduledOperationWhereInput
  slug: String

  """All values containing the given string."""
  slug_contains: String

  """All values ending with the given string."""
  slug_ends_with: String

  """All values that are contained in given list."""
  slug_in: [String]

  """Any other value that exists and is not equal to the given value."""
  slug_not: String

  """All values not containing the given string."""
  slug_not_contains: String

  """All values not ending with the given string"""
  slug_not_ends_with: String

  """All values that are not contained in given list."""
  slug_not_in: [String]

  """All values not starting with the given string."""
  slug_not_starts_with: String

  """All values starting with the given string."""
  slug_starts_with: String
  telegramHandle: String

  """All values containing the given string."""
  telegramHandle_contains: String

  """All values ending with the given string."""
  telegramHandle_ends_with: String

  """All values that are contained in given list."""
  telegramHandle_in: [String]

  """Any other value that exists and is not equal to the given value."""
  telegramHandle_not: String

  """All values not containing the given string."""
  telegramHandle_not_contains: String

  """All values not ending with the given string"""
  telegramHandle_not_ends_with: String

  """All values that are not contained in given list."""
  telegramHandle_not_in: [String]

  """All values not starting with the given string."""
  telegramHandle_not_starts_with: String

  """All values starting with the given string."""
  telegramHandle_starts_with: String
  tiktokHandle: String

  """All values containing the given string."""
  tiktokHandle_contains: String

  """All values ending with the given string."""
  tiktokHandle_ends_with: String

  """All values that are contained in given list."""
  tiktokHandle_in: [String]

  """Any other value that exists and is not equal to the given value."""
  tiktokHandle_not: String

  """All values not containing the given string."""
  tiktokHandle_not_contains: String

  """All values not ending with the given string"""
  tiktokHandle_not_ends_with: String

  """All values that are not contained in given list."""
  tiktokHandle_not_in: [String]

  """All values not starting with the given string."""
  tiktokHandle_not_starts_with: String

  """All values starting with the given string."""
  tiktokHandle_starts_with: String
  twitterHandle: String

  """All values containing the given string."""
  twitterHandle_contains: String

  """All values ending with the given string."""
  twitterHandle_ends_with: String

  """All values that are contained in given list."""
  twitterHandle_in: [String]

  """Any other value that exists and is not equal to the given value."""
  twitterHandle_not: String

  """All values not containing the given string."""
  twitterHandle_not_contains: String

  """All values not ending with the given string"""
  twitterHandle_not_ends_with: String

  """All values that are not contained in given list."""
  twitterHandle_not_in: [String]

  """All values not starting with the given string."""
  twitterHandle_not_starts_with: String

  """All values starting with the given string."""
  twitterHandle_starts_with: String
  updatedAt: DateTime

  """All values greater than the given value."""
  updatedAt_gt: DateTime

  """All values greater than or equal the given value."""
  updatedAt_gte: DateTime

  """All values that are contained in given list."""
  updatedAt_in: [DateTime]

  """All values less than the given value."""
  updatedAt_lt: DateTime

  """All values less than or equal the given value."""
  updatedAt_lte: DateTime

  """Any other value that exists and is not equal to the given value."""
  updatedAt_not: DateTime

  """All values that are not contained in given list."""
  updatedAt_not_in: [DateTime]
  updatedBy: UserWhereInput
  youtubeHandle: String

  """All values containing the given string."""
  youtubeHandle_contains: String

  """All values ending with the given string."""
  youtubeHandle_ends_with: String

  """All values that are contained in given list."""
  youtubeHandle_in: [String]

  """Any other value that exists and is not equal to the given value."""
  youtubeHandle_not: String

  """All values not containing the given string."""
  youtubeHandle_not_contains: String

  """All values not ending with the given string"""
  youtubeHandle_not_ends_with: String

  """All values that are not contained in given list."""
  youtubeHandle_not_in: [String]

  """All values not starting with the given string."""
  youtubeHandle_not_starts_with: String

  """All values starting with the given string."""
  youtubeHandle_starts_with: String
}

enum OrganizerOrderByInput {
  createdAt_ASC
  createdAt_DESC
  discordWidgetId_ASC
  discordWidgetId_DESC
  facebookHandle_ASC
  facebookHandle_DESC
  heroImageClasses_ASC
  heroImageClasses_DESC
  id_ASC
  id_DESC
  imageClasses_ASC
  imageClasses_DESC
  instagramHandle_ASC
  instagramHandle_DESC
  name_ASC
  name_DESC
  publishedAt_ASC
  publishedAt_DESC
  slug_ASC
  slug_DESC
  telegramHandle_ASC
  telegramHandle_DESC
  tiktokHandle_ASC
  tiktokHandle_DESC
  twitterHandle_ASC
  twitterHandle_DESC
  updatedAt_ASC
  updatedAt_DESC
  youtubeHandle_ASC
  youtubeHandle_DESC
}

input OrganizerUpdateInput {
  """description input for default locale (en)"""
  description: RichTextAST
  discordWidgetId: String
  events: EventUpdateManyInlineInput
  facebookHandle: String
  heroImage: AssetUpdateOneInlineInput
  heroImageClasses: String
  image: AssetUpdateOneInlineInput
  imageClasses: String
  instagramHandle: String

  """Manage document localizations"""
  localizations: OrganizerUpdateLocalizationsInput
  name: String
  slug: String
  telegramHandle: String
  tiktokHandle: String
  twitterHandle: String
  youtubeHandle: String
}

input OrganizerUpdateLocalizationDataInput {
  description: RichTextAST
}

input OrganizerUpdateLocalizationInput {
  data: OrganizerUpdateLocalizationDataInput!
  locale: Locale!
}

input OrganizerUpdateLocalizationsInput {
  """Localizations to create"""
  create: [OrganizerCreateLocalizationInput!]

  """Localizations to delete"""
  delete: [Locale!]

  """Localizations to update"""
  update: [OrganizerUpdateLocalizationInput!]
  upsert: [OrganizerUpsertLocalizationInput!]
}

input OrganizerUpdateManyInlineInput {
  """Connect multiple existing Organizer documents"""
  connect: [OrganizerConnectInput!]

  """Create and connect multiple Organizer documents"""
  create: [OrganizerCreateInput!]

  """Delete multiple Organizer documents"""
  delete: [OrganizerWhereUniqueInput!]

  """Disconnect multiple Organizer documents"""
  disconnect: [OrganizerWhereUniqueInput!]

  """
  Override currently-connected documents with multiple existing Organizer documents
  """
  set: [OrganizerWhereUniqueInput!]

  """Update multiple Organizer documents"""
  update: [OrganizerUpdateWithNestedWhereUniqueInput!]

  """Upsert multiple Organizer documents"""
  upsert: [OrganizerUpsertWithNestedWhereUniqueInput!]
}

input OrganizerUpdateManyInput {
  """description input for default locale (en)"""
  description: RichTextAST
  discordWidgetId: String
  facebookHandle: String
  heroImageClasses: String
  imageClasses: String
  instagramHandle: String

  """Optional updates to localizations"""
  localizations: OrganizerUpdateManyLocalizationsInput
  telegramHandle: String
  tiktokHandle: String
  twitterHandle: String
  youtubeHandle: String
}

input OrganizerUpdateManyLocalizationDataInput {
  description: RichTextAST
}

input OrganizerUpdateManyLocalizationInput {
  data: OrganizerUpdateManyLocalizationDataInput!
  locale: Locale!
}

input OrganizerUpdateManyLocalizationsInput {
  """Localizations to update"""
  update: [OrganizerUpdateManyLocalizationInput!]
}

input OrganizerUpdateOneInlineInput {
  """Connect existing Organizer document"""
  connect: OrganizerWhereUniqueInput

  """Create and connect one Organizer document"""
  create: OrganizerCreateInput

  """Delete currently connected Organizer document"""
  delete: Boolean

  """Disconnect currently connected Organizer document"""
  disconnect: Boolean

  """Update single Organizer document"""
  update: OrganizerUpdateWithNestedWhereUniqueInput

  """Upsert single Organizer document"""
  upsert: OrganizerUpsertWithNestedWhereUniqueInput
}

input OrganizerUpdateWithNestedWhereUniqueInput {
  """Document to update"""
  data: OrganizerUpdateInput!

  """Unique document search"""
  where: OrganizerWhereUniqueInput!
}

input OrganizerUpsertInput {
  """Create document if it didn't exist"""
  create: OrganizerCreateInput!

  """Update document if it exists"""
  update: OrganizerUpdateInput!
}

input OrganizerUpsertLocalizationInput {
  create: OrganizerCreateLocalizationDataInput!
  locale: Locale!
  update: OrganizerUpdateLocalizationDataInput!
}

input OrganizerUpsertWithNestedWhereUniqueInput {
  """Upsert data"""
  data: OrganizerUpsertInput!

  """Unique document search"""
  where: OrganizerWhereUniqueInput!
}

"""
This contains a set of filters that can be used to compare values internally
"""
input OrganizerWhereComparatorInput {
  """
  This field can be used to request to check if the entry is outdated by internal comparison
  """
  outdated_to: Boolean
}

"""Identifies documents"""
input OrganizerWhereInput {
  """Logical AND on all given filters."""
  AND: [OrganizerWhereInput!]

  """Logical NOT on all given filters combined by AND."""
  NOT: [OrganizerWhereInput!]

  """Logical OR on all given filters."""
  OR: [OrganizerWhereInput!]

  """Contains search across all appropriate fields."""
  _search: String
  createdAt: DateTime

  """All values greater than the given value."""
  createdAt_gt: DateTime

  """All values greater than or equal the given value."""
  createdAt_gte: DateTime

  """All values that are contained in given list."""
  createdAt_in: [DateTime]

  """All values less than the given value."""
  createdAt_lt: DateTime

  """All values less than or equal the given value."""
  createdAt_lte: DateTime

  """Any other value that exists and is not equal to the given value."""
  createdAt_not: DateTime

  """All values that are not contained in given list."""
  createdAt_not_in: [DateTime]
  createdBy: UserWhereInput
  discordWidgetId: String

  """All values containing the given string."""
  discordWidgetId_contains: String

  """All values ending with the given string."""
  discordWidgetId_ends_with: String

  """All values that are contained in given list."""
  discordWidgetId_in: [String]

  """Any other value that exists and is not equal to the given value."""
  discordWidgetId_not: String

  """All values not containing the given string."""
  discordWidgetId_not_contains: String

  """All values not ending with the given string"""
  discordWidgetId_not_ends_with: String

  """All values that are not contained in given list."""
  discordWidgetId_not_in: [String]

  """All values not starting with the given string."""
  discordWidgetId_not_starts_with: String

  """All values starting with the given string."""
  discordWidgetId_starts_with: String
  documentInStages_every: OrganizerWhereStageInput
  documentInStages_none: OrganizerWhereStageInput
  documentInStages_some: OrganizerWhereStageInput
  events_every: EventWhereInput
  events_none: EventWhereInput
  events_some: EventWhereInput
  facebookHandle: String

  """All values containing the given string."""
  facebookHandle_contains: String

  """All values ending with the given string."""
  facebookHandle_ends_with: String

  """All values that are contained in given list."""
  facebookHandle_in: [String]

  """Any other value that exists and is not equal to the given value."""
  facebookHandle_not: String

  """All values not containing the given string."""
  facebookHandle_not_contains: String

  """All values not ending with the given string"""
  facebookHandle_not_ends_with: String

  """All values that are not contained in given list."""
  facebookHandle_not_in: [String]

  """All values not starting with the given string."""
  facebookHandle_not_starts_with: String

  """All values starting with the given string."""
  facebookHandle_starts_with: String
  heroImage: AssetWhereInput
  heroImageClasses: String

  """All values containing the given string."""
  heroImageClasses_contains: String

  """All values ending with the given string."""
  heroImageClasses_ends_with: String

  """All values that are contained in given list."""
  heroImageClasses_in: [String]

  """Any other value that exists and is not equal to the given value."""
  heroImageClasses_not: String

  """All values not containing the given string."""
  heroImageClasses_not_contains: String

  """All values not ending with the given string"""
  heroImageClasses_not_ends_with: String

  """All values that are not contained in given list."""
  heroImageClasses_not_in: [String]

  """All values not starting with the given string."""
  heroImageClasses_not_starts_with: String

  """All values starting with the given string."""
  heroImageClasses_starts_with: String
  id: ID

  """All values containing the given string."""
  id_contains: ID

  """All values ending with the given string."""
  id_ends_with: ID

  """All values that are contained in given list."""
  id_in: [ID]

  """Any other value that exists and is not equal to the given value."""
  id_not: ID

  """All values not containing the given string."""
  id_not_contains: ID

  """All values not ending with the given string"""
  id_not_ends_with: ID

  """All values that are not contained in given list."""
  id_not_in: [ID]

  """All values not starting with the given string."""
  id_not_starts_with: ID

  """All values starting with the given string."""
  id_starts_with: ID
  image: AssetWhereInput
  imageClasses: String

  """All values containing the given string."""
  imageClasses_contains: String

  """All values ending with the given string."""
  imageClasses_ends_with: String

  """All values that are contained in given list."""
  imageClasses_in: [String]

  """Any other value that exists and is not equal to the given value."""
  imageClasses_not: String

  """All values not containing the given string."""
  imageClasses_not_contains: String

  """All values not ending with the given string"""
  imageClasses_not_ends_with: String

  """All values that are not contained in given list."""
  imageClasses_not_in: [String]

  """All values not starting with the given string."""
  imageClasses_not_starts_with: String

  """All values starting with the given string."""
  imageClasses_starts_with: String
  instagramHandle: String

  """All values containing the given string."""
  instagramHandle_contains: String

  """All values ending with the given string."""
  instagramHandle_ends_with: String

  """All values that are contained in given list."""
  instagramHandle_in: [String]

  """Any other value that exists and is not equal to the given value."""
  instagramHandle_not: String

  """All values not containing the given string."""
  instagramHandle_not_contains: String

  """All values not ending with the given string"""
  instagramHandle_not_ends_with: String

  """All values that are not contained in given list."""
  instagramHandle_not_in: [String]

  """All values not starting with the given string."""
  instagramHandle_not_starts_with: String

  """All values starting with the given string."""
  instagramHandle_starts_with: String
  name: String

  """All values containing the given string."""
  name_contains: String

  """All values ending with the given string."""
  name_ends_with: String

  """All values that are contained in given list."""
  name_in: [String]

  """Any other value that exists and is not equal to the given value."""
  name_not: String

  """All values not containing the given string."""
  name_not_contains: String

  """All values not ending with the given string"""
  name_not_ends_with: String

  """All values that are not contained in given list."""
  name_not_in: [String]

  """All values not starting with the given string."""
  name_not_starts_with: String

  """All values starting with the given string."""
  name_starts_with: String
  publishedAt: DateTime

  """All values greater than the given value."""
  publishedAt_gt: DateTime

  """All values greater than or equal the given value."""
  publishedAt_gte: DateTime

  """All values that are contained in given list."""
  publishedAt_in: [DateTime]

  """All values less than the given value."""
  publishedAt_lt: DateTime

  """All values less than or equal the given value."""
  publishedAt_lte: DateTime

  """Any other value that exists and is not equal to the given value."""
  publishedAt_not: DateTime

  """All values that are not contained in given list."""
  publishedAt_not_in: [DateTime]
  publishedBy: UserWhereInput
  scheduledIn_every: ScheduledOperationWhereInput
  scheduledIn_none: ScheduledOperationWhereInput
  scheduledIn_some: ScheduledOperationWhereInput
  slug: String

  """All values containing the given string."""
  slug_contains: String

  """All values ending with the given string."""
  slug_ends_with: String

  """All values that are contained in given list."""
  slug_in: [String]

  """Any other value that exists and is not equal to the given value."""
  slug_not: String

  """All values not containing the given string."""
  slug_not_contains: String

  """All values not ending with the given string"""
  slug_not_ends_with: String

  """All values that are not contained in given list."""
  slug_not_in: [String]

  """All values not starting with the given string."""
  slug_not_starts_with: String

  """All values starting with the given string."""
  slug_starts_with: String
  telegramHandle: String

  """All values containing the given string."""
  telegramHandle_contains: String

  """All values ending with the given string."""
  telegramHandle_ends_with: String

  """All values that are contained in given list."""
  telegramHandle_in: [String]

  """Any other value that exists and is not equal to the given value."""
  telegramHandle_not: String

  """All values not containing the given string."""
  telegramHandle_not_contains: String

  """All values not ending with the given string"""
  telegramHandle_not_ends_with: String

  """All values that are not contained in given list."""
  telegramHandle_not_in: [String]

  """All values not starting with the given string."""
  telegramHandle_not_starts_with: String

  """All values starting with the given string."""
  telegramHandle_starts_with: String
  tiktokHandle: String

  """All values containing the given string."""
  tiktokHandle_contains: String

  """All values ending with the given string."""
  tiktokHandle_ends_with: String

  """All values that are contained in given list."""
  tiktokHandle_in: [String]

  """Any other value that exists and is not equal to the given value."""
  tiktokHandle_not: String

  """All values not containing the given string."""
  tiktokHandle_not_contains: String

  """All values not ending with the given string"""
  tiktokHandle_not_ends_with: String

  """All values that are not contained in given list."""
  tiktokHandle_not_in: [String]

  """All values not starting with the given string."""
  tiktokHandle_not_starts_with: String

  """All values starting with the given string."""
  tiktokHandle_starts_with: String
  twitterHandle: String

  """All values containing the given string."""
  twitterHandle_contains: String

  """All values ending with the given string."""
  twitterHandle_ends_with: String

  """All values that are contained in given list."""
  twitterHandle_in: [String]

  """Any other value that exists and is not equal to the given value."""
  twitterHandle_not: String

  """All values not containing the given string."""
  twitterHandle_not_contains: String

  """All values not ending with the given string"""
  twitterHandle_not_ends_with: String

  """All values that are not contained in given list."""
  twitterHandle_not_in: [String]

  """All values not starting with the given string."""
  twitterHandle_not_starts_with: String

  """All values starting with the given string."""
  twitterHandle_starts_with: String
  updatedAt: DateTime

  """All values greater than the given value."""
  updatedAt_gt: DateTime

  """All values greater than or equal the given value."""
  updatedAt_gte: DateTime

  """All values that are contained in given list."""
  updatedAt_in: [DateTime]

  """All values less than the given value."""
  updatedAt_lt: DateTime

  """All values less than or equal the given value."""
  updatedAt_lte: DateTime

  """Any other value that exists and is not equal to the given value."""
  updatedAt_not: DateTime

  """All values that are not contained in given list."""
  updatedAt_not_in: [DateTime]
  updatedBy: UserWhereInput
  youtubeHandle: String

  """All values containing the given string."""
  youtubeHandle_contains: String

  """All values ending with the given string."""
  youtubeHandle_ends_with: String

  """All values that are contained in given list."""
  youtubeHandle_in: [String]

  """Any other value that exists and is not equal to the given value."""
  youtubeHandle_not: String

  """All values not containing the given string."""
  youtubeHandle_not_contains: String

  """All values not ending with the given string"""
  youtubeHandle_not_ends_with: String

  """All values that are not contained in given list."""
  youtubeHandle_not_in: [String]

  """All values not starting with the given string."""
  youtubeHandle_not_starts_with: String

  """All values starting with the given string."""
  youtubeHandle_starts_with: String
}

"""
The document in stages filter allows specifying a stage entry to cross compare the same document between different stages
"""
input OrganizerWhereStageInput {
  """Logical AND on all given filters."""
  AND: [OrganizerWhereStageInput!]

  """Logical NOT on all given filters combined by AND."""
  NOT: [OrganizerWhereStageInput!]

  """Logical OR on all given filters."""
  OR: [OrganizerWhereStageInput!]

  """
  This field contains fields which can be set as true or false to specify an internal comparison
  """
  compareWithParent: OrganizerWhereComparatorInput

  """Specify the stage to compare with"""
  stage: Stage
}

"""References Organizer record uniquely"""
input OrganizerWhereUniqueInput {
  id: ID
  name: String
  slug: String
}

"""References Organizer record uniquely"""
input OrganizerWhereUniqueInput_remote_rel_eventParametersorganizer {
  name: String
  slug: String
}

"""References Organizer record uniquely"""
input OrganizerWhereUniqueInput_remote_rel_eventPassNftorganizer {
  name: String
  slug: String
}

"""References Organizer record uniquely"""
input OrganizerWhereUniqueInput_remote_rel_roleAssignmentsorganizer {
  name: String
  slug: String
}

"""Information about pagination in a connection."""
type PageInfo {
  """When paginating forwards, the cursor to continue."""
  endCursor: String

  """When paginating forwards, are there more items?"""
  hasNextPage: Boolean!

  """When paginating backwards, are there more items?"""
  hasPreviousPage: Boolean!

  """Number of items in the current page."""
  pageSize: Int

  """When paginating backwards, the cursor to continue."""
  startCursor: String
}

"""
Define the options of an 'Event Pass' on an 'Event Date Location'. You can define severals if the event have multiple locations.
"""
type PassOption implements Entity {
  """
  Description of the option, like "Access to the event on Day 1"
  """
  description: String

  """
  Define the location and date for this option.
  Important ! It will determine the release and availability for the Pass access.
  """
  eventDateLocation(
    """
    Sets the locale of the resolved parent document as the only locale in the query's subtree.
    
    Note that `eventDateLocation` is a model without localized fields and will not be affected directly by this argument, however the locale will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `eventDateLocation` is a model without localized fields and will not be affected directly by this argument, however the locales will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
  ): EventDateLocation

  """The unique identifier"""
  id: ID!

  """System Locale field"""
  locale: Locale!

  """Get the other localizations for this document"""
  localizations(
    """Decides if the current locale should be included or not"""
    includeCurrent: Boolean! = false

    """
    Potential locales that should be returned. 
    
    The order of locales will also override locale fall-backing behaviour in the query's subtree.
    
    Note any related model with localized fields in the query's subtree will be affected.
    The first locale matching the provided list will be returned, localized entries that do not have the provided locale defined will be filtered out.
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    
    Consider using this in conjunction with forceParentLocale on the children relation fields.
    """
    locales: [Locale!]! = [en, fr]
  ): [PassOption!]!

  """
  Name of the options, like "Day 1 Access" or "VIP Room Access"
  """
  name: String!

  """System stage field"""
  stage: Stage!
}

input PassOptionCreateInput {
  """description input for default locale (en)"""
  description: String
  eventDateLocation: EventDateLocationCreateOneInlineInput

  """
  Inline mutations for managing document localizations excluding the default locale
  """
  localizations: PassOptionCreateLocalizationsInput

  """name input for default locale (en)"""
  name: String!
}

input PassOptionCreateLocalizationDataInput {
  description: String
  name: String!
}

input PassOptionCreateLocalizationInput {
  """Localization input"""
  data: PassOptionCreateLocalizationDataInput!
  locale: Locale!
}

input PassOptionCreateLocalizationsInput {
  """Create localizations for the newly-created document"""
  create: [PassOptionCreateLocalizationInput!]
}

input PassOptionCreateManyInlineInput {
  """Create and connect multiple existing PassOption documents"""
  create: [PassOptionCreateInput!]
}

input PassOptionCreateWithPositionInput {
  """Document to create"""
  data: PassOptionCreateInput!

  """
  Position in the list of existing component instances, will default to appending at the end of list
  """
  position: ConnectPositionInput
}

enum PassOptionOrderByInput {
  description_ASC
  description_DESC
  id_ASC
  id_DESC
  name_ASC
  name_DESC
}

input PassOptionUpdateInput {
  """description input for default locale (en)"""
  description: String
  eventDateLocation: EventDateLocationUpdateOneInlineInput

  """Manage document localizations"""
  localizations: PassOptionUpdateLocalizationsInput

  """name input for default locale (en)"""
  name: String
}

input PassOptionUpdateLocalizationDataInput {
  description: String
  name: String
}

input PassOptionUpdateLocalizationInput {
  data: PassOptionUpdateLocalizationDataInput!
  locale: Locale!
}

input PassOptionUpdateLocalizationsInput {
  """Localizations to create"""
  create: [PassOptionCreateLocalizationInput!]

  """Localizations to delete"""
  delete: [Locale!]

  """Localizations to update"""
  update: [PassOptionUpdateLocalizationInput!]
  upsert: [PassOptionUpsertLocalizationInput!]
}

input PassOptionUpdateManyInlineInput {
  """Create and connect multiple PassOption component instances"""
  create: [PassOptionCreateWithPositionInput!]

  """Delete multiple PassOption documents"""
  delete: [PassOptionWhereUniqueInput!]

  """Update multiple PassOption component instances"""
  update: [PassOptionUpdateWithNestedWhereUniqueAndPositionInput!]

  """Upsert multiple PassOption component instances"""
  upsert: [PassOptionUpsertWithNestedWhereUniqueAndPositionInput!]
}

input PassOptionUpdateWithNestedWhereUniqueAndPositionInput {
  """Document to update"""
  data: PassOptionUpdateInput

  """
  Position in the list of existing component instances, will default to appending at the end of list
  """
  position: ConnectPositionInput

  """Unique component instance search"""
  where: PassOptionWhereUniqueInput!
}

input PassOptionUpsertInput {
  """Create document if it didn't exist"""
  create: PassOptionCreateInput!

  """Update document if it exists"""
  update: PassOptionUpdateInput!
}

input PassOptionUpsertLocalizationInput {
  create: PassOptionCreateLocalizationDataInput!
  locale: Locale!
  update: PassOptionUpdateLocalizationDataInput!
}

input PassOptionUpsertWithNestedWhereUniqueAndPositionInput {
  """Document to upsert"""
  data: PassOptionUpsertInput

  """
  Position in the list of existing component instances, will default to appending at the end of list
  """
  position: ConnectPositionInput

  """Unique component instance search"""
  where: PassOptionWhereUniqueInput!
}

"""Identifies documents"""
input PassOptionWhereInput {
  """Logical AND on all given filters."""
  AND: [PassOptionWhereInput!]

  """Logical NOT on all given filters combined by AND."""
  NOT: [PassOptionWhereInput!]

  """Logical OR on all given filters."""
  OR: [PassOptionWhereInput!]

  """Contains search across all appropriate fields."""
  _search: String
  description: String

  """All values containing the given string."""
  description_contains: String

  """All values ending with the given string."""
  description_ends_with: String

  """All values that are contained in given list."""
  description_in: [String]

  """Any other value that exists and is not equal to the given value."""
  description_not: String

  """All values not containing the given string."""
  description_not_contains: String

  """All values not ending with the given string"""
  description_not_ends_with: String

  """All values that are not contained in given list."""
  description_not_in: [String]

  """All values not starting with the given string."""
  description_not_starts_with: String

  """All values starting with the given string."""
  description_starts_with: String
  eventDateLocation: EventDateLocationWhereInput
  id: ID

  """All values containing the given string."""
  id_contains: ID

  """All values ending with the given string."""
  id_ends_with: ID

  """All values that are contained in given list."""
  id_in: [ID]

  """Any other value that exists and is not equal to the given value."""
  id_not: ID

  """All values not containing the given string."""
  id_not_contains: ID

  """All values not ending with the given string"""
  id_not_ends_with: ID

  """All values that are not contained in given list."""
  id_not_in: [ID]

  """All values not starting with the given string."""
  id_not_starts_with: ID

  """All values starting with the given string."""
  id_starts_with: ID
  name: String

  """All values containing the given string."""
  name_contains: String

  """All values ending with the given string."""
  name_ends_with: String

  """All values that are contained in given list."""
  name_in: [String]

  """Any other value that exists and is not equal to the given value."""
  name_not: String

  """All values not containing the given string."""
  name_not_contains: String

  """All values not ending with the given string"""
  name_not_ends_with: String

  """All values that are not contained in given list."""
  name_not_in: [String]

  """All values not starting with the given string."""
  name_not_starts_with: String

  """All values starting with the given string."""
  name_starts_with: String
}

"""References PassOption record uniquely"""
input PassOptionWhereUniqueInput {
  id: ID
}

"""Slate-compatible RichText AST"""
scalar RichTextAST

"""Scheduled Operation system model"""
type ScheduledOperation implements Entity & Node {
  affectedDocuments(
    after: String
    before: String
    first: Int

    """
    Sets the locale of the resolved parent document as the only locale in the query's subtree.
    
    Note that `affectedDocuments` is a model without localized fields and will not be affected directly by this argument, however the locale will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean
    last: Int

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `affectedDocuments` is a model without localized fields and will not be affected directly by this argument, however the locales will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
    skip: Int
  ): [ScheduledOperationAffectedDocument!]!

  """The time the document was created"""
  createdAt: DateTime!

  """User that created this document"""
  createdBy(
    """
    Sets the locale of the resolved parent document as the only locale in the query's subtree.
    
    Note that `createdBy` is a model without localized fields and will not be affected directly by this argument, however the locale will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `createdBy` is a model without localized fields and will not be affected directly by this argument, however the locales will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
  ): User

  """Operation description"""
  description: String

  """Get the document in other stages"""
  documentInStages(
    """Decides if the current stage should be included or not"""
    includeCurrent: Boolean! = false

    """
    Decides if the documents should match the parent documents locale or should use the fallback order defined in the tree
    """
    inheritLocale: Boolean! = false

    """Potential stages that should be returned"""
    stages: [Stage!]! = [DRAFT, PUBLISHED]
  ): [ScheduledOperation!]!

  """Operation error message"""
  errorMessage: String

  """The unique identifier"""
  id: ID!

  """The time the document was published. Null on documents in draft stage."""
  publishedAt: DateTime

  """User that last published this document"""
  publishedBy(
    """
    Sets the locale of the resolved parent document as the only locale in the query's subtree.
    
    Note that `publishedBy` is a model without localized fields and will not be affected directly by this argument, however the locale will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `publishedBy` is a model without localized fields and will not be affected directly by this argument, however the locales will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
  ): User

  """
  Raw operation payload including all details, this field is subject to change
  """
  rawPayload: Json!

  """The release this operation is scheduled for"""
  release(
    """
    Sets the locale of the resolved parent document as the only locale in the query's subtree.
    
    Note that `release` is a model without localized fields and will not be affected directly by this argument, however the locale will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `release` is a model without localized fields and will not be affected directly by this argument, however the locales will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
  ): ScheduledRelease

  """System stage field"""
  stage: Stage!

  """operation Status"""
  status: ScheduledOperationStatus!

  """The time the document was updated"""
  updatedAt: DateTime!

  """User that last updated this document"""
  updatedBy(
    """
    Sets the locale of the resolved parent document as the only locale in the query's subtree.
    
    Note that `updatedBy` is a model without localized fields and will not be affected directly by this argument, however the locale will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `updatedBy` is a model without localized fields and will not be affected directly by this argument, however the locales will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
  ): User
}

union ScheduledOperationAffectedDocument = Asset | Event | EventPass | EventPassDelayedRevealed | Organizer

"""A connection to a list of items."""
type ScheduledOperationConnection {
  aggregate: Aggregate!

  """A list of edges."""
  edges: [ScheduledOperationEdge!]!

  """Information to aid in pagination."""
  pageInfo: PageInfo!
}

"""An edge in a connection."""
type ScheduledOperationEdge {
  """A cursor for use in pagination."""
  cursor: String!

  """The item at the end of the edge."""
  node: ScheduledOperation!
}

enum ScheduledOperationOrderByInput {
  createdAt_ASC
  createdAt_DESC
  description_ASC
  description_DESC
  errorMessage_ASC
  errorMessage_DESC
  id_ASC
  id_DESC
  publishedAt_ASC
  publishedAt_DESC
  status_ASC
  status_DESC
  updatedAt_ASC
  updatedAt_DESC
}

"""System Scheduled Operation Status"""
enum ScheduledOperationStatus {
  CANCELED
  COMPLETED
  FAILED
  IN_PROGRESS
  PENDING
}

"""Identifies documents"""
input ScheduledOperationWhereInput {
  """Logical AND on all given filters."""
  AND: [ScheduledOperationWhereInput!]

  """Logical NOT on all given filters combined by AND."""
  NOT: [ScheduledOperationWhereInput!]

  """Logical OR on all given filters."""
  OR: [ScheduledOperationWhereInput!]

  """Contains search across all appropriate fields."""
  _search: String
  createdAt: DateTime

  """All values greater than the given value."""
  createdAt_gt: DateTime

  """All values greater than or equal the given value."""
  createdAt_gte: DateTime

  """All values that are contained in given list."""
  createdAt_in: [DateTime]

  """All values less than the given value."""
  createdAt_lt: DateTime

  """All values less than or equal the given value."""
  createdAt_lte: DateTime

  """Any other value that exists and is not equal to the given value."""
  createdAt_not: DateTime

  """All values that are not contained in given list."""
  createdAt_not_in: [DateTime]
  createdBy: UserWhereInput
  description: String

  """All values containing the given string."""
  description_contains: String

  """All values ending with the given string."""
  description_ends_with: String

  """All values that are contained in given list."""
  description_in: [String]

  """Any other value that exists and is not equal to the given value."""
  description_not: String

  """All values not containing the given string."""
  description_not_contains: String

  """All values not ending with the given string"""
  description_not_ends_with: String

  """All values that are not contained in given list."""
  description_not_in: [String]

  """All values not starting with the given string."""
  description_not_starts_with: String

  """All values starting with the given string."""
  description_starts_with: String
  errorMessage: String

  """All values containing the given string."""
  errorMessage_contains: String

  """All values ending with the given string."""
  errorMessage_ends_with: String

  """All values that are contained in given list."""
  errorMessage_in: [String]

  """Any other value that exists and is not equal to the given value."""
  errorMessage_not: String

  """All values not containing the given string."""
  errorMessage_not_contains: String

  """All values not ending with the given string"""
  errorMessage_not_ends_with: String

  """All values that are not contained in given list."""
  errorMessage_not_in: [String]

  """All values not starting with the given string."""
  errorMessage_not_starts_with: String

  """All values starting with the given string."""
  errorMessage_starts_with: String
  id: ID

  """All values containing the given string."""
  id_contains: ID

  """All values ending with the given string."""
  id_ends_with: ID

  """All values that are contained in given list."""
  id_in: [ID]

  """Any other value that exists and is not equal to the given value."""
  id_not: ID

  """All values not containing the given string."""
  id_not_contains: ID

  """All values not ending with the given string"""
  id_not_ends_with: ID

  """All values that are not contained in given list."""
  id_not_in: [ID]

  """All values not starting with the given string."""
  id_not_starts_with: ID

  """All values starting with the given string."""
  id_starts_with: ID
  publishedAt: DateTime

  """All values greater than the given value."""
  publishedAt_gt: DateTime

  """All values greater than or equal the given value."""
  publishedAt_gte: DateTime

  """All values that are contained in given list."""
  publishedAt_in: [DateTime]

  """All values less than the given value."""
  publishedAt_lt: DateTime

  """All values less than or equal the given value."""
  publishedAt_lte: DateTime

  """Any other value that exists and is not equal to the given value."""
  publishedAt_not: DateTime

  """All values that are not contained in given list."""
  publishedAt_not_in: [DateTime]
  publishedBy: UserWhereInput

  """All values containing the given json path."""
  rawPayload_json_path_exists: String

  """
  Recursively tries to find the provided JSON scalar value inside the field.
  It does use an exact match when comparing values.
  If you pass `null` as value the filter will be ignored. 
  Note: This filter fails if you try to look for a non scalar JSON value!
  """
  rawPayload_value_recursive: Json
  release: ScheduledReleaseWhereInput
  status: ScheduledOperationStatus

  """All values that are contained in given list."""
  status_in: [ScheduledOperationStatus]

  """Any other value that exists and is not equal to the given value."""
  status_not: ScheduledOperationStatus

  """All values that are not contained in given list."""
  status_not_in: [ScheduledOperationStatus]
  updatedAt: DateTime

  """All values greater than the given value."""
  updatedAt_gt: DateTime

  """All values greater than or equal the given value."""
  updatedAt_gte: DateTime

  """All values that are contained in given list."""
  updatedAt_in: [DateTime]

  """All values less than the given value."""
  updatedAt_lt: DateTime

  """All values less than or equal the given value."""
  updatedAt_lte: DateTime

  """Any other value that exists and is not equal to the given value."""
  updatedAt_not: DateTime

  """All values that are not contained in given list."""
  updatedAt_not_in: [DateTime]
  updatedBy: UserWhereInput
}

"""References ScheduledOperation record uniquely"""
input ScheduledOperationWhereUniqueInput {
  id: ID
}

"""Scheduled Release system model"""
type ScheduledRelease implements Entity & Node {
  """The time the document was created"""
  createdAt: DateTime!

  """User that created this document"""
  createdBy(
    """
    Sets the locale of the resolved parent document as the only locale in the query's subtree.
    
    Note that `createdBy` is a model without localized fields and will not be affected directly by this argument, however the locale will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `createdBy` is a model without localized fields and will not be affected directly by this argument, however the locales will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
  ): User

  """Release description"""
  description: String

  """Get the document in other stages"""
  documentInStages(
    """Decides if the current stage should be included or not"""
    includeCurrent: Boolean! = false

    """
    Decides if the documents should match the parent documents locale or should use the fallback order defined in the tree
    """
    inheritLocale: Boolean! = false

    """Potential stages that should be returned"""
    stages: [Stage!]! = [DRAFT, PUBLISHED]
  ): [ScheduledRelease!]!

  """Release error message"""
  errorMessage: String

  """The unique identifier"""
  id: ID!

  """Whether scheduled release should be run"""
  isActive: Boolean!

  """Whether scheduled release is implicit"""
  isImplicit: Boolean!

  """Operations to run with this release"""
  operations(
    after: String
    before: String
    first: Int

    """
    Sets the locale of the resolved parent document as the only locale in the query's subtree.
    
    Note that `operations` is a model without localized fields and will not be affected directly by this argument, however the locale will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean
    last: Int

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `operations` is a model without localized fields and will not be affected directly by this argument, however the locales will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
    orderBy: ScheduledOperationOrderByInput
    skip: Int
    where: ScheduledOperationWhereInput
  ): [ScheduledOperation!]!

  """The time the document was published. Null on documents in draft stage."""
  publishedAt: DateTime

  """User that last published this document"""
  publishedBy(
    """
    Sets the locale of the resolved parent document as the only locale in the query's subtree.
    
    Note that `publishedBy` is a model without localized fields and will not be affected directly by this argument, however the locale will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `publishedBy` is a model without localized fields and will not be affected directly by this argument, however the locales will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
  ): User

  """Release date and time"""
  releaseAt: DateTime

  """System stage field"""
  stage: Stage!

  """Release Status"""
  status: ScheduledReleaseStatus!

  """Release Title"""
  title: String

  """The time the document was updated"""
  updatedAt: DateTime!

  """User that last updated this document"""
  updatedBy(
    """
    Sets the locale of the resolved parent document as the only locale in the query's subtree.
    
    Note that `updatedBy` is a model without localized fields and will not be affected directly by this argument, however the locale will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will affect any existing locale filtering defined in the query's tree for the subtree.
    """
    forceParentLocale: Boolean

    """
    Allows to optionally override locale filtering behaviour in the query's subtree.
    
    Note that `updatedBy` is a model without localized fields and will not be affected directly by this argument, however the locales will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument will overwrite any existing locale filtering defined in the query's tree for the subtree.
    """
    locales: [Locale!]
  ): User
}

"""A connection to a list of items."""
type ScheduledReleaseConnection {
  aggregate: Aggregate!

  """A list of edges."""
  edges: [ScheduledReleaseEdge!]!

  """Information to aid in pagination."""
  pageInfo: PageInfo!
}

input ScheduledReleaseCreateInput {
  createdAt: DateTime
  description: String
  errorMessage: String
  isActive: Boolean = true
  releaseAt: DateTime
  title: String
  updatedAt: DateTime
}

"""An edge in a connection."""
type ScheduledReleaseEdge {
  """A cursor for use in pagination."""
  cursor: String!

  """The item at the end of the edge."""
  node: ScheduledRelease!
}

enum ScheduledReleaseOrderByInput {
  createdAt_ASC
  createdAt_DESC
  description_ASC
  description_DESC
  errorMessage_ASC
  errorMessage_DESC
  id_ASC
  id_DESC
  isActive_ASC
  isActive_DESC
  isImplicit_ASC
  isImplicit_DESC
  publishedAt_ASC
  publishedAt_DESC
  releaseAt_ASC
  releaseAt_DESC
  status_ASC
  status_DESC
  title_ASC
  title_DESC
  updatedAt_ASC
  updatedAt_DESC
}

"""System Scheduled Release Status"""
enum ScheduledReleaseStatus {
  COMPLETED
  FAILED
  IN_PROGRESS
  PENDING
}

input ScheduledReleaseUpdateInput {
  description: String
  errorMessage: String
  isActive: Boolean
  releaseAt: DateTime
  title: String
}

"""Identifies documents"""
input ScheduledReleaseWhereInput {
  """Logical AND on all given filters."""
  AND: [ScheduledReleaseWhereInput!]

  """Logical NOT on all given filters combined by AND."""
  NOT: [ScheduledReleaseWhereInput!]

  """Logical OR on all given filters."""
  OR: [ScheduledReleaseWhereInput!]

  """Contains search across all appropriate fields."""
  _search: String
  createdAt: DateTime

  """All values greater than the given value."""
  createdAt_gt: DateTime

  """All values greater than or equal the given value."""
  createdAt_gte: DateTime

  """All values that are contained in given list."""
  createdAt_in: [DateTime]

  """All values less than the given value."""
  createdAt_lt: DateTime

  """All values less than or equal the given value."""
  createdAt_lte: DateTime

  """Any other value that exists and is not equal to the given value."""
  createdAt_not: DateTime

  """All values that are not contained in given list."""
  createdAt_not_in: [DateTime]
  createdBy: UserWhereInput
  description: String

  """All values containing the given string."""
  description_contains: String

  """All values ending with the given string."""
  description_ends_with: String

  """All values that are contained in given list."""
  description_in: [String]

  """Any other value that exists and is not equal to the given value."""
  description_not: String

  """All values not containing the given string."""
  description_not_contains: String

  """All values not ending with the given string"""
  description_not_ends_with: String

  """All values that are not contained in given list."""
  description_not_in: [String]

  """All values not starting with the given string."""
  description_not_starts_with: String

  """All values starting with the given string."""
  description_starts_with: String
  errorMessage: String

  """All values containing the given string."""
  errorMessage_contains: String

  """All values ending with the given string."""
  errorMessage_ends_with: String

  """All values that are contained in given list."""
  errorMessage_in: [String]

  """Any other value that exists and is not equal to the given value."""
  errorMessage_not: String

  """All values not containing the given string."""
  errorMessage_not_contains: String

  """All values not ending with the given string"""
  errorMessage_not_ends_with: String

  """All values that are not contained in given list."""
  errorMessage_not_in: [String]

  """All values not starting with the given string."""
  errorMessage_not_starts_with: String

  """All values starting with the given string."""
  errorMessage_starts_with: String
  id: ID

  """All values containing the given string."""
  id_contains: ID

  """All values ending with the given string."""
  id_ends_with: ID

  """All values that are contained in given list."""
  id_in: [ID]

  """Any other value that exists and is not equal to the given value."""
  id_not: ID

  """All values not containing the given string."""
  id_not_contains: ID

  """All values not ending with the given string"""
  id_not_ends_with: ID

  """All values that are not contained in given list."""
  id_not_in: [ID]

  """All values not starting with the given string."""
  id_not_starts_with: ID

  """All values starting with the given string."""
  id_starts_with: ID
  isActive: Boolean

  """Any other value that exists and is not equal to the given value."""
  isActive_not: Boolean
  isImplicit: Boolean

  """Any other value that exists and is not equal to the given value."""
  isImplicit_not: Boolean
  operations_every: ScheduledOperationWhereInput
  operations_none: ScheduledOperationWhereInput
  operations_some: ScheduledOperationWhereInput
  publishedAt: DateTime

  """All values greater than the given value."""
  publishedAt_gt: DateTime

  """All values greater than or equal the given value."""
  publishedAt_gte: DateTime

  """All values that are contained in given list."""
  publishedAt_in: [DateTime]

  """All values less than the given value."""
  publishedAt_lt: DateTime

  """All values less than or equal the given value."""
  publishedAt_lte: DateTime

  """Any other value that exists and is not equal to the given value."""
  publishedAt_not: DateTime

  """All values that are not contained in given list."""
  publishedAt_not_in: [DateTime]
  publishedBy: UserWhereInput
  releaseAt: DateTime

  """All values greater than the given value."""
  releaseAt_gt: DateTime

  """All values greater than or equal the given value."""
  releaseAt_gte: DateTime

  """All values that are contained in given list."""
  releaseAt_in: [DateTime]

  """All values less than the given value."""
  releaseAt_lt: DateTime

  """All values less than or equal the given value."""
  releaseAt_lte: DateTime

  """Any other value that exists and is not equal to the given value."""
  releaseAt_not: DateTime

  """All values that are not contained in given list."""
  releaseAt_not_in: [DateTime]
  status: ScheduledReleaseStatus

  """All values that are contained in given list."""
  status_in: [ScheduledReleaseStatus]

  """Any other value that exists and is not equal to the given value."""
  status_not: ScheduledReleaseStatus

  """All values that are not contained in given list."""
  status_not_in: [ScheduledReleaseStatus]
  title: String

  """All values containing the given string."""
  title_contains: String

  """All values ending with the given string."""
  title_ends_with: String

  """All values that are contained in given list."""
  title_in: [String]

  """Any other value that exists and is not equal to the given value."""
  title_not: String

  """All values not containing the given string."""
  title_not_contains: String

  """All values not ending with the given string"""
  title_not_ends_with: String

  """All values that are not contained in given list."""
  title_not_in: [String]

  """All values not starting with the given string."""
  title_not_starts_with: String

  """All values starting with the given string."""
  title_starts_with: String
  updatedAt: DateTime

  """All values greater than the given value."""
  updatedAt_gt: DateTime

  """All values greater than or equal the given value."""
  updatedAt_gte: DateTime

  """All values that are contained in given list."""
  updatedAt_in: [DateTime]

  """All values less than the given value."""
  updatedAt_lt: DateTime

  """All values less than or equal the given value."""
  updatedAt_lte: DateTime

  """Any other value that exists and is not equal to the given value."""
  updatedAt_not: DateTime

  """All values that are not contained in given list."""
  updatedAt_not_in: [DateTime]
  updatedBy: UserWhereInput
}

"""References ScheduledRelease record uniquely"""
input ScheduledReleaseWhereUniqueInput {
  id: ID
}

"""Stage system enumeration"""
enum Stage {
  """The Draft is the default stage for all your content."""
  DRAFT

  """The Published stage is where you can publish your content to."""
  PUBLISHED
}

"""
Boolean expression to compare columns of type "String". All fields are combined with logical 'AND'.
"""
input String_comparison_exp {
  _eq: String
  _gt: String
  _gte: String

  """does the column match the given case-insensitive pattern"""
  _ilike: String
  _in: [String!]

  """
  does the column match the given POSIX regular expression, case insensitive
  """
  _iregex: String
  _is_null: Boolean

  """does the column match the given pattern"""
  _like: String
  _lt: String
  _lte: String
  _neq: String

  """does the column NOT match the given case-insensitive pattern"""
  _nilike: String
  _nin: [String!]

  """
  does the column NOT match the given POSIX regular expression, case insensitive
  """
  _niregex: String

  """does the column NOT match the given pattern"""
  _nlike: String

  """
  does the column NOT match the given POSIX regular expression, case sensitive
  """
  _nregex: String

  """does the column NOT match the given SQL regular expression"""
  _nsimilar: String

  """
  does the column match the given POSIX regular expression, case sensitive
  """
  _regex: String

  """does the column match the given SQL regular expression"""
  _similar: String
}

enum SystemDateTimeFieldVariation {
  BASE
  COMBINED
  LOCALIZATION
}

"""User system model"""
type User implements Entity & Node {
  """The time the document was created"""
  createdAt: DateTime!

  """Get the document in other stages"""
  documentInStages(
    """Decides if the current stage should be included or not"""
    includeCurrent: Boolean! = false

    """
    Decides if the documents should match the parent documents locale or should use the fallback order defined in the tree
    """
    inheritLocale: Boolean! = false

    """Potential stages that should be returned"""
    stages: [Stage!]! = [DRAFT, PUBLISHED]
  ): [User!]!

  """The unique identifier"""
  id: ID!

  """Flag to determine if user is active or not"""
  isActive: Boolean!

  """User Kind. Can be either MEMBER, PAT or PUBLIC"""
  kind: UserKind!

  """The username"""
  name: String!

  """Profile Picture url"""
  picture: String

  """The time the document was published. Null on documents in draft stage."""
  publishedAt: DateTime

  """System stage field"""
  stage: Stage!

  """The time the document was updated"""
  updatedAt: DateTime!
}

"""A connection to a list of items."""
type UserConnection {
  aggregate: Aggregate!

  """A list of edges."""
  edges: [UserEdge!]!

  """Information to aid in pagination."""
  pageInfo: PageInfo!
}

"""An edge in a connection."""
type UserEdge {
  """A cursor for use in pagination."""
  cursor: String!

  """The item at the end of the edge."""
  node: User!
}

"""System User Kind"""
enum UserKind {
  APP_TOKEN
  MEMBER
  PAT
  PUBLIC
  WEBHOOK
}

enum UserOrderByInput {
  createdAt_ASC
  createdAt_DESC
  id_ASC
  id_DESC
  isActive_ASC
  isActive_DESC
  kind_ASC
  kind_DESC
  name_ASC
  name_DESC
  picture_ASC
  picture_DESC
  publishedAt_ASC
  publishedAt_DESC
  updatedAt_ASC
  updatedAt_DESC
}

"""
This contains a set of filters that can be used to compare values internally
"""
input UserWhereComparatorInput {
  """
  This field can be used to request to check if the entry is outdated by internal comparison
  """
  outdated_to: Boolean
}

"""Identifies documents"""
input UserWhereInput {
  """Logical AND on all given filters."""
  AND: [UserWhereInput!]

  """Logical NOT on all given filters combined by AND."""
  NOT: [UserWhereInput!]

  """Logical OR on all given filters."""
  OR: [UserWhereInput!]

  """Contains search across all appropriate fields."""
  _search: String
  createdAt: DateTime

  """All values greater than the given value."""
  createdAt_gt: DateTime

  """All values greater than or equal the given value."""
  createdAt_gte: DateTime

  """All values that are contained in given list."""
  createdAt_in: [DateTime]

  """All values less than the given value."""
  createdAt_lt: DateTime

  """All values less than or equal the given value."""
  createdAt_lte: DateTime

  """Any other value that exists and is not equal to the given value."""
  createdAt_not: DateTime

  """All values that are not contained in given list."""
  createdAt_not_in: [DateTime]
  documentInStages_every: UserWhereStageInput
  documentInStages_none: UserWhereStageInput
  documentInStages_some: UserWhereStageInput
  id: ID

  """All values containing the given string."""
  id_contains: ID

  """All values ending with the given string."""
  id_ends_with: ID

  """All values that are contained in given list."""
  id_in: [ID]

  """Any other value that exists and is not equal to the given value."""
  id_not: ID

  """All values not containing the given string."""
  id_not_contains: ID

  """All values not ending with the given string"""
  id_not_ends_with: ID

  """All values that are not contained in given list."""
  id_not_in: [ID]

  """All values not starting with the given string."""
  id_not_starts_with: ID

  """All values starting with the given string."""
  id_starts_with: ID
  isActive: Boolean

  """Any other value that exists and is not equal to the given value."""
  isActive_not: Boolean
  kind: UserKind

  """All values that are contained in given list."""
  kind_in: [UserKind]

  """Any other value that exists and is not equal to the given value."""
  kind_not: UserKind

  """All values that are not contained in given list."""
  kind_not_in: [UserKind]
  name: String

  """All values containing the given string."""
  name_contains: String

  """All values ending with the given string."""
  name_ends_with: String

  """All values that are contained in given list."""
  name_in: [String]

  """Any other value that exists and is not equal to the given value."""
  name_not: String

  """All values not containing the given string."""
  name_not_contains: String

  """All values not ending with the given string"""
  name_not_ends_with: String

  """All values that are not contained in given list."""
  name_not_in: [String]

  """All values not starting with the given string."""
  name_not_starts_with: String

  """All values starting with the given string."""
  name_starts_with: String
  picture: String

  """All values containing the given string."""
  picture_contains: String

  """All values ending with the given string."""
  picture_ends_with: String

  """All values that are contained in given list."""
  picture_in: [String]

  """Any other value that exists and is not equal to the given value."""
  picture_not: String

  """All values not containing the given string."""
  picture_not_contains: String

  """All values not ending with the given string"""
  picture_not_ends_with: String

  """All values that are not contained in given list."""
  picture_not_in: [String]

  """All values not starting with the given string."""
  picture_not_starts_with: String

  """All values starting with the given string."""
  picture_starts_with: String
  publishedAt: DateTime

  """All values greater than the given value."""
  publishedAt_gt: DateTime

  """All values greater than or equal the given value."""
  publishedAt_gte: DateTime

  """All values that are contained in given list."""
  publishedAt_in: [DateTime]

  """All values less than the given value."""
  publishedAt_lt: DateTime

  """All values less than or equal the given value."""
  publishedAt_lte: DateTime

  """Any other value that exists and is not equal to the given value."""
  publishedAt_not: DateTime

  """All values that are not contained in given list."""
  publishedAt_not_in: [DateTime]
  updatedAt: DateTime

  """All values greater than the given value."""
  updatedAt_gt: DateTime

  """All values greater than or equal the given value."""
  updatedAt_gte: DateTime

  """All values that are contained in given list."""
  updatedAt_in: [DateTime]

  """All values less than the given value."""
  updatedAt_lt: DateTime

  """All values less than or equal the given value."""
  updatedAt_lte: DateTime

  """Any other value that exists and is not equal to the given value."""
  updatedAt_not: DateTime

  """All values that are not contained in given list."""
  updatedAt_not_in: [DateTime]
}

"""
The document in stages filter allows specifying a stage entry to cross compare the same document between different stages
"""
input UserWhereStageInput {
  """Logical AND on all given filters."""
  AND: [UserWhereStageInput!]

  """Logical NOT on all given filters combined by AND."""
  NOT: [UserWhereStageInput!]

  """Logical OR on all given filters."""
  OR: [UserWhereStageInput!]

  """
  This field contains fields which can be set as true or false to specify an internal comparison
  """
  compareWithParent: UserWhereComparatorInput

  """Specify the stage to compare with"""
  stage: Stage
}

"""References User record uniquely"""
input UserWhereUniqueInput {
  id: ID
}

type Version {
  createdAt: DateTime!
  id: ID!
  revision: Int!
  stage: Stage!
}

input VersionWhereInput {
  id: ID!
  revision: Int!
  stage: Stage!
}

"""
An account can represent an user or organizer. It store essential informations and is used as the root class for relationships with other tables
"""
type account {
  address: String!
  created_at: timestamptz
  email: String
  emailVerified: Boolean!
  id: uuid!

  """An object relationship"""
  kyc: kyc

  """An array relationship"""
  roles(
    """distinct select on columns"""
    distinct_on: [roleAssignments_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [roleAssignments_order_by!]

    """filter the rows returned"""
    where: roleAssignments_bool_exp
  ): [roleAssignments!]!

  """An aggregate relationship"""
  roles_aggregate(
    """distinct select on columns"""
    distinct_on: [roleAssignments_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [roleAssignments_order_by!]

    """filter the rows returned"""
    where: roleAssignments_bool_exp
  ): roleAssignments_aggregate!

  """An object relationship"""
  stripeCustomer: stripeCustomer
  updated_at: timestamptz
}

"""
aggregated selection of "account"
"""
type account_aggregate {
  aggregate: account_aggregate_fields
  nodes: [account!]!
}

"""
aggregate fields of "account"
"""
type account_aggregate_fields {
  count(columns: [account_select_column!], distinct: Boolean): Int!
  max: account_max_fields
  min: account_min_fields
}

"""
Boolean expression to filter rows from the table "account". All fields are combined with a logical 'AND'.
"""
input account_bool_exp {
  _and: [account_bool_exp!]
  _not: account_bool_exp
  _or: [account_bool_exp!]
  address: String_comparison_exp
  created_at: timestamptz_comparison_exp
  email: String_comparison_exp
  emailVerified: Boolean_comparison_exp
  id: uuid_comparison_exp
  kyc: kyc_bool_exp
  roles: roleAssignments_bool_exp
  roles_aggregate: roleAssignments_aggregate_bool_exp
  stripeCustomer: stripeCustomer_bool_exp
  updated_at: timestamptz_comparison_exp
}

"""
unique or primary key constraints on table "account"
"""
enum account_constraint {
  """
  unique or primary key constraint on columns "address"
  """
  account_address_key

  """
  unique or primary key constraint on columns "id"
  """
  account_pkey
}

"""
input type for inserting data into table "account"
"""
input account_insert_input {
  address: String
  created_at: timestamptz
  email: String
  emailVerified: Boolean
  id: uuid
  kyc: kyc_obj_rel_insert_input
  roles: roleAssignments_arr_rel_insert_input
  stripeCustomer: stripeCustomer_obj_rel_insert_input
  updated_at: timestamptz
}

"""aggregate max on columns"""
type account_max_fields {
  address: String
  created_at: timestamptz
  email: String
  id: uuid
  updated_at: timestamptz
}

"""aggregate min on columns"""
type account_min_fields {
  address: String
  created_at: timestamptz
  email: String
  id: uuid
  updated_at: timestamptz
}

"""
response of any mutation on the table "account"
"""
type account_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [account!]!
}

"""
input type for inserting object relation for remote table "account"
"""
input account_obj_rel_insert_input {
  data: account_insert_input!

  """upsert condition"""
  on_conflict: account_on_conflict
}

"""
on_conflict condition type for table "account"
"""
input account_on_conflict {
  constraint: account_constraint!
  update_columns: [account_update_column!]! = []
  where: account_bool_exp
}

"""Ordering options when selecting data from "account"."""
input account_order_by {
  address: order_by
  created_at: order_by
  email: order_by
  emailVerified: order_by
  id: order_by
  kyc: kyc_order_by
  roles_aggregate: roleAssignments_aggregate_order_by
  stripeCustomer: stripeCustomer_order_by
  updated_at: order_by
}

"""primary key columns input for table: account"""
input account_pk_columns_input {
  id: uuid!
}

"""
select columns of table "account"
"""
enum account_select_column {
  """column name"""
  address

  """column name"""
  created_at

  """column name"""
  email

  """column name"""
  emailVerified

  """column name"""
  id

  """column name"""
  updated_at
}

"""
input type for updating data in table "account"
"""
input account_set_input {
  address: String
  created_at: timestamptz
  email: String
  emailVerified: Boolean
  id: uuid
  updated_at: timestamptz
}

"""
Streaming cursor of the table "account"
"""
input account_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: account_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input account_stream_cursor_value_input {
  address: String
  created_at: timestamptz
  email: String
  emailVerified: Boolean
  id: uuid
  updated_at: timestamptz
}

"""
update columns of table "account"
"""
enum account_update_column {
  """column name"""
  address

  """column name"""
  created_at

  """column name"""
  email

  """column name"""
  emailVerified

  """column name"""
  id

  """column name"""
  updated_at
}

input account_updates {
  """sets the columns of the filtered rows to the given values"""
  _set: account_set_input

  """filter the rows which have to be updated"""
  where: account_bool_exp!
}

"""
History of auditable actions on audited tables, from audit.if_modified_func()
"""
type audit_logged_actions {
  """Action type; I = insert, D = delete, U = update, T = truncate"""
  action: String!

  """Wall clock time at which audited event's trigger call occurred"""
  action_tstamp_clk: timestamptz!

  """Statement start timestamp for tx in which audited event occurred"""
  action_tstamp_stm: timestamptz!

  """Transaction start timestamp for tx in which audited event occurred"""
  action_tstamp_tx: timestamptz!

  """
  Application name set when this audit event occurred. Can be changed in-session by client.
  """
  application_name: String

  """
  New values of fields changed by UPDATE. Null except for row-level UPDATE events.
  """
  changed_fields(
    """JSON select path"""
    path: String
  ): jsonb

  """IP address of client that issued query. Null for unix domain socket."""
  client_addr: inet

  """
  Remote peer IP port address of client that issued query. Undefined for unix socket.
  """
  client_port: Int

  """
  Top-level query that caused this auditable event. May be more than one statement.
  """
  client_query: String

  """Unique identifier for each auditable event"""
  event_id: bigint!
  hasura_user(
    """JSON select path"""
    path: String
  ): jsonb

  """Table OID. Changes with drop/create. Get with 'tablename'::regclass"""
  relid: oid!

  """
  Record value. Null for statement-level trigger. For INSERT this is the new tuple. For DELETE and UPDATE it is the old tuple.
  """
  row_data(
    """JSON select path"""
    path: String
  ): jsonb

  """Database schema audited table for this event is in"""
  schema_name: String!

  """Login / session user whose statement caused the audited event"""
  session_user_name: String

  """
  't' if audit event is from an FOR EACH STATEMENT trigger, 'f' for FOR EACH ROW
  """
  statement_only: Boolean!

  """Non-schema-qualified table name of table event occured in"""
  table_name: String!

  """
  Identifier of transaction that made the change. May wrap, but unique paired with action_tstamp_tx.
  """
  transaction_id: bigint
}

"""
aggregated selection of "audit.logged_actions"
"""
type audit_logged_actions_aggregate {
  aggregate: audit_logged_actions_aggregate_fields
  nodes: [audit_logged_actions!]!
}

"""
aggregate fields of "audit.logged_actions"
"""
type audit_logged_actions_aggregate_fields {
  avg: audit_logged_actions_avg_fields
  count(columns: [audit_logged_actions_select_column!], distinct: Boolean): Int!
  max: audit_logged_actions_max_fields
  min: audit_logged_actions_min_fields
  stddev: audit_logged_actions_stddev_fields
  stddev_pop: audit_logged_actions_stddev_pop_fields
  stddev_samp: audit_logged_actions_stddev_samp_fields
  sum: audit_logged_actions_sum_fields
  var_pop: audit_logged_actions_var_pop_fields
  var_samp: audit_logged_actions_var_samp_fields
  variance: audit_logged_actions_variance_fields
}

"""append existing jsonb value of filtered columns with new jsonb value"""
input audit_logged_actions_append_input {
  """
  New values of fields changed by UPDATE. Null except for row-level UPDATE events.
  """
  changed_fields: jsonb
  hasura_user: jsonb

  """
  Record value. Null for statement-level trigger. For INSERT this is the new tuple. For DELETE and UPDATE it is the old tuple.
  """
  row_data: jsonb
}

"""aggregate avg on columns"""
type audit_logged_actions_avg_fields {
  """
  Remote peer IP port address of client that issued query. Undefined for unix socket.
  """
  client_port: Float

  """Unique identifier for each auditable event"""
  event_id: Float

  """
  Identifier of transaction that made the change. May wrap, but unique paired with action_tstamp_tx.
  """
  transaction_id: Float
}

"""
Boolean expression to filter rows from the table "audit.logged_actions". All fields are combined with a logical 'AND'.
"""
input audit_logged_actions_bool_exp {
  _and: [audit_logged_actions_bool_exp!]
  _not: audit_logged_actions_bool_exp
  _or: [audit_logged_actions_bool_exp!]
  action: String_comparison_exp
  action_tstamp_clk: timestamptz_comparison_exp
  action_tstamp_stm: timestamptz_comparison_exp
  action_tstamp_tx: timestamptz_comparison_exp
  application_name: String_comparison_exp
  changed_fields: jsonb_comparison_exp
  client_addr: inet_comparison_exp
  client_port: Int_comparison_exp
  client_query: String_comparison_exp
  event_id: bigint_comparison_exp
  hasura_user: jsonb_comparison_exp
  relid: oid_comparison_exp
  row_data: jsonb_comparison_exp
  schema_name: String_comparison_exp
  session_user_name: String_comparison_exp
  statement_only: Boolean_comparison_exp
  table_name: String_comparison_exp
  transaction_id: bigint_comparison_exp
}

"""
unique or primary key constraints on table "audit.logged_actions"
"""
enum audit_logged_actions_constraint {
  """
  unique or primary key constraint on columns "event_id"
  """
  logged_actions_pkey
}

"""
delete the field or element with specified path (for JSON arrays, negative integers count from the end)
"""
input audit_logged_actions_delete_at_path_input {
  """
  New values of fields changed by UPDATE. Null except for row-level UPDATE events.
  """
  changed_fields: [String!]
  hasura_user: [String!]

  """
  Record value. Null for statement-level trigger. For INSERT this is the new tuple. For DELETE and UPDATE it is the old tuple.
  """
  row_data: [String!]
}

"""
delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
"""
input audit_logged_actions_delete_elem_input {
  """
  New values of fields changed by UPDATE. Null except for row-level UPDATE events.
  """
  changed_fields: Int
  hasura_user: Int

  """
  Record value. Null for statement-level trigger. For INSERT this is the new tuple. For DELETE and UPDATE it is the old tuple.
  """
  row_data: Int
}

"""
delete key/value pair or string element. key/value pairs are matched based on their key value
"""
input audit_logged_actions_delete_key_input {
  """
  New values of fields changed by UPDATE. Null except for row-level UPDATE events.
  """
  changed_fields: String
  hasura_user: String

  """
  Record value. Null for statement-level trigger. For INSERT this is the new tuple. For DELETE and UPDATE it is the old tuple.
  """
  row_data: String
}

"""
input type for incrementing numeric columns in table "audit.logged_actions"
"""
input audit_logged_actions_inc_input {
  """
  Remote peer IP port address of client that issued query. Undefined for unix socket.
  """
  client_port: Int

  """Unique identifier for each auditable event"""
  event_id: bigint

  """
  Identifier of transaction that made the change. May wrap, but unique paired with action_tstamp_tx.
  """
  transaction_id: bigint
}

"""
input type for inserting data into table "audit.logged_actions"
"""
input audit_logged_actions_insert_input {
  """Action type; I = insert, D = delete, U = update, T = truncate"""
  action: String

  """Wall clock time at which audited event's trigger call occurred"""
  action_tstamp_clk: timestamptz

  """Statement start timestamp for tx in which audited event occurred"""
  action_tstamp_stm: timestamptz

  """Transaction start timestamp for tx in which audited event occurred"""
  action_tstamp_tx: timestamptz

  """
  Application name set when this audit event occurred. Can be changed in-session by client.
  """
  application_name: String

  """
  New values of fields changed by UPDATE. Null except for row-level UPDATE events.
  """
  changed_fields: jsonb

  """IP address of client that issued query. Null for unix domain socket."""
  client_addr: inet

  """
  Remote peer IP port address of client that issued query. Undefined for unix socket.
  """
  client_port: Int

  """
  Top-level query that caused this auditable event. May be more than one statement.
  """
  client_query: String

  """Unique identifier for each auditable event"""
  event_id: bigint
  hasura_user: jsonb

  """Table OID. Changes with drop/create. Get with 'tablename'::regclass"""
  relid: oid

  """
  Record value. Null for statement-level trigger. For INSERT this is the new tuple. For DELETE and UPDATE it is the old tuple.
  """
  row_data: jsonb

  """Database schema audited table for this event is in"""
  schema_name: String

  """Login / session user whose statement caused the audited event"""
  session_user_name: String

  """
  't' if audit event is from an FOR EACH STATEMENT trigger, 'f' for FOR EACH ROW
  """
  statement_only: Boolean

  """Non-schema-qualified table name of table event occured in"""
  table_name: String

  """
  Identifier of transaction that made the change. May wrap, but unique paired with action_tstamp_tx.
  """
  transaction_id: bigint
}

"""aggregate max on columns"""
type audit_logged_actions_max_fields {
  """Action type; I = insert, D = delete, U = update, T = truncate"""
  action: String

  """Wall clock time at which audited event's trigger call occurred"""
  action_tstamp_clk: timestamptz

  """Statement start timestamp for tx in which audited event occurred"""
  action_tstamp_stm: timestamptz

  """Transaction start timestamp for tx in which audited event occurred"""
  action_tstamp_tx: timestamptz

  """
  Application name set when this audit event occurred. Can be changed in-session by client.
  """
  application_name: String

  """
  Remote peer IP port address of client that issued query. Undefined for unix socket.
  """
  client_port: Int

  """
  Top-level query that caused this auditable event. May be more than one statement.
  """
  client_query: String

  """Unique identifier for each auditable event"""
  event_id: bigint

  """Database schema audited table for this event is in"""
  schema_name: String

  """Login / session user whose statement caused the audited event"""
  session_user_name: String

  """Non-schema-qualified table name of table event occured in"""
  table_name: String

  """
  Identifier of transaction that made the change. May wrap, but unique paired with action_tstamp_tx.
  """
  transaction_id: bigint
}

"""aggregate min on columns"""
type audit_logged_actions_min_fields {
  """Action type; I = insert, D = delete, U = update, T = truncate"""
  action: String

  """Wall clock time at which audited event's trigger call occurred"""
  action_tstamp_clk: timestamptz

  """Statement start timestamp for tx in which audited event occurred"""
  action_tstamp_stm: timestamptz

  """Transaction start timestamp for tx in which audited event occurred"""
  action_tstamp_tx: timestamptz

  """
  Application name set when this audit event occurred. Can be changed in-session by client.
  """
  application_name: String

  """
  Remote peer IP port address of client that issued query. Undefined for unix socket.
  """
  client_port: Int

  """
  Top-level query that caused this auditable event. May be more than one statement.
  """
  client_query: String

  """Unique identifier for each auditable event"""
  event_id: bigint

  """Database schema audited table for this event is in"""
  schema_name: String

  """Login / session user whose statement caused the audited event"""
  session_user_name: String

  """Non-schema-qualified table name of table event occured in"""
  table_name: String

  """
  Identifier of transaction that made the change. May wrap, but unique paired with action_tstamp_tx.
  """
  transaction_id: bigint
}

"""
response of any mutation on the table "audit.logged_actions"
"""
type audit_logged_actions_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [audit_logged_actions!]!
}

"""
on_conflict condition type for table "audit.logged_actions"
"""
input audit_logged_actions_on_conflict {
  constraint: audit_logged_actions_constraint!
  update_columns: [audit_logged_actions_update_column!]! = []
  where: audit_logged_actions_bool_exp
}

"""Ordering options when selecting data from "audit.logged_actions"."""
input audit_logged_actions_order_by {
  action: order_by
  action_tstamp_clk: order_by
  action_tstamp_stm: order_by
  action_tstamp_tx: order_by
  application_name: order_by
  changed_fields: order_by
  client_addr: order_by
  client_port: order_by
  client_query: order_by
  event_id: order_by
  hasura_user: order_by
  relid: order_by
  row_data: order_by
  schema_name: order_by
  session_user_name: order_by
  statement_only: order_by
  table_name: order_by
  transaction_id: order_by
}

"""primary key columns input for table: audit.logged_actions"""
input audit_logged_actions_pk_columns_input {
  """Unique identifier for each auditable event"""
  event_id: bigint!
}

"""prepend existing jsonb value of filtered columns with new jsonb value"""
input audit_logged_actions_prepend_input {
  """
  New values of fields changed by UPDATE. Null except for row-level UPDATE events.
  """
  changed_fields: jsonb
  hasura_user: jsonb

  """
  Record value. Null for statement-level trigger. For INSERT this is the new tuple. For DELETE and UPDATE it is the old tuple.
  """
  row_data: jsonb
}

"""
select columns of table "audit.logged_actions"
"""
enum audit_logged_actions_select_column {
  """column name"""
  action

  """column name"""
  action_tstamp_clk

  """column name"""
  action_tstamp_stm

  """column name"""
  action_tstamp_tx

  """column name"""
  application_name

  """column name"""
  changed_fields

  """column name"""
  client_addr

  """column name"""
  client_port

  """column name"""
  client_query

  """column name"""
  event_id

  """column name"""
  hasura_user

  """column name"""
  relid

  """column name"""
  row_data

  """column name"""
  schema_name

  """column name"""
  session_user_name

  """column name"""
  statement_only

  """column name"""
  table_name

  """column name"""
  transaction_id
}

"""
input type for updating data in table "audit.logged_actions"
"""
input audit_logged_actions_set_input {
  """Action type; I = insert, D = delete, U = update, T = truncate"""
  action: String

  """Wall clock time at which audited event's trigger call occurred"""
  action_tstamp_clk: timestamptz

  """Statement start timestamp for tx in which audited event occurred"""
  action_tstamp_stm: timestamptz

  """Transaction start timestamp for tx in which audited event occurred"""
  action_tstamp_tx: timestamptz

  """
  Application name set when this audit event occurred. Can be changed in-session by client.
  """
  application_name: String

  """
  New values of fields changed by UPDATE. Null except for row-level UPDATE events.
  """
  changed_fields: jsonb

  """IP address of client that issued query. Null for unix domain socket."""
  client_addr: inet

  """
  Remote peer IP port address of client that issued query. Undefined for unix socket.
  """
  client_port: Int

  """
  Top-level query that caused this auditable event. May be more than one statement.
  """
  client_query: String

  """Unique identifier for each auditable event"""
  event_id: bigint
  hasura_user: jsonb

  """Table OID. Changes with drop/create. Get with 'tablename'::regclass"""
  relid: oid

  """
  Record value. Null for statement-level trigger. For INSERT this is the new tuple. For DELETE and UPDATE it is the old tuple.
  """
  row_data: jsonb

  """Database schema audited table for this event is in"""
  schema_name: String

  """Login / session user whose statement caused the audited event"""
  session_user_name: String

  """
  't' if audit event is from an FOR EACH STATEMENT trigger, 'f' for FOR EACH ROW
  """
  statement_only: Boolean

  """Non-schema-qualified table name of table event occured in"""
  table_name: String

  """
  Identifier of transaction that made the change. May wrap, but unique paired with action_tstamp_tx.
  """
  transaction_id: bigint
}

"""aggregate stddev on columns"""
type audit_logged_actions_stddev_fields {
  """
  Remote peer IP port address of client that issued query. Undefined for unix socket.
  """
  client_port: Float

  """Unique identifier for each auditable event"""
  event_id: Float

  """
  Identifier of transaction that made the change. May wrap, but unique paired with action_tstamp_tx.
  """
  transaction_id: Float
}

"""aggregate stddev_pop on columns"""
type audit_logged_actions_stddev_pop_fields {
  """
  Remote peer IP port address of client that issued query. Undefined for unix socket.
  """
  client_port: Float

  """Unique identifier for each auditable event"""
  event_id: Float

  """
  Identifier of transaction that made the change. May wrap, but unique paired with action_tstamp_tx.
  """
  transaction_id: Float
}

"""aggregate stddev_samp on columns"""
type audit_logged_actions_stddev_samp_fields {
  """
  Remote peer IP port address of client that issued query. Undefined for unix socket.
  """
  client_port: Float

  """Unique identifier for each auditable event"""
  event_id: Float

  """
  Identifier of transaction that made the change. May wrap, but unique paired with action_tstamp_tx.
  """
  transaction_id: Float
}

"""
Streaming cursor of the table "audit_logged_actions"
"""
input audit_logged_actions_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: audit_logged_actions_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input audit_logged_actions_stream_cursor_value_input {
  """Action type; I = insert, D = delete, U = update, T = truncate"""
  action: String

  """Wall clock time at which audited event's trigger call occurred"""
  action_tstamp_clk: timestamptz

  """Statement start timestamp for tx in which audited event occurred"""
  action_tstamp_stm: timestamptz

  """Transaction start timestamp for tx in which audited event occurred"""
  action_tstamp_tx: timestamptz

  """
  Application name set when this audit event occurred. Can be changed in-session by client.
  """
  application_name: String

  """
  New values of fields changed by UPDATE. Null except for row-level UPDATE events.
  """
  changed_fields: jsonb

  """IP address of client that issued query. Null for unix domain socket."""
  client_addr: inet

  """
  Remote peer IP port address of client that issued query. Undefined for unix socket.
  """
  client_port: Int

  """
  Top-level query that caused this auditable event. May be more than one statement.
  """
  client_query: String

  """Unique identifier for each auditable event"""
  event_id: bigint
  hasura_user: jsonb

  """Table OID. Changes with drop/create. Get with 'tablename'::regclass"""
  relid: oid

  """
  Record value. Null for statement-level trigger. For INSERT this is the new tuple. For DELETE and UPDATE it is the old tuple.
  """
  row_data: jsonb

  """Database schema audited table for this event is in"""
  schema_name: String

  """Login / session user whose statement caused the audited event"""
  session_user_name: String

  """
  't' if audit event is from an FOR EACH STATEMENT trigger, 'f' for FOR EACH ROW
  """
  statement_only: Boolean

  """Non-schema-qualified table name of table event occured in"""
  table_name: String

  """
  Identifier of transaction that made the change. May wrap, but unique paired with action_tstamp_tx.
  """
  transaction_id: bigint
}

"""aggregate sum on columns"""
type audit_logged_actions_sum_fields {
  """
  Remote peer IP port address of client that issued query. Undefined for unix socket.
  """
  client_port: Int

  """Unique identifier for each auditable event"""
  event_id: bigint

  """
  Identifier of transaction that made the change. May wrap, but unique paired with action_tstamp_tx.
  """
  transaction_id: bigint
}

"""
update columns of table "audit.logged_actions"
"""
enum audit_logged_actions_update_column {
  """column name"""
  action

  """column name"""
  action_tstamp_clk

  """column name"""
  action_tstamp_stm

  """column name"""
  action_tstamp_tx

  """column name"""
  application_name

  """column name"""
  changed_fields

  """column name"""
  client_addr

  """column name"""
  client_port

  """column name"""
  client_query

  """column name"""
  event_id

  """column name"""
  hasura_user

  """column name"""
  relid

  """column name"""
  row_data

  """column name"""
  schema_name

  """column name"""
  session_user_name

  """column name"""
  statement_only

  """column name"""
  table_name

  """column name"""
  transaction_id
}

input audit_logged_actions_updates {
  """append existing jsonb value of filtered columns with new jsonb value"""
  _append: audit_logged_actions_append_input

  """
  delete the field or element with specified path (for JSON arrays, negative integers count from the end)
  """
  _delete_at_path: audit_logged_actions_delete_at_path_input

  """
  delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
  """
  _delete_elem: audit_logged_actions_delete_elem_input

  """
  delete key/value pair or string element. key/value pairs are matched based on their key value
  """
  _delete_key: audit_logged_actions_delete_key_input

  """increments the numeric columns with given value of the filtered values"""
  _inc: audit_logged_actions_inc_input

  """prepend existing jsonb value of filtered columns with new jsonb value"""
  _prepend: audit_logged_actions_prepend_input

  """sets the columns of the filtered rows to the given values"""
  _set: audit_logged_actions_set_input

  """filter the rows which have to be updated"""
  where: audit_logged_actions_bool_exp!
}

"""aggregate var_pop on columns"""
type audit_logged_actions_var_pop_fields {
  """
  Remote peer IP port address of client that issued query. Undefined for unix socket.
  """
  client_port: Float

  """Unique identifier for each auditable event"""
  event_id: Float

  """
  Identifier of transaction that made the change. May wrap, but unique paired with action_tstamp_tx.
  """
  transaction_id: Float
}

"""aggregate var_samp on columns"""
type audit_logged_actions_var_samp_fields {
  """
  Remote peer IP port address of client that issued query. Undefined for unix socket.
  """
  client_port: Float

  """Unique identifier for each auditable event"""
  event_id: Float

  """
  Identifier of transaction that made the change. May wrap, but unique paired with action_tstamp_tx.
  """
  transaction_id: Float
}

"""aggregate variance on columns"""
type audit_logged_actions_variance_fields {
  """
  Remote peer IP port address of client that issued query. Undefined for unix socket.
  """
  client_port: Float

  """Unique identifier for each auditable event"""
  event_id: Float

  """
  Identifier of transaction that made the change. May wrap, but unique paired with action_tstamp_tx.
  """
  transaction_id: Float
}

scalar bigint

"""
Boolean expression to compare columns of type "bigint". All fields are combined with logical 'AND'.
"""
input bigint_comparison_exp {
  _eq: bigint
  _gt: bigint
  _gte: bigint
  _in: [bigint!]
  _is_null: Boolean
  _lt: bigint
  _lte: bigint
  _neq: bigint
  _nin: [bigint!]
}

"""
Currencies code following the standard ISO 4217 (https://en.wikipedia.org/wiki/ISO_4217)
"""
type currency {
  value: String!
}

"""
aggregated selection of "currency"
"""
type currency_aggregate {
  aggregate: currency_aggregate_fields
  nodes: [currency!]!
}

"""
aggregate fields of "currency"
"""
type currency_aggregate_fields {
  count(columns: [currency_select_column!], distinct: Boolean): Int!
  max: currency_max_fields
  min: currency_min_fields
}

"""
Boolean expression to filter rows from the table "currency". All fields are combined with a logical 'AND'.
"""
input currency_bool_exp {
  _and: [currency_bool_exp!]
  _not: currency_bool_exp
  _or: [currency_bool_exp!]
  value: String_comparison_exp
}

"""
unique or primary key constraints on table "currency"
"""
enum currency_constraint {
  """
  unique or primary key constraint on columns "value"
  """
  currency_pkey
}

enum currency_enum {
  AED
  CNY
  EUR
  GBP
  QAR
  SGD
  USD
}

"""
Boolean expression to compare columns of type "currency_enum". All fields are combined with logical 'AND'.
"""
input currency_enum_comparison_exp {
  _eq: currency_enum
  _in: [currency_enum!]
  _is_null: Boolean
  _neq: currency_enum
  _nin: [currency_enum!]
}

"""
input type for inserting data into table "currency"
"""
input currency_insert_input {
  value: String
}

"""aggregate max on columns"""
type currency_max_fields {
  value: String
}

"""aggregate min on columns"""
type currency_min_fields {
  value: String
}

"""
response of any mutation on the table "currency"
"""
type currency_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [currency!]!
}

"""
on_conflict condition type for table "currency"
"""
input currency_on_conflict {
  constraint: currency_constraint!
  update_columns: [currency_update_column!]! = []
  where: currency_bool_exp
}

"""Ordering options when selecting data from "currency"."""
input currency_order_by {
  value: order_by
}

"""primary key columns input for table: currency"""
input currency_pk_columns_input {
  value: String!
}

"""
select columns of table "currency"
"""
enum currency_select_column {
  """column name"""
  value
}

"""
input type for updating data in table "currency"
"""
input currency_set_input {
  value: String
}

"""
Streaming cursor of the table "currency"
"""
input currency_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: currency_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input currency_stream_cursor_value_input {
  value: String
}

"""
update columns of table "currency"
"""
enum currency_update_column {
  """column name"""
  value
}

input currency_updates {
  """sets the columns of the filtered rows to the given values"""
  _set: currency_set_input

  """filter the rows which have to be updated"""
  where: currency_bool_exp!
}

"""ordering argument of a cursor"""
enum cursor_ordering {
  """ascending ordering of the cursor"""
  ASC

  """descending ordering of the cursor"""
  DESC
}

"""
The eventParameters model is designed to define properties on an event involving all event passes. This table includes critical details like the eventId and activityWebhookId, which aids in monitoring and processing events or changes related to the event parameters. By centralizing this information, our system can effectively manage and control parameters tied to specific events, enhancing the overall functionality and flexibility of event handling.
"""
type eventParameters {
  activityWebhookId: String
  dateEnd: timestamp
  dateSaleEnd: timestamp
  dateSaleStart: timestamp
  dateStart: timestamp
  event(
    """
    Defines which locales should be returned.
    
    Note that `Event` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, entries with non matching locales will be filtered out.
    
    This argument may be overwritten by another locales definition in a relational child field, this will effectively use the overwritten argument for the affected query's subtree.
    """
    locales: [Locale!]! = [en]
    stage: Stage! = PUBLISHED
    where: EventWhereUniqueInput_remote_rel_eventParametersevent!
  ): Event
  eventId: String!

  """An array relationship"""
  eventPassNftContracts(
    """distinct select on columns"""
    distinct_on: [eventPassNftContract_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [eventPassNftContract_order_by!]

    """filter the rows returned"""
    where: eventPassNftContract_bool_exp
  ): [eventPassNftContract!]!

  """An aggregate relationship"""
  eventPassNftContracts_aggregate(
    """distinct select on columns"""
    distinct_on: [eventPassNftContract_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [eventPassNftContract_order_by!]

    """filter the rows returned"""
    where: eventPassNftContract_bool_exp
  ): eventPassNftContract_aggregate!

  """An array relationship"""
  eventPassNfts(
    """distinct select on columns"""
    distinct_on: [eventPassNft_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [eventPassNft_order_by!]

    """filter the rows returned"""
    where: eventPassNft_bool_exp
  ): [eventPassNft!]!

  """An aggregate relationship"""
  eventPassNfts_aggregate(
    """distinct select on columns"""
    distinct_on: [eventPassNft_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [eventPassNft_order_by!]

    """filter the rows returned"""
    where: eventPassNft_bool_exp
  ): eventPassNft_aggregate!
  id: uuid!
  organizer(
    """
    Defines which locales should be returned.
    
    Note that `Organizer` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, entries with non matching locales will be filtered out.
    
    This argument may be overwritten by another locales definition in a relational child field, this will effectively use the overwritten argument for the affected query's subtree.
    """
    locales: [Locale!]! = [en]
    stage: Stage! = PUBLISHED
    where: OrganizerWhereUniqueInput_remote_rel_eventParametersorganizer!
  ): Organizer
  organizerId: String!
  signingKey: String
  timezone: String
}

"""
aggregated selection of "eventParameters"
"""
type eventParameters_aggregate {
  aggregate: eventParameters_aggregate_fields
  nodes: [eventParameters!]!
}

"""
aggregate fields of "eventParameters"
"""
type eventParameters_aggregate_fields {
  count(columns: [eventParameters_select_column!], distinct: Boolean): Int!
  max: eventParameters_max_fields
  min: eventParameters_min_fields
}

"""
Boolean expression to filter rows from the table "eventParameters". All fields are combined with a logical 'AND'.
"""
input eventParameters_bool_exp {
  _and: [eventParameters_bool_exp!]
  _not: eventParameters_bool_exp
  _or: [eventParameters_bool_exp!]
  activityWebhookId: String_comparison_exp
  dateEnd: timestamp_comparison_exp
  dateSaleEnd: timestamp_comparison_exp
  dateSaleStart: timestamp_comparison_exp
  dateStart: timestamp_comparison_exp
  eventId: String_comparison_exp
  eventPassNftContracts: eventPassNftContract_bool_exp
  eventPassNftContracts_aggregate: eventPassNftContract_aggregate_bool_exp
  eventPassNfts: eventPassNft_bool_exp
  eventPassNfts_aggregate: eventPassNft_aggregate_bool_exp
  id: uuid_comparison_exp
  organizerId: String_comparison_exp
  signingKey: String_comparison_exp
  timezone: String_comparison_exp
}

"""
unique or primary key constraints on table "eventParameters"
"""
enum eventParameters_constraint {
  """
  unique or primary key constraint on columns "activityWebhookId"
  """
  eventParameters_activityWebhookId_key

  """
  unique or primary key constraint on columns "eventId"
  """
  eventParameters_eventId_key

  """
  unique or primary key constraint on columns "id"
  """
  eventParameters_pkey

  """
  unique or primary key constraint on columns "signingKey"
  """
  eventParameters_signingKey_key
}

"""
input type for inserting data into table "eventParameters"
"""
input eventParameters_insert_input {
  activityWebhookId: String
  dateEnd: timestamp
  dateSaleEnd: timestamp
  dateSaleStart: timestamp
  dateStart: timestamp
  eventId: String
  eventPassNftContracts: eventPassNftContract_arr_rel_insert_input
  eventPassNfts: eventPassNft_arr_rel_insert_input
  id: uuid
  organizerId: String
  signingKey: String
  timezone: String
}

"""aggregate max on columns"""
type eventParameters_max_fields {
  activityWebhookId: String
  dateEnd: timestamp
  dateSaleEnd: timestamp
  dateSaleStart: timestamp
  dateStart: timestamp
  eventId: String
  id: uuid
  organizerId: String
  signingKey: String
  timezone: String
}

"""aggregate min on columns"""
type eventParameters_min_fields {
  activityWebhookId: String
  dateEnd: timestamp
  dateSaleEnd: timestamp
  dateSaleStart: timestamp
  dateStart: timestamp
  eventId: String
  id: uuid
  organizerId: String
  signingKey: String
  timezone: String
}

"""
response of any mutation on the table "eventParameters"
"""
type eventParameters_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [eventParameters!]!
}

"""
input type for inserting object relation for remote table "eventParameters"
"""
input eventParameters_obj_rel_insert_input {
  data: eventParameters_insert_input!

  """upsert condition"""
  on_conflict: eventParameters_on_conflict
}

"""
on_conflict condition type for table "eventParameters"
"""
input eventParameters_on_conflict {
  constraint: eventParameters_constraint!
  update_columns: [eventParameters_update_column!]! = []
  where: eventParameters_bool_exp
}

"""Ordering options when selecting data from "eventParameters"."""
input eventParameters_order_by {
  activityWebhookId: order_by
  dateEnd: order_by
  dateSaleEnd: order_by
  dateSaleStart: order_by
  dateStart: order_by
  eventId: order_by
  eventPassNftContracts_aggregate: eventPassNftContract_aggregate_order_by
  eventPassNfts_aggregate: eventPassNft_aggregate_order_by
  id: order_by
  organizerId: order_by
  signingKey: order_by
  timezone: order_by
}

"""primary key columns input for table: eventParameters"""
input eventParameters_pk_columns_input {
  id: uuid!
}

"""
select columns of table "eventParameters"
"""
enum eventParameters_select_column {
  """column name"""
  activityWebhookId

  """column name"""
  dateEnd

  """column name"""
  dateSaleEnd

  """column name"""
  dateSaleStart

  """column name"""
  dateStart

  """column name"""
  eventId

  """column name"""
  id

  """column name"""
  organizerId

  """column name"""
  signingKey

  """column name"""
  timezone
}

"""
input type for updating data in table "eventParameters"
"""
input eventParameters_set_input {
  activityWebhookId: String
  dateEnd: timestamp
  dateSaleEnd: timestamp
  dateSaleStart: timestamp
  dateStart: timestamp
  eventId: String
  id: uuid
  organizerId: String
  signingKey: String
  timezone: String
}

"""
Streaming cursor of the table "eventParameters"
"""
input eventParameters_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: eventParameters_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input eventParameters_stream_cursor_value_input {
  activityWebhookId: String
  dateEnd: timestamp
  dateSaleEnd: timestamp
  dateSaleStart: timestamp
  dateStart: timestamp
  eventId: String
  id: uuid
  organizerId: String
  signingKey: String
  timezone: String
}

"""
update columns of table "eventParameters"
"""
enum eventParameters_update_column {
  """column name"""
  activityWebhookId

  """column name"""
  dateEnd

  """column name"""
  dateSaleEnd

  """column name"""
  dateSaleStart

  """column name"""
  dateStart

  """column name"""
  eventId

  """column name"""
  id

  """column name"""
  organizerId

  """column name"""
  signingKey

  """column name"""
  timezone
}

input eventParameters_updates {
  """sets the columns of the filtered rows to the given values"""
  _set: eventParameters_set_input

  """filter the rows which have to be updated"""
  where: eventParameters_bool_exp!
}

"""
The eventPassNft model is designed to consolidate and store the metadata associated with each event pass NFT. It centralizes fixed metadata, enabling the system to retrieve NFT details without frequently querying external APIs. It integrates with the existing nftTransfer model, providing a holistic view of each event pass NFT's journey and characteristics within the platform.
"""
type eventPassNft {
  """Denotes the specific blockchain or network of the event pass NFT"""
  chainId: String!

  """
  Identifies the smart contract associated with the event pass NFT. This provides a direct link to the NFT's origin and behavior on the blockchain.
  """
  contractAddress: String!
  created_at: timestamptz!

  """
  The address currently holding the event pass NFT, allowing tracking of ownership
  """
  currentOwnerAddress: String

  """
  Contains any error message related to metadata retrieval, ensuring transparency in the data extraction process.
  """
  error: String
  event(
    """
    Defines which locales should be returned.
    
    Note that `Event` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, entries with non matching locales will be filtered out.
    
    This argument may be overwritten by another locales definition in a relational child field, this will effectively use the overwritten argument for the affected query's subtree.
    """
    locales: [Locale!]! = [en]
    stage: Stage! = PUBLISHED
    where: EventWhereUniqueInput_remote_rel_eventPassNftevent!
  ): Event

  """A reference to the event associated with the event pass NFT"""
  eventId: String!

  """An object relationship"""
  eventParameters: eventParameters
  eventPass(
    """
    Defines which locales should be returned.
    
    Note that `EventPass` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, entries with non matching locales will be filtered out.
    
    This argument may be overwritten by another locales definition in a relational child field, this will effectively use the overwritten argument for the affected query's subtree.
    """
    locales: [Locale!]! = [en]
    stage: Stage! = PUBLISHED
  ): EventPass

  """Directly relates to a specific Event Pass within the system"""
  eventPassId: String!

  """An object relationship"""
  eventPassNftContract: eventPassNftContract

  """An object relationship"""
  eventPassPricing: eventPassPricing
  id: uuid!

  """
  Indicates whether the QR code pass for the event pass NFT has been revealed by the owner. This field is essential for tracking and managing the reveal status within the platform.
  """
  isRevealed: Boolean!

  """An object relationship"""
  lastNftTransfer: nftTransfer

  """
  Reference `id` to the latest `nftTransfer` entry, detailing the most recent transaction for this event pass NFT.
  """
  lastNftTransferId: uuid

  """
  The structured metadata parsed from the token URI. This contains a variety of details regarding the event pass NFT.
  """
  metadata(
    """JSON select path"""
    path: String
  ): jsonb!

  """An array relationship"""
  nftTransfers(
    """distinct select on columns"""
    distinct_on: [nftTransfer_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [nftTransfer_order_by!]

    """filter the rows returned"""
    where: nftTransfer_bool_exp
  ): [nftTransfer!]!

  """An aggregate relationship"""
  nftTransfers_aggregate(
    """distinct select on columns"""
    distinct_on: [nftTransfer_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [nftTransfer_order_by!]

    """filter the rows returned"""
    where: nftTransfer_bool_exp
  ): nftTransfer_aggregate!
  organizer(
    """
    Defines which locales should be returned.
    
    Note that `Organizer` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, entries with non matching locales will be filtered out.
    
    This argument may be overwritten by another locales definition in a relational child field, this will effectively use the overwritten argument for the affected query's subtree.
    """
    locales: [Locale!]! = [en]
    stage: Stage! = PUBLISHED
    where: OrganizerWhereUniqueInput_remote_rel_eventPassNftorganizer!
  ): Organizer

  """Ties the event pass NFT to a specific organizer within the platform"""
  organizerId: String!

  """An object relationship"""
  packNftContract: packNftContract
  packNftContractId: uuid

  """
  The unique identifier of the event pass NFT within its specific collection or contract. This remains constant across various platforms.
  """
  tokenId: bigint!

  """
  The designated URI for the event pass NFT's metadata blob, providing a stable reference for data extraction.
  """
  tokenUri: String
  updated_at: timestamptz!
}

"""
The eventPassNftContract model is designed to store metadata associated with NFT contracts linked to specific event passes. This table captures critical, immutable details from the ERC-721 standard, such as the chainId and contractAddress, ensuring accurate tracking and referencing of NFT contracts. Additionally, this table includes information specific to each event pass, like the eventPassId and organizerId, allowing for precise management and interaction with NFT contracts tied to individual event passes. By centralizing this information, our system can effectively manage, reference, and interact with NFT contracts related to particular event passes.
"""
type eventPassNftContract {
  chainId: String!
  contractAddress: String!

  """Timestamp of when the record was created."""
  created_at: timestamptz!
  eventId: String!
  eventPass(
    """
    Defines which locales should be returned.
    
    Note that `EventPass` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, entries with non matching locales will be filtered out.
    
    This argument may be overwritten by another locales definition in a relational child field, this will effectively use the overwritten argument for the affected query's subtree.
    """
    locales: [Locale!]! = [en]
    stage: Stage! = PUBLISHED
  ): EventPass
  eventPassId: String!

  """An array relationship"""
  eventPassNfts(
    """distinct select on columns"""
    distinct_on: [eventPassNft_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [eventPassNft_order_by!]

    """filter the rows returned"""
    where: eventPassNft_bool_exp
  ): [eventPassNft!]!

  """An aggregate relationship"""
  eventPassNfts_aggregate(
    """distinct select on columns"""
    distinct_on: [eventPassNft_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [eventPassNft_order_by!]

    """filter the rows returned"""
    where: eventPassNft_bool_exp
  ): eventPassNft_aggregate!

  """An object relationship"""
  eventPassOrderSums: eventPassOrderSums

  """An array relationship"""
  eventPassOrders(
    """distinct select on columns"""
    distinct_on: [eventPassOrder_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [eventPassOrder_order_by!]

    """filter the rows returned"""
    where: eventPassOrder_bool_exp
  ): [eventPassOrder!]!

  """An aggregate relationship"""
  eventPassOrders_aggregate(
    """distinct select on columns"""
    distinct_on: [eventPassOrder_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [eventPassOrder_order_by!]

    """filter the rows returned"""
    where: eventPassOrder_bool_exp
  ): eventPassOrder_aggregate!

  """An object relationship"""
  eventPassPricing: eventPassPricing
  id: uuid!

  """Flag indicating whether the event pass NFT is airdropped."""
  isAirdrop: Boolean!

  """
  Flag indicating whether the delayed reveal functionality is active. Can be set to true only if type is delayed_reveal.
  """
  isDelayedRevealed: Boolean!
  organizerId: String!

  """
  Password for the delayed reveal functionality. Nullable and only applicable for delayed_reveal type.
  """
  password: String

  """Type of the event pass NFT contract."""
  type: eventPassNftContractType_enum!

  """Timestamp of the last update to the record."""
  updated_at: timestamptz!
}

"""Contract types representing the nature of the event pass NFT contract."""
type eventPassNftContractType {
  """Type name for event pass NFT contract."""
  value: String!
}

"""
aggregated selection of "eventPassNftContractType"
"""
type eventPassNftContractType_aggregate {
  aggregate: eventPassNftContractType_aggregate_fields
  nodes: [eventPassNftContractType!]!
}

"""
aggregate fields of "eventPassNftContractType"
"""
type eventPassNftContractType_aggregate_fields {
  count(columns: [eventPassNftContractType_select_column!], distinct: Boolean): Int!
  max: eventPassNftContractType_max_fields
  min: eventPassNftContractType_min_fields
}

"""
Boolean expression to filter rows from the table "eventPassNftContractType". All fields are combined with a logical 'AND'.
"""
input eventPassNftContractType_bool_exp {
  _and: [eventPassNftContractType_bool_exp!]
  _not: eventPassNftContractType_bool_exp
  _or: [eventPassNftContractType_bool_exp!]
  value: String_comparison_exp
}

"""
unique or primary key constraints on table "eventPassNftContractType"
"""
enum eventPassNftContractType_constraint {
  """
  unique or primary key constraint on columns "value"
  """
  eventPassNftContractType_pkey
}

enum eventPassNftContractType_enum {
  delayed_reveal
  normal
}

"""
Boolean expression to compare columns of type "eventPassNftContractType_enum". All fields are combined with logical 'AND'.
"""
input eventPassNftContractType_enum_comparison_exp {
  _eq: eventPassNftContractType_enum
  _in: [eventPassNftContractType_enum!]
  _is_null: Boolean
  _neq: eventPassNftContractType_enum
  _nin: [eventPassNftContractType_enum!]
}

"""
input type for inserting data into table "eventPassNftContractType"
"""
input eventPassNftContractType_insert_input {
  """Type name for event pass NFT contract."""
  value: String
}

"""aggregate max on columns"""
type eventPassNftContractType_max_fields {
  """Type name for event pass NFT contract."""
  value: String
}

"""aggregate min on columns"""
type eventPassNftContractType_min_fields {
  """Type name for event pass NFT contract."""
  value: String
}

"""
response of any mutation on the table "eventPassNftContractType"
"""
type eventPassNftContractType_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [eventPassNftContractType!]!
}

"""
on_conflict condition type for table "eventPassNftContractType"
"""
input eventPassNftContractType_on_conflict {
  constraint: eventPassNftContractType_constraint!
  update_columns: [eventPassNftContractType_update_column!]! = []
  where: eventPassNftContractType_bool_exp
}

"""Ordering options when selecting data from "eventPassNftContractType"."""
input eventPassNftContractType_order_by {
  value: order_by
}

"""primary key columns input for table: eventPassNftContractType"""
input eventPassNftContractType_pk_columns_input {
  """Type name for event pass NFT contract."""
  value: String!
}

"""
select columns of table "eventPassNftContractType"
"""
enum eventPassNftContractType_select_column {
  """column name"""
  value
}

"""
input type for updating data in table "eventPassNftContractType"
"""
input eventPassNftContractType_set_input {
  """Type name for event pass NFT contract."""
  value: String
}

"""
Streaming cursor of the table "eventPassNftContractType"
"""
input eventPassNftContractType_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: eventPassNftContractType_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input eventPassNftContractType_stream_cursor_value_input {
  """Type name for event pass NFT contract."""
  value: String
}

"""
update columns of table "eventPassNftContractType"
"""
enum eventPassNftContractType_update_column {
  """column name"""
  value
}

input eventPassNftContractType_updates {
  """sets the columns of the filtered rows to the given values"""
  _set: eventPassNftContractType_set_input

  """filter the rows which have to be updated"""
  where: eventPassNftContractType_bool_exp!
}

"""
aggregated selection of "eventPassNftContract"
"""
type eventPassNftContract_aggregate {
  aggregate: eventPassNftContract_aggregate_fields
  nodes: [eventPassNftContract!]!
}

input eventPassNftContract_aggregate_bool_exp {
  bool_and: eventPassNftContract_aggregate_bool_exp_bool_and
  bool_or: eventPassNftContract_aggregate_bool_exp_bool_or
  count: eventPassNftContract_aggregate_bool_exp_count
}

input eventPassNftContract_aggregate_bool_exp_bool_and {
  arguments: eventPassNftContract_select_column_eventPassNftContract_aggregate_bool_exp_bool_and_arguments_columns!
  distinct: Boolean
  filter: eventPassNftContract_bool_exp
  predicate: Boolean_comparison_exp!
}

input eventPassNftContract_aggregate_bool_exp_bool_or {
  arguments: eventPassNftContract_select_column_eventPassNftContract_aggregate_bool_exp_bool_or_arguments_columns!
  distinct: Boolean
  filter: eventPassNftContract_bool_exp
  predicate: Boolean_comparison_exp!
}

input eventPassNftContract_aggregate_bool_exp_count {
  arguments: [eventPassNftContract_select_column!]
  distinct: Boolean
  filter: eventPassNftContract_bool_exp
  predicate: Int_comparison_exp!
}

"""
aggregate fields of "eventPassNftContract"
"""
type eventPassNftContract_aggregate_fields {
  count(columns: [eventPassNftContract_select_column!], distinct: Boolean): Int!
  max: eventPassNftContract_max_fields
  min: eventPassNftContract_min_fields
}

"""
order by aggregate values of table "eventPassNftContract"
"""
input eventPassNftContract_aggregate_order_by {
  count: order_by
  max: eventPassNftContract_max_order_by
  min: eventPassNftContract_min_order_by
}

"""
input type for inserting array relation for remote table "eventPassNftContract"
"""
input eventPassNftContract_arr_rel_insert_input {
  data: [eventPassNftContract_insert_input!]!

  """upsert condition"""
  on_conflict: eventPassNftContract_on_conflict
}

"""
Boolean expression to filter rows from the table "eventPassNftContract". All fields are combined with a logical 'AND'.
"""
input eventPassNftContract_bool_exp {
  _and: [eventPassNftContract_bool_exp!]
  _not: eventPassNftContract_bool_exp
  _or: [eventPassNftContract_bool_exp!]
  chainId: String_comparison_exp
  contractAddress: String_comparison_exp
  created_at: timestamptz_comparison_exp
  eventId: String_comparison_exp
  eventPassId: String_comparison_exp
  eventPassNfts: eventPassNft_bool_exp
  eventPassNfts_aggregate: eventPassNft_aggregate_bool_exp
  eventPassOrderSums: eventPassOrderSums_bool_exp
  eventPassOrders: eventPassOrder_bool_exp
  eventPassOrders_aggregate: eventPassOrder_aggregate_bool_exp
  eventPassPricing: eventPassPricing_bool_exp
  id: uuid_comparison_exp
  isAirdrop: Boolean_comparison_exp
  isDelayedRevealed: Boolean_comparison_exp
  organizerId: String_comparison_exp
  password: String_comparison_exp
  type: eventPassNftContractType_enum_comparison_exp
  updated_at: timestamptz_comparison_exp
}

"""
unique or primary key constraints on table "eventPassNftContract"
"""
enum eventPassNftContract_constraint {
  """
  unique or primary key constraint on columns "chainId", "contractAddress"
  """
  eventPassNftContract_contractAddress_chainId_key
}

"""
input type for inserting data into table "eventPassNftContract"
"""
input eventPassNftContract_insert_input {
  chainId: String
  contractAddress: String

  """Timestamp of when the record was created."""
  created_at: timestamptz
  eventId: String
  eventPassId: String
  eventPassNfts: eventPassNft_arr_rel_insert_input
  eventPassOrderSums: eventPassOrderSums_obj_rel_insert_input
  eventPassOrders: eventPassOrder_arr_rel_insert_input
  eventPassPricing: eventPassPricing_obj_rel_insert_input
  id: uuid

  """Flag indicating whether the event pass NFT is airdropped."""
  isAirdrop: Boolean

  """
  Flag indicating whether the delayed reveal functionality is active. Can be set to true only if type is delayed_reveal.
  """
  isDelayedRevealed: Boolean
  organizerId: String

  """
  Password for the delayed reveal functionality. Nullable and only applicable for delayed_reveal type.
  """
  password: String

  """Type of the event pass NFT contract."""
  type: eventPassNftContractType_enum

  """Timestamp of the last update to the record."""
  updated_at: timestamptz
}

"""aggregate max on columns"""
type eventPassNftContract_max_fields {
  chainId: String
  contractAddress: String

  """Timestamp of when the record was created."""
  created_at: timestamptz
  eventId: String
  eventPassId: String
  id: uuid
  organizerId: String

  """
  Password for the delayed reveal functionality. Nullable and only applicable for delayed_reveal type.
  """
  password: String

  """Timestamp of the last update to the record."""
  updated_at: timestamptz
}

"""
order by max() on columns of table "eventPassNftContract"
"""
input eventPassNftContract_max_order_by {
  chainId: order_by
  contractAddress: order_by

  """Timestamp of when the record was created."""
  created_at: order_by
  eventId: order_by
  eventPassId: order_by
  id: order_by
  organizerId: order_by

  """
  Password for the delayed reveal functionality. Nullable and only applicable for delayed_reveal type.
  """
  password: order_by

  """Timestamp of the last update to the record."""
  updated_at: order_by
}

"""aggregate min on columns"""
type eventPassNftContract_min_fields {
  chainId: String
  contractAddress: String

  """Timestamp of when the record was created."""
  created_at: timestamptz
  eventId: String
  eventPassId: String
  id: uuid
  organizerId: String

  """
  Password for the delayed reveal functionality. Nullable and only applicable for delayed_reveal type.
  """
  password: String

  """Timestamp of the last update to the record."""
  updated_at: timestamptz
}

"""
order by min() on columns of table "eventPassNftContract"
"""
input eventPassNftContract_min_order_by {
  chainId: order_by
  contractAddress: order_by

  """Timestamp of when the record was created."""
  created_at: order_by
  eventId: order_by
  eventPassId: order_by
  id: order_by
  organizerId: order_by

  """
  Password for the delayed reveal functionality. Nullable and only applicable for delayed_reveal type.
  """
  password: order_by

  """Timestamp of the last update to the record."""
  updated_at: order_by
}

"""
response of any mutation on the table "eventPassNftContract"
"""
type eventPassNftContract_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [eventPassNftContract!]!
}

"""
input type for inserting object relation for remote table "eventPassNftContract"
"""
input eventPassNftContract_obj_rel_insert_input {
  data: eventPassNftContract_insert_input!

  """upsert condition"""
  on_conflict: eventPassNftContract_on_conflict
}

"""
on_conflict condition type for table "eventPassNftContract"
"""
input eventPassNftContract_on_conflict {
  constraint: eventPassNftContract_constraint!
  update_columns: [eventPassNftContract_update_column!]! = []
  where: eventPassNftContract_bool_exp
}

"""Ordering options when selecting data from "eventPassNftContract"."""
input eventPassNftContract_order_by {
  chainId: order_by
  contractAddress: order_by
  created_at: order_by
  eventId: order_by
  eventPassId: order_by
  eventPassNfts_aggregate: eventPassNft_aggregate_order_by
  eventPassOrderSums: eventPassOrderSums_order_by
  eventPassOrders_aggregate: eventPassOrder_aggregate_order_by
  eventPassPricing: eventPassPricing_order_by
  id: order_by
  isAirdrop: order_by
  isDelayedRevealed: order_by
  organizerId: order_by
  password: order_by
  type: order_by
  updated_at: order_by
}

"""
select columns of table "eventPassNftContract"
"""
enum eventPassNftContract_select_column {
  """column name"""
  chainId

  """column name"""
  contractAddress

  """column name"""
  created_at

  """column name"""
  eventId

  """column name"""
  eventPassId

  """column name"""
  id

  """column name"""
  isAirdrop

  """column name"""
  isDelayedRevealed

  """column name"""
  organizerId

  """column name"""
  password

  """column name"""
  type

  """column name"""
  updated_at
}

"""
select "eventPassNftContract_aggregate_bool_exp_bool_and_arguments_columns" columns of table "eventPassNftContract"
"""
enum eventPassNftContract_select_column_eventPassNftContract_aggregate_bool_exp_bool_and_arguments_columns {
  """column name"""
  isAirdrop

  """column name"""
  isDelayedRevealed
}

"""
select "eventPassNftContract_aggregate_bool_exp_bool_or_arguments_columns" columns of table "eventPassNftContract"
"""
enum eventPassNftContract_select_column_eventPassNftContract_aggregate_bool_exp_bool_or_arguments_columns {
  """column name"""
  isAirdrop

  """column name"""
  isDelayedRevealed
}

"""
input type for updating data in table "eventPassNftContract"
"""
input eventPassNftContract_set_input {
  chainId: String
  contractAddress: String

  """Timestamp of when the record was created."""
  created_at: timestamptz
  eventId: String
  eventPassId: String
  id: uuid

  """Flag indicating whether the event pass NFT is airdropped."""
  isAirdrop: Boolean

  """
  Flag indicating whether the delayed reveal functionality is active. Can be set to true only if type is delayed_reveal.
  """
  isDelayedRevealed: Boolean
  organizerId: String

  """
  Password for the delayed reveal functionality. Nullable and only applicable for delayed_reveal type.
  """
  password: String

  """Type of the event pass NFT contract."""
  type: eventPassNftContractType_enum

  """Timestamp of the last update to the record."""
  updated_at: timestamptz
}

"""
Streaming cursor of the table "eventPassNftContract"
"""
input eventPassNftContract_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: eventPassNftContract_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input eventPassNftContract_stream_cursor_value_input {
  chainId: String
  contractAddress: String

  """Timestamp of when the record was created."""
  created_at: timestamptz
  eventId: String
  eventPassId: String
  id: uuid

  """Flag indicating whether the event pass NFT is airdropped."""
  isAirdrop: Boolean

  """
  Flag indicating whether the delayed reveal functionality is active. Can be set to true only if type is delayed_reveal.
  """
  isDelayedRevealed: Boolean
  organizerId: String

  """
  Password for the delayed reveal functionality. Nullable and only applicable for delayed_reveal type.
  """
  password: String

  """Type of the event pass NFT contract."""
  type: eventPassNftContractType_enum

  """Timestamp of the last update to the record."""
  updated_at: timestamptz
}

"""
update columns of table "eventPassNftContract"
"""
enum eventPassNftContract_update_column {
  """column name"""
  chainId

  """column name"""
  contractAddress

  """column name"""
  created_at

  """column name"""
  eventId

  """column name"""
  eventPassId

  """column name"""
  id

  """column name"""
  isAirdrop

  """column name"""
  isDelayedRevealed

  """column name"""
  organizerId

  """column name"""
  password

  """column name"""
  type

  """column name"""
  updated_at
}

input eventPassNftContract_updates {
  """sets the columns of the filtered rows to the given values"""
  _set: eventPassNftContract_set_input

  """filter the rows which have to be updated"""
  where: eventPassNftContract_bool_exp!
}

"""
aggregated selection of "eventPassNft"
"""
type eventPassNft_aggregate {
  aggregate: eventPassNft_aggregate_fields
  nodes: [eventPassNft!]!
}

input eventPassNft_aggregate_bool_exp {
  bool_and: eventPassNft_aggregate_bool_exp_bool_and
  bool_or: eventPassNft_aggregate_bool_exp_bool_or
  count: eventPassNft_aggregate_bool_exp_count
}

input eventPassNft_aggregate_bool_exp_bool_and {
  arguments: eventPassNft_select_column_eventPassNft_aggregate_bool_exp_bool_and_arguments_columns!
  distinct: Boolean
  filter: eventPassNft_bool_exp
  predicate: Boolean_comparison_exp!
}

input eventPassNft_aggregate_bool_exp_bool_or {
  arguments: eventPassNft_select_column_eventPassNft_aggregate_bool_exp_bool_or_arguments_columns!
  distinct: Boolean
  filter: eventPassNft_bool_exp
  predicate: Boolean_comparison_exp!
}

input eventPassNft_aggregate_bool_exp_count {
  arguments: [eventPassNft_select_column!]
  distinct: Boolean
  filter: eventPassNft_bool_exp
  predicate: Int_comparison_exp!
}

"""
aggregate fields of "eventPassNft"
"""
type eventPassNft_aggregate_fields {
  avg: eventPassNft_avg_fields
  count(columns: [eventPassNft_select_column!], distinct: Boolean): Int!
  max: eventPassNft_max_fields
  min: eventPassNft_min_fields
  stddev: eventPassNft_stddev_fields
  stddev_pop: eventPassNft_stddev_pop_fields
  stddev_samp: eventPassNft_stddev_samp_fields
  sum: eventPassNft_sum_fields
  var_pop: eventPassNft_var_pop_fields
  var_samp: eventPassNft_var_samp_fields
  variance: eventPassNft_variance_fields
}

"""
order by aggregate values of table "eventPassNft"
"""
input eventPassNft_aggregate_order_by {
  avg: eventPassNft_avg_order_by
  count: order_by
  max: eventPassNft_max_order_by
  min: eventPassNft_min_order_by
  stddev: eventPassNft_stddev_order_by
  stddev_pop: eventPassNft_stddev_pop_order_by
  stddev_samp: eventPassNft_stddev_samp_order_by
  sum: eventPassNft_sum_order_by
  var_pop: eventPassNft_var_pop_order_by
  var_samp: eventPassNft_var_samp_order_by
  variance: eventPassNft_variance_order_by
}

"""append existing jsonb value of filtered columns with new jsonb value"""
input eventPassNft_append_input {
  """
  The structured metadata parsed from the token URI. This contains a variety of details regarding the event pass NFT.
  """
  metadata: jsonb
}

"""
input type for inserting array relation for remote table "eventPassNft"
"""
input eventPassNft_arr_rel_insert_input {
  data: [eventPassNft_insert_input!]!

  """upsert condition"""
  on_conflict: eventPassNft_on_conflict
}

"""aggregate avg on columns"""
type eventPassNft_avg_fields {
  """
  The unique identifier of the event pass NFT within its specific collection or contract. This remains constant across various platforms.
  """
  tokenId: Float
}

"""
order by avg() on columns of table "eventPassNft"
"""
input eventPassNft_avg_order_by {
  """
  The unique identifier of the event pass NFT within its specific collection or contract. This remains constant across various platforms.
  """
  tokenId: order_by
}

"""
Boolean expression to filter rows from the table "eventPassNft". All fields are combined with a logical 'AND'.
"""
input eventPassNft_bool_exp {
  _and: [eventPassNft_bool_exp!]
  _not: eventPassNft_bool_exp
  _or: [eventPassNft_bool_exp!]
  chainId: String_comparison_exp
  contractAddress: String_comparison_exp
  created_at: timestamptz_comparison_exp
  currentOwnerAddress: String_comparison_exp
  error: String_comparison_exp
  eventId: String_comparison_exp
  eventParameters: eventParameters_bool_exp
  eventPassId: String_comparison_exp
  eventPassNftContract: eventPassNftContract_bool_exp
  eventPassPricing: eventPassPricing_bool_exp
  id: uuid_comparison_exp
  isRevealed: Boolean_comparison_exp
  lastNftTransfer: nftTransfer_bool_exp
  lastNftTransferId: uuid_comparison_exp
  metadata: jsonb_comparison_exp
  nftTransfers: nftTransfer_bool_exp
  nftTransfers_aggregate: nftTransfer_aggregate_bool_exp
  organizerId: String_comparison_exp
  packNftContract: packNftContract_bool_exp
  packNftContractId: uuid_comparison_exp
  tokenId: bigint_comparison_exp
  tokenUri: String_comparison_exp
  updated_at: timestamptz_comparison_exp
}

"""
unique or primary key constraints on table "eventPassNft"
"""
enum eventPassNft_constraint {
  """
  unique or primary key constraint on columns "chainId", "contractAddress", "tokenId"
  """
  eventPassNft_contractAddress_tokenId_chainId_key

  """
  unique or primary key constraint on columns "id"
  """
  eventPassNft_pkey

  """
  unique or primary key constraint on columns "chainId", "contractAddress", "tokenId"
  """
  event_pass_nft_unique_nft
}

"""
delete the field or element with specified path (for JSON arrays, negative integers count from the end)
"""
input eventPassNft_delete_at_path_input {
  """
  The structured metadata parsed from the token URI. This contains a variety of details regarding the event pass NFT.
  """
  metadata: [String!]
}

"""
delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
"""
input eventPassNft_delete_elem_input {
  """
  The structured metadata parsed from the token URI. This contains a variety of details regarding the event pass NFT.
  """
  metadata: Int
}

"""
delete key/value pair or string element. key/value pairs are matched based on their key value
"""
input eventPassNft_delete_key_input {
  """
  The structured metadata parsed from the token URI. This contains a variety of details regarding the event pass NFT.
  """
  metadata: String
}

"""
input type for incrementing numeric columns in table "eventPassNft"
"""
input eventPassNft_inc_input {
  """
  The unique identifier of the event pass NFT within its specific collection or contract. This remains constant across various platforms.
  """
  tokenId: bigint
}

"""
input type for inserting data into table "eventPassNft"
"""
input eventPassNft_insert_input {
  """Denotes the specific blockchain or network of the event pass NFT"""
  chainId: String

  """
  Identifies the smart contract associated with the event pass NFT. This provides a direct link to the NFT's origin and behavior on the blockchain.
  """
  contractAddress: String
  created_at: timestamptz

  """
  The address currently holding the event pass NFT, allowing tracking of ownership
  """
  currentOwnerAddress: String

  """
  Contains any error message related to metadata retrieval, ensuring transparency in the data extraction process.
  """
  error: String

  """A reference to the event associated with the event pass NFT"""
  eventId: String
  eventParameters: eventParameters_obj_rel_insert_input

  """Directly relates to a specific Event Pass within the system"""
  eventPassId: String
  eventPassNftContract: eventPassNftContract_obj_rel_insert_input
  eventPassPricing: eventPassPricing_obj_rel_insert_input
  id: uuid

  """
  Indicates whether the QR code pass for the event pass NFT has been revealed by the owner. This field is essential for tracking and managing the reveal status within the platform.
  """
  isRevealed: Boolean
  lastNftTransfer: nftTransfer_obj_rel_insert_input

  """
  Reference `id` to the latest `nftTransfer` entry, detailing the most recent transaction for this event pass NFT.
  """
  lastNftTransferId: uuid

  """
  The structured metadata parsed from the token URI. This contains a variety of details regarding the event pass NFT.
  """
  metadata: jsonb
  nftTransfers: nftTransfer_arr_rel_insert_input

  """Ties the event pass NFT to a specific organizer within the platform"""
  organizerId: String
  packNftContract: packNftContract_obj_rel_insert_input
  packNftContractId: uuid

  """
  The unique identifier of the event pass NFT within its specific collection or contract. This remains constant across various platforms.
  """
  tokenId: bigint

  """
  The designated URI for the event pass NFT's metadata blob, providing a stable reference for data extraction.
  """
  tokenUri: String
  updated_at: timestamptz
}

"""aggregate max on columns"""
type eventPassNft_max_fields {
  """Denotes the specific blockchain or network of the event pass NFT"""
  chainId: String

  """
  Identifies the smart contract associated with the event pass NFT. This provides a direct link to the NFT's origin and behavior on the blockchain.
  """
  contractAddress: String
  created_at: timestamptz

  """
  The address currently holding the event pass NFT, allowing tracking of ownership
  """
  currentOwnerAddress: String

  """
  Contains any error message related to metadata retrieval, ensuring transparency in the data extraction process.
  """
  error: String

  """A reference to the event associated with the event pass NFT"""
  eventId: String

  """Directly relates to a specific Event Pass within the system"""
  eventPassId: String
  id: uuid

  """
  Reference `id` to the latest `nftTransfer` entry, detailing the most recent transaction for this event pass NFT.
  """
  lastNftTransferId: uuid

  """Ties the event pass NFT to a specific organizer within the platform"""
  organizerId: String
  packNftContractId: uuid

  """
  The unique identifier of the event pass NFT within its specific collection or contract. This remains constant across various platforms.
  """
  tokenId: bigint

  """
  The designated URI for the event pass NFT's metadata blob, providing a stable reference for data extraction.
  """
  tokenUri: String
  updated_at: timestamptz
}

"""
order by max() on columns of table "eventPassNft"
"""
input eventPassNft_max_order_by {
  """Denotes the specific blockchain or network of the event pass NFT"""
  chainId: order_by

  """
  Identifies the smart contract associated with the event pass NFT. This provides a direct link to the NFT's origin and behavior on the blockchain.
  """
  contractAddress: order_by
  created_at: order_by

  """
  The address currently holding the event pass NFT, allowing tracking of ownership
  """
  currentOwnerAddress: order_by

  """
  Contains any error message related to metadata retrieval, ensuring transparency in the data extraction process.
  """
  error: order_by

  """A reference to the event associated with the event pass NFT"""
  eventId: order_by

  """Directly relates to a specific Event Pass within the system"""
  eventPassId: order_by
  id: order_by

  """
  Reference `id` to the latest `nftTransfer` entry, detailing the most recent transaction for this event pass NFT.
  """
  lastNftTransferId: order_by

  """Ties the event pass NFT to a specific organizer within the platform"""
  organizerId: order_by
  packNftContractId: order_by

  """
  The unique identifier of the event pass NFT within its specific collection or contract. This remains constant across various platforms.
  """
  tokenId: order_by

  """
  The designated URI for the event pass NFT's metadata blob, providing a stable reference for data extraction.
  """
  tokenUri: order_by
  updated_at: order_by
}

"""aggregate min on columns"""
type eventPassNft_min_fields {
  """Denotes the specific blockchain or network of the event pass NFT"""
  chainId: String

  """
  Identifies the smart contract associated with the event pass NFT. This provides a direct link to the NFT's origin and behavior on the blockchain.
  """
  contractAddress: String
  created_at: timestamptz

  """
  The address currently holding the event pass NFT, allowing tracking of ownership
  """
  currentOwnerAddress: String

  """
  Contains any error message related to metadata retrieval, ensuring transparency in the data extraction process.
  """
  error: String

  """A reference to the event associated with the event pass NFT"""
  eventId: String

  """Directly relates to a specific Event Pass within the system"""
  eventPassId: String
  id: uuid

  """
  Reference `id` to the latest `nftTransfer` entry, detailing the most recent transaction for this event pass NFT.
  """
  lastNftTransferId: uuid

  """Ties the event pass NFT to a specific organizer within the platform"""
  organizerId: String
  packNftContractId: uuid

  """
  The unique identifier of the event pass NFT within its specific collection or contract. This remains constant across various platforms.
  """
  tokenId: bigint

  """
  The designated URI for the event pass NFT's metadata blob, providing a stable reference for data extraction.
  """
  tokenUri: String
  updated_at: timestamptz
}

"""
order by min() on columns of table "eventPassNft"
"""
input eventPassNft_min_order_by {
  """Denotes the specific blockchain or network of the event pass NFT"""
  chainId: order_by

  """
  Identifies the smart contract associated with the event pass NFT. This provides a direct link to the NFT's origin and behavior on the blockchain.
  """
  contractAddress: order_by
  created_at: order_by

  """
  The address currently holding the event pass NFT, allowing tracking of ownership
  """
  currentOwnerAddress: order_by

  """
  Contains any error message related to metadata retrieval, ensuring transparency in the data extraction process.
  """
  error: order_by

  """A reference to the event associated with the event pass NFT"""
  eventId: order_by

  """Directly relates to a specific Event Pass within the system"""
  eventPassId: order_by
  id: order_by

  """
  Reference `id` to the latest `nftTransfer` entry, detailing the most recent transaction for this event pass NFT.
  """
  lastNftTransferId: order_by

  """Ties the event pass NFT to a specific organizer within the platform"""
  organizerId: order_by
  packNftContractId: order_by

  """
  The unique identifier of the event pass NFT within its specific collection or contract. This remains constant across various platforms.
  """
  tokenId: order_by

  """
  The designated URI for the event pass NFT's metadata blob, providing a stable reference for data extraction.
  """
  tokenUri: order_by
  updated_at: order_by
}

"""
response of any mutation on the table "eventPassNft"
"""
type eventPassNft_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [eventPassNft!]!
}

"""
on_conflict condition type for table "eventPassNft"
"""
input eventPassNft_on_conflict {
  constraint: eventPassNft_constraint!
  update_columns: [eventPassNft_update_column!]! = []
  where: eventPassNft_bool_exp
}

"""Ordering options when selecting data from "eventPassNft"."""
input eventPassNft_order_by {
  chainId: order_by
  contractAddress: order_by
  created_at: order_by
  currentOwnerAddress: order_by
  error: order_by
  eventId: order_by
  eventParameters: eventParameters_order_by
  eventPassId: order_by
  eventPassNftContract: eventPassNftContract_order_by
  eventPassPricing: eventPassPricing_order_by
  id: order_by
  isRevealed: order_by
  lastNftTransfer: nftTransfer_order_by
  lastNftTransferId: order_by
  metadata: order_by
  nftTransfers_aggregate: nftTransfer_aggregate_order_by
  organizerId: order_by
  packNftContract: packNftContract_order_by
  packNftContractId: order_by
  tokenId: order_by
  tokenUri: order_by
  updated_at: order_by
}

"""primary key columns input for table: eventPassNft"""
input eventPassNft_pk_columns_input {
  id: uuid!
}

"""prepend existing jsonb value of filtered columns with new jsonb value"""
input eventPassNft_prepend_input {
  """
  The structured metadata parsed from the token URI. This contains a variety of details regarding the event pass NFT.
  """
  metadata: jsonb
}

"""
select columns of table "eventPassNft"
"""
enum eventPassNft_select_column {
  """column name"""
  chainId

  """column name"""
  contractAddress

  """column name"""
  created_at

  """column name"""
  currentOwnerAddress

  """column name"""
  error

  """column name"""
  eventId

  """column name"""
  eventPassId

  """column name"""
  id

  """column name"""
  isRevealed

  """column name"""
  lastNftTransferId

  """column name"""
  metadata

  """column name"""
  organizerId

  """column name"""
  packNftContractId

  """column name"""
  tokenId

  """column name"""
  tokenUri

  """column name"""
  updated_at
}

"""
select "eventPassNft_aggregate_bool_exp_bool_and_arguments_columns" columns of table "eventPassNft"
"""
enum eventPassNft_select_column_eventPassNft_aggregate_bool_exp_bool_and_arguments_columns {
  """column name"""
  isRevealed
}

"""
select "eventPassNft_aggregate_bool_exp_bool_or_arguments_columns" columns of table "eventPassNft"
"""
enum eventPassNft_select_column_eventPassNft_aggregate_bool_exp_bool_or_arguments_columns {
  """column name"""
  isRevealed
}

"""
input type for updating data in table "eventPassNft"
"""
input eventPassNft_set_input {
  """Denotes the specific blockchain or network of the event pass NFT"""
  chainId: String

  """
  Identifies the smart contract associated with the event pass NFT. This provides a direct link to the NFT's origin and behavior on the blockchain.
  """
  contractAddress: String
  created_at: timestamptz

  """
  The address currently holding the event pass NFT, allowing tracking of ownership
  """
  currentOwnerAddress: String

  """
  Contains any error message related to metadata retrieval, ensuring transparency in the data extraction process.
  """
  error: String

  """A reference to the event associated with the event pass NFT"""
  eventId: String

  """Directly relates to a specific Event Pass within the system"""
  eventPassId: String
  id: uuid

  """
  Indicates whether the QR code pass for the event pass NFT has been revealed by the owner. This field is essential for tracking and managing the reveal status within the platform.
  """
  isRevealed: Boolean

  """
  Reference `id` to the latest `nftTransfer` entry, detailing the most recent transaction for this event pass NFT.
  """
  lastNftTransferId: uuid

  """
  The structured metadata parsed from the token URI. This contains a variety of details regarding the event pass NFT.
  """
  metadata: jsonb

  """Ties the event pass NFT to a specific organizer within the platform"""
  organizerId: String
  packNftContractId: uuid

  """
  The unique identifier of the event pass NFT within its specific collection or contract. This remains constant across various platforms.
  """
  tokenId: bigint

  """
  The designated URI for the event pass NFT's metadata blob, providing a stable reference for data extraction.
  """
  tokenUri: String
  updated_at: timestamptz
}

"""aggregate stddev on columns"""
type eventPassNft_stddev_fields {
  """
  The unique identifier of the event pass NFT within its specific collection or contract. This remains constant across various platforms.
  """
  tokenId: Float
}

"""
order by stddev() on columns of table "eventPassNft"
"""
input eventPassNft_stddev_order_by {
  """
  The unique identifier of the event pass NFT within its specific collection or contract. This remains constant across various platforms.
  """
  tokenId: order_by
}

"""aggregate stddev_pop on columns"""
type eventPassNft_stddev_pop_fields {
  """
  The unique identifier of the event pass NFT within its specific collection or contract. This remains constant across various platforms.
  """
  tokenId: Float
}

"""
order by stddev_pop() on columns of table "eventPassNft"
"""
input eventPassNft_stddev_pop_order_by {
  """
  The unique identifier of the event pass NFT within its specific collection or contract. This remains constant across various platforms.
  """
  tokenId: order_by
}

"""aggregate stddev_samp on columns"""
type eventPassNft_stddev_samp_fields {
  """
  The unique identifier of the event pass NFT within its specific collection or contract. This remains constant across various platforms.
  """
  tokenId: Float
}

"""
order by stddev_samp() on columns of table "eventPassNft"
"""
input eventPassNft_stddev_samp_order_by {
  """
  The unique identifier of the event pass NFT within its specific collection or contract. This remains constant across various platforms.
  """
  tokenId: order_by
}

"""
Streaming cursor of the table "eventPassNft"
"""
input eventPassNft_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: eventPassNft_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input eventPassNft_stream_cursor_value_input {
  """Denotes the specific blockchain or network of the event pass NFT"""
  chainId: String

  """
  Identifies the smart contract associated with the event pass NFT. This provides a direct link to the NFT's origin and behavior on the blockchain.
  """
  contractAddress: String
  created_at: timestamptz

  """
  The address currently holding the event pass NFT, allowing tracking of ownership
  """
  currentOwnerAddress: String

  """
  Contains any error message related to metadata retrieval, ensuring transparency in the data extraction process.
  """
  error: String

  """A reference to the event associated with the event pass NFT"""
  eventId: String

  """Directly relates to a specific Event Pass within the system"""
  eventPassId: String
  id: uuid

  """
  Indicates whether the QR code pass for the event pass NFT has been revealed by the owner. This field is essential for tracking and managing the reveal status within the platform.
  """
  isRevealed: Boolean

  """
  Reference `id` to the latest `nftTransfer` entry, detailing the most recent transaction for this event pass NFT.
  """
  lastNftTransferId: uuid

  """
  The structured metadata parsed from the token URI. This contains a variety of details regarding the event pass NFT.
  """
  metadata: jsonb

  """Ties the event pass NFT to a specific organizer within the platform"""
  organizerId: String
  packNftContractId: uuid

  """
  The unique identifier of the event pass NFT within its specific collection or contract. This remains constant across various platforms.
  """
  tokenId: bigint

  """
  The designated URI for the event pass NFT's metadata blob, providing a stable reference for data extraction.
  """
  tokenUri: String
  updated_at: timestamptz
}

"""aggregate sum on columns"""
type eventPassNft_sum_fields {
  """
  The unique identifier of the event pass NFT within its specific collection or contract. This remains constant across various platforms.
  """
  tokenId: bigint
}

"""
order by sum() on columns of table "eventPassNft"
"""
input eventPassNft_sum_order_by {
  """
  The unique identifier of the event pass NFT within its specific collection or contract. This remains constant across various platforms.
  """
  tokenId: order_by
}

"""
update columns of table "eventPassNft"
"""
enum eventPassNft_update_column {
  """column name"""
  chainId

  """column name"""
  contractAddress

  """column name"""
  created_at

  """column name"""
  currentOwnerAddress

  """column name"""
  error

  """column name"""
  eventId

  """column name"""
  eventPassId

  """column name"""
  id

  """column name"""
  isRevealed

  """column name"""
  lastNftTransferId

  """column name"""
  metadata

  """column name"""
  organizerId

  """column name"""
  packNftContractId

  """column name"""
  tokenId

  """column name"""
  tokenUri

  """column name"""
  updated_at
}

input eventPassNft_updates {
  """append existing jsonb value of filtered columns with new jsonb value"""
  _append: eventPassNft_append_input

  """
  delete the field or element with specified path (for JSON arrays, negative integers count from the end)
  """
  _delete_at_path: eventPassNft_delete_at_path_input

  """
  delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
  """
  _delete_elem: eventPassNft_delete_elem_input

  """
  delete key/value pair or string element. key/value pairs are matched based on their key value
  """
  _delete_key: eventPassNft_delete_key_input

  """increments the numeric columns with given value of the filtered values"""
  _inc: eventPassNft_inc_input

  """prepend existing jsonb value of filtered columns with new jsonb value"""
  _prepend: eventPassNft_prepend_input

  """sets the columns of the filtered rows to the given values"""
  _set: eventPassNft_set_input

  """filter the rows which have to be updated"""
  where: eventPassNft_bool_exp!
}

"""aggregate var_pop on columns"""
type eventPassNft_var_pop_fields {
  """
  The unique identifier of the event pass NFT within its specific collection or contract. This remains constant across various platforms.
  """
  tokenId: Float
}

"""
order by var_pop() on columns of table "eventPassNft"
"""
input eventPassNft_var_pop_order_by {
  """
  The unique identifier of the event pass NFT within its specific collection or contract. This remains constant across various platforms.
  """
  tokenId: order_by
}

"""aggregate var_samp on columns"""
type eventPassNft_var_samp_fields {
  """
  The unique identifier of the event pass NFT within its specific collection or contract. This remains constant across various platforms.
  """
  tokenId: Float
}

"""
order by var_samp() on columns of table "eventPassNft"
"""
input eventPassNft_var_samp_order_by {
  """
  The unique identifier of the event pass NFT within its specific collection or contract. This remains constant across various platforms.
  """
  tokenId: order_by
}

"""aggregate variance on columns"""
type eventPassNft_variance_fields {
  """
  The unique identifier of the event pass NFT within its specific collection or contract. This remains constant across various platforms.
  """
  tokenId: Float
}

"""
order by variance() on columns of table "eventPassNft"
"""
input eventPassNft_variance_order_by {
  """
  The unique identifier of the event pass NFT within its specific collection or contract. This remains constant across various platforms.
  """
  tokenId: order_by
}

"""
Order with as quantity for Event Pass (linked to Hygraph model EventPass) and associated to an Account
"""
type eventPassOrder {
  """An object relationship"""
  account: account
  accountId: uuid!
  created_at: timestamptz!
  eventPass(
    """
    Defines which locales should be returned.
    
    Note that `EventPass` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, entries with non matching locales will be filtered out.
    
    This argument may be overwritten by another locales definition in a relational child field, this will effectively use the overwritten argument for the affected query's subtree.
    """
    locales: [Locale!]! = [en]
    stage: Stage! = PUBLISHED
  ): EventPass
  eventPassId: String!

  """An object relationship"""
  eventPassNftContract: eventPassNftContract

  """An object relationship"""
  eventPassPricing: eventPassPricing
  id: uuid!
  quantity: Int!
  status: orderStatus_enum!
  stripeCheckoutSessionId: String
  updated_at: timestamptz!
}

"""Hold the sums for the Event Pass Orders"""
type eventPassOrderSums {
  eventPassId: String!
  totalReserved: Int!
}

"""
aggregated selection of "eventPassOrderSums"
"""
type eventPassOrderSums_aggregate {
  aggregate: eventPassOrderSums_aggregate_fields
  nodes: [eventPassOrderSums!]!
}

"""
aggregate fields of "eventPassOrderSums"
"""
type eventPassOrderSums_aggregate_fields {
  avg: eventPassOrderSums_avg_fields
  count(columns: [eventPassOrderSums_select_column!], distinct: Boolean): Int!
  max: eventPassOrderSums_max_fields
  min: eventPassOrderSums_min_fields
  stddev: eventPassOrderSums_stddev_fields
  stddev_pop: eventPassOrderSums_stddev_pop_fields
  stddev_samp: eventPassOrderSums_stddev_samp_fields
  sum: eventPassOrderSums_sum_fields
  var_pop: eventPassOrderSums_var_pop_fields
  var_samp: eventPassOrderSums_var_samp_fields
  variance: eventPassOrderSums_variance_fields
}

"""aggregate avg on columns"""
type eventPassOrderSums_avg_fields {
  totalReserved: Float
}

"""
Boolean expression to filter rows from the table "eventPassOrderSums". All fields are combined with a logical 'AND'.
"""
input eventPassOrderSums_bool_exp {
  _and: [eventPassOrderSums_bool_exp!]
  _not: eventPassOrderSums_bool_exp
  _or: [eventPassOrderSums_bool_exp!]
  eventPassId: String_comparison_exp
  totalReserved: Int_comparison_exp
}

"""
unique or primary key constraints on table "eventPassOrderSums"
"""
enum eventPassOrderSums_constraint {
  """
  unique or primary key constraint on columns "eventPassId"
  """
  eventPassOrderSums_pkey
}

"""
input type for incrementing numeric columns in table "eventPassOrderSums"
"""
input eventPassOrderSums_inc_input {
  totalReserved: Int
}

"""
input type for inserting data into table "eventPassOrderSums"
"""
input eventPassOrderSums_insert_input {
  eventPassId: String
  totalReserved: Int
}

"""aggregate max on columns"""
type eventPassOrderSums_max_fields {
  eventPassId: String
  totalReserved: Int
}

"""aggregate min on columns"""
type eventPassOrderSums_min_fields {
  eventPassId: String
  totalReserved: Int
}

"""
response of any mutation on the table "eventPassOrderSums"
"""
type eventPassOrderSums_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [eventPassOrderSums!]!
}

"""
input type for inserting object relation for remote table "eventPassOrderSums"
"""
input eventPassOrderSums_obj_rel_insert_input {
  data: eventPassOrderSums_insert_input!

  """upsert condition"""
  on_conflict: eventPassOrderSums_on_conflict
}

"""
on_conflict condition type for table "eventPassOrderSums"
"""
input eventPassOrderSums_on_conflict {
  constraint: eventPassOrderSums_constraint!
  update_columns: [eventPassOrderSums_update_column!]! = []
  where: eventPassOrderSums_bool_exp
}

"""Ordering options when selecting data from "eventPassOrderSums"."""
input eventPassOrderSums_order_by {
  eventPassId: order_by
  totalReserved: order_by
}

"""primary key columns input for table: eventPassOrderSums"""
input eventPassOrderSums_pk_columns_input {
  eventPassId: String!
}

"""
select columns of table "eventPassOrderSums"
"""
enum eventPassOrderSums_select_column {
  """column name"""
  eventPassId

  """column name"""
  totalReserved
}

"""
input type for updating data in table "eventPassOrderSums"
"""
input eventPassOrderSums_set_input {
  eventPassId: String
  totalReserved: Int
}

"""aggregate stddev on columns"""
type eventPassOrderSums_stddev_fields {
  totalReserved: Float
}

"""aggregate stddev_pop on columns"""
type eventPassOrderSums_stddev_pop_fields {
  totalReserved: Float
}

"""aggregate stddev_samp on columns"""
type eventPassOrderSums_stddev_samp_fields {
  totalReserved: Float
}

"""
Streaming cursor of the table "eventPassOrderSums"
"""
input eventPassOrderSums_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: eventPassOrderSums_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input eventPassOrderSums_stream_cursor_value_input {
  eventPassId: String
  totalReserved: Int
}

"""aggregate sum on columns"""
type eventPassOrderSums_sum_fields {
  totalReserved: Int
}

"""
update columns of table "eventPassOrderSums"
"""
enum eventPassOrderSums_update_column {
  """column name"""
  eventPassId

  """column name"""
  totalReserved
}

input eventPassOrderSums_updates {
  """increments the numeric columns with given value of the filtered values"""
  _inc: eventPassOrderSums_inc_input

  """sets the columns of the filtered rows to the given values"""
  _set: eventPassOrderSums_set_input

  """filter the rows which have to be updated"""
  where: eventPassOrderSums_bool_exp!
}

"""aggregate var_pop on columns"""
type eventPassOrderSums_var_pop_fields {
  totalReserved: Float
}

"""aggregate var_samp on columns"""
type eventPassOrderSums_var_samp_fields {
  totalReserved: Float
}

"""aggregate variance on columns"""
type eventPassOrderSums_variance_fields {
  totalReserved: Float
}

"""
aggregated selection of "eventPassOrder"
"""
type eventPassOrder_aggregate {
  aggregate: eventPassOrder_aggregate_fields
  nodes: [eventPassOrder!]!
}

input eventPassOrder_aggregate_bool_exp {
  count: eventPassOrder_aggregate_bool_exp_count
}

input eventPassOrder_aggregate_bool_exp_count {
  arguments: [eventPassOrder_select_column!]
  distinct: Boolean
  filter: eventPassOrder_bool_exp
  predicate: Int_comparison_exp!
}

"""
aggregate fields of "eventPassOrder"
"""
type eventPassOrder_aggregate_fields {
  avg: eventPassOrder_avg_fields
  count(columns: [eventPassOrder_select_column!], distinct: Boolean): Int!
  max: eventPassOrder_max_fields
  min: eventPassOrder_min_fields
  stddev: eventPassOrder_stddev_fields
  stddev_pop: eventPassOrder_stddev_pop_fields
  stddev_samp: eventPassOrder_stddev_samp_fields
  sum: eventPassOrder_sum_fields
  var_pop: eventPassOrder_var_pop_fields
  var_samp: eventPassOrder_var_samp_fields
  variance: eventPassOrder_variance_fields
}

"""
order by aggregate values of table "eventPassOrder"
"""
input eventPassOrder_aggregate_order_by {
  avg: eventPassOrder_avg_order_by
  count: order_by
  max: eventPassOrder_max_order_by
  min: eventPassOrder_min_order_by
  stddev: eventPassOrder_stddev_order_by
  stddev_pop: eventPassOrder_stddev_pop_order_by
  stddev_samp: eventPassOrder_stddev_samp_order_by
  sum: eventPassOrder_sum_order_by
  var_pop: eventPassOrder_var_pop_order_by
  var_samp: eventPassOrder_var_samp_order_by
  variance: eventPassOrder_variance_order_by
}

"""
input type for inserting array relation for remote table "eventPassOrder"
"""
input eventPassOrder_arr_rel_insert_input {
  data: [eventPassOrder_insert_input!]!

  """upsert condition"""
  on_conflict: eventPassOrder_on_conflict
}

"""aggregate avg on columns"""
type eventPassOrder_avg_fields {
  quantity: Float
}

"""
order by avg() on columns of table "eventPassOrder"
"""
input eventPassOrder_avg_order_by {
  quantity: order_by
}

"""
Boolean expression to filter rows from the table "eventPassOrder". All fields are combined with a logical 'AND'.
"""
input eventPassOrder_bool_exp {
  _and: [eventPassOrder_bool_exp!]
  _not: eventPassOrder_bool_exp
  _or: [eventPassOrder_bool_exp!]
  account: account_bool_exp
  accountId: uuid_comparison_exp
  created_at: timestamptz_comparison_exp
  eventPassId: String_comparison_exp
  eventPassNftContract: eventPassNftContract_bool_exp
  eventPassPricing: eventPassPricing_bool_exp
  id: uuid_comparison_exp
  quantity: Int_comparison_exp
  status: orderStatus_enum_comparison_exp
  stripeCheckoutSessionId: String_comparison_exp
  updated_at: timestamptz_comparison_exp
}

"""
unique or primary key constraints on table "eventPassOrder"
"""
enum eventPassOrder_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  eventPassOrder_pkey
}

"""
input type for incrementing numeric columns in table "eventPassOrder"
"""
input eventPassOrder_inc_input {
  quantity: Int
}

"""
input type for inserting data into table "eventPassOrder"
"""
input eventPassOrder_insert_input {
  account: account_obj_rel_insert_input
  accountId: uuid
  created_at: timestamptz
  eventPassId: String
  eventPassNftContract: eventPassNftContract_obj_rel_insert_input
  eventPassPricing: eventPassPricing_obj_rel_insert_input
  id: uuid
  quantity: Int
  status: orderStatus_enum
  stripeCheckoutSessionId: String
  updated_at: timestamptz
}

"""aggregate max on columns"""
type eventPassOrder_max_fields {
  accountId: uuid
  created_at: timestamptz
  eventPassId: String
  id: uuid
  quantity: Int
  stripeCheckoutSessionId: String
  updated_at: timestamptz
}

"""
order by max() on columns of table "eventPassOrder"
"""
input eventPassOrder_max_order_by {
  accountId: order_by
  created_at: order_by
  eventPassId: order_by
  id: order_by
  quantity: order_by
  stripeCheckoutSessionId: order_by
  updated_at: order_by
}

"""aggregate min on columns"""
type eventPassOrder_min_fields {
  accountId: uuid
  created_at: timestamptz
  eventPassId: String
  id: uuid
  quantity: Int
  stripeCheckoutSessionId: String
  updated_at: timestamptz
}

"""
order by min() on columns of table "eventPassOrder"
"""
input eventPassOrder_min_order_by {
  accountId: order_by
  created_at: order_by
  eventPassId: order_by
  id: order_by
  quantity: order_by
  stripeCheckoutSessionId: order_by
  updated_at: order_by
}

"""
response of any mutation on the table "eventPassOrder"
"""
type eventPassOrder_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [eventPassOrder!]!
}

"""
on_conflict condition type for table "eventPassOrder"
"""
input eventPassOrder_on_conflict {
  constraint: eventPassOrder_constraint!
  update_columns: [eventPassOrder_update_column!]! = []
  where: eventPassOrder_bool_exp
}

"""Ordering options when selecting data from "eventPassOrder"."""
input eventPassOrder_order_by {
  account: account_order_by
  accountId: order_by
  created_at: order_by
  eventPassId: order_by
  eventPassNftContract: eventPassNftContract_order_by
  eventPassPricing: eventPassPricing_order_by
  id: order_by
  quantity: order_by
  status: order_by
  stripeCheckoutSessionId: order_by
  updated_at: order_by
}

"""primary key columns input for table: eventPassOrder"""
input eventPassOrder_pk_columns_input {
  id: uuid!
}

"""
select columns of table "eventPassOrder"
"""
enum eventPassOrder_select_column {
  """column name"""
  accountId

  """column name"""
  created_at

  """column name"""
  eventPassId

  """column name"""
  id

  """column name"""
  quantity

  """column name"""
  status

  """column name"""
  stripeCheckoutSessionId

  """column name"""
  updated_at
}

"""
input type for updating data in table "eventPassOrder"
"""
input eventPassOrder_set_input {
  accountId: uuid
  created_at: timestamptz
  eventPassId: String
  id: uuid
  quantity: Int
  status: orderStatus_enum
  stripeCheckoutSessionId: String
  updated_at: timestamptz
}

"""aggregate stddev on columns"""
type eventPassOrder_stddev_fields {
  quantity: Float
}

"""
order by stddev() on columns of table "eventPassOrder"
"""
input eventPassOrder_stddev_order_by {
  quantity: order_by
}

"""aggregate stddev_pop on columns"""
type eventPassOrder_stddev_pop_fields {
  quantity: Float
}

"""
order by stddev_pop() on columns of table "eventPassOrder"
"""
input eventPassOrder_stddev_pop_order_by {
  quantity: order_by
}

"""aggregate stddev_samp on columns"""
type eventPassOrder_stddev_samp_fields {
  quantity: Float
}

"""
order by stddev_samp() on columns of table "eventPassOrder"
"""
input eventPassOrder_stddev_samp_order_by {
  quantity: order_by
}

"""
Streaming cursor of the table "eventPassOrder"
"""
input eventPassOrder_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: eventPassOrder_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input eventPassOrder_stream_cursor_value_input {
  accountId: uuid
  created_at: timestamptz
  eventPassId: String
  id: uuid
  quantity: Int
  status: orderStatus_enum
  stripeCheckoutSessionId: String
  updated_at: timestamptz
}

"""aggregate sum on columns"""
type eventPassOrder_sum_fields {
  quantity: Int
}

"""
order by sum() on columns of table "eventPassOrder"
"""
input eventPassOrder_sum_order_by {
  quantity: order_by
}

"""
update columns of table "eventPassOrder"
"""
enum eventPassOrder_update_column {
  """column name"""
  accountId

  """column name"""
  created_at

  """column name"""
  eventPassId

  """column name"""
  id

  """column name"""
  quantity

  """column name"""
  status

  """column name"""
  stripeCheckoutSessionId

  """column name"""
  updated_at
}

input eventPassOrder_updates {
  """increments the numeric columns with given value of the filtered values"""
  _inc: eventPassOrder_inc_input

  """sets the columns of the filtered rows to the given values"""
  _set: eventPassOrder_set_input

  """filter the rows which have to be updated"""
  where: eventPassOrder_bool_exp!
}

"""aggregate var_pop on columns"""
type eventPassOrder_var_pop_fields {
  quantity: Float
}

"""
order by var_pop() on columns of table "eventPassOrder"
"""
input eventPassOrder_var_pop_order_by {
  quantity: order_by
}

"""aggregate var_samp on columns"""
type eventPassOrder_var_samp_fields {
  quantity: Float
}

"""
order by var_samp() on columns of table "eventPassOrder"
"""
input eventPassOrder_var_samp_order_by {
  quantity: order_by
}

"""aggregate variance on columns"""
type eventPassOrder_variance_fields {
  quantity: Float
}

"""
order by variance() on columns of table "eventPassOrder"
"""
input eventPassOrder_variance_order_by {
  quantity: order_by
}

"""
Pending Order with as quantity for Event Pass (linked to Hygraph model EventPass) and associated to an Account. 
  Those orders are time bound and are automatically destroyed given an amount of time to preserve access to the event for other users.
"""
type eventPassPendingOrder {
  """An object relationship"""
  account: account
  accountId: uuid!
  created_at: timestamptz!
  eventPass(
    """
    Defines which locales should be returned.
    
    Note that `EventPass` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, entries with non matching locales will be filtered out.
    
    This argument may be overwritten by another locales definition in a relational child field, this will effectively use the overwritten argument for the affected query's subtree.
    """
    locales: [Locale!]! = [en]
    stage: Stage! = PUBLISHED
  ): EventPass
  eventPassId: String!

  """An object relationship"""
  eventPassPricing: eventPassPricing
  id: uuid!
  quantity: Int!
}

"""
aggregated selection of "eventPassPendingOrder"
"""
type eventPassPendingOrder_aggregate {
  aggregate: eventPassPendingOrder_aggregate_fields
  nodes: [eventPassPendingOrder!]!
}

"""
aggregate fields of "eventPassPendingOrder"
"""
type eventPassPendingOrder_aggregate_fields {
  avg: eventPassPendingOrder_avg_fields
  count(columns: [eventPassPendingOrder_select_column!], distinct: Boolean): Int!
  max: eventPassPendingOrder_max_fields
  min: eventPassPendingOrder_min_fields
  stddev: eventPassPendingOrder_stddev_fields
  stddev_pop: eventPassPendingOrder_stddev_pop_fields
  stddev_samp: eventPassPendingOrder_stddev_samp_fields
  sum: eventPassPendingOrder_sum_fields
  var_pop: eventPassPendingOrder_var_pop_fields
  var_samp: eventPassPendingOrder_var_samp_fields
  variance: eventPassPendingOrder_variance_fields
}

"""aggregate avg on columns"""
type eventPassPendingOrder_avg_fields {
  quantity: Float
}

"""
Boolean expression to filter rows from the table "eventPassPendingOrder". All fields are combined with a logical 'AND'.
"""
input eventPassPendingOrder_bool_exp {
  _and: [eventPassPendingOrder_bool_exp!]
  _not: eventPassPendingOrder_bool_exp
  _or: [eventPassPendingOrder_bool_exp!]
  account: account_bool_exp
  accountId: uuid_comparison_exp
  created_at: timestamptz_comparison_exp
  eventPassId: String_comparison_exp
  eventPassPricing: eventPassPricing_bool_exp
  id: uuid_comparison_exp
  quantity: Int_comparison_exp
}

"""
unique or primary key constraints on table "eventPassPendingOrder"
"""
enum eventPassPendingOrder_constraint {
  """
  unique or primary key constraint on columns "eventPassId", "accountId"
  """
  eventPassPendingOrder_eventPassId_accountId_key

  """
  unique or primary key constraint on columns "id"
  """
  eventPassPendingOrder_pkey
}

"""
input type for incrementing numeric columns in table "eventPassPendingOrder"
"""
input eventPassPendingOrder_inc_input {
  quantity: Int
}

"""
input type for inserting data into table "eventPassPendingOrder"
"""
input eventPassPendingOrder_insert_input {
  account: account_obj_rel_insert_input
  accountId: uuid
  created_at: timestamptz
  eventPassId: String
  eventPassPricing: eventPassPricing_obj_rel_insert_input
  id: uuid
  quantity: Int
}

"""aggregate max on columns"""
type eventPassPendingOrder_max_fields {
  accountId: uuid
  created_at: timestamptz
  eventPassId: String
  id: uuid
  quantity: Int
}

"""aggregate min on columns"""
type eventPassPendingOrder_min_fields {
  accountId: uuid
  created_at: timestamptz
  eventPassId: String
  id: uuid
  quantity: Int
}

"""
response of any mutation on the table "eventPassPendingOrder"
"""
type eventPassPendingOrder_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [eventPassPendingOrder!]!
}

"""
on_conflict condition type for table "eventPassPendingOrder"
"""
input eventPassPendingOrder_on_conflict {
  constraint: eventPassPendingOrder_constraint!
  update_columns: [eventPassPendingOrder_update_column!]! = []
  where: eventPassPendingOrder_bool_exp
}

"""Ordering options when selecting data from "eventPassPendingOrder"."""
input eventPassPendingOrder_order_by {
  account: account_order_by
  accountId: order_by
  created_at: order_by
  eventPassId: order_by
  eventPassPricing: eventPassPricing_order_by
  id: order_by
  quantity: order_by
}

"""primary key columns input for table: eventPassPendingOrder"""
input eventPassPendingOrder_pk_columns_input {
  id: uuid!
}

"""
select columns of table "eventPassPendingOrder"
"""
enum eventPassPendingOrder_select_column {
  """column name"""
  accountId

  """column name"""
  created_at

  """column name"""
  eventPassId

  """column name"""
  id

  """column name"""
  quantity
}

"""
input type for updating data in table "eventPassPendingOrder"
"""
input eventPassPendingOrder_set_input {
  accountId: uuid
  created_at: timestamptz
  eventPassId: String
  id: uuid
  quantity: Int
}

"""aggregate stddev on columns"""
type eventPassPendingOrder_stddev_fields {
  quantity: Float
}

"""aggregate stddev_pop on columns"""
type eventPassPendingOrder_stddev_pop_fields {
  quantity: Float
}

"""aggregate stddev_samp on columns"""
type eventPassPendingOrder_stddev_samp_fields {
  quantity: Float
}

"""
Streaming cursor of the table "eventPassPendingOrder"
"""
input eventPassPendingOrder_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: eventPassPendingOrder_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input eventPassPendingOrder_stream_cursor_value_input {
  accountId: uuid
  created_at: timestamptz
  eventPassId: String
  id: uuid
  quantity: Int
}

"""aggregate sum on columns"""
type eventPassPendingOrder_sum_fields {
  quantity: Int
}

"""
update columns of table "eventPassPendingOrder"
"""
enum eventPassPendingOrder_update_column {
  """column name"""
  accountId

  """column name"""
  created_at

  """column name"""
  eventPassId

  """column name"""
  id

  """column name"""
  quantity
}

input eventPassPendingOrder_updates {
  """increments the numeric columns with given value of the filtered values"""
  _inc: eventPassPendingOrder_inc_input

  """sets the columns of the filtered rows to the given values"""
  _set: eventPassPendingOrder_set_input

  """filter the rows which have to be updated"""
  where: eventPassPendingOrder_bool_exp!
}

"""aggregate var_pop on columns"""
type eventPassPendingOrder_var_pop_fields {
  quantity: Float
}

"""aggregate var_samp on columns"""
type eventPassPendingOrder_var_samp_fields {
  quantity: Float
}

"""aggregate variance on columns"""
type eventPassPendingOrder_variance_fields {
  quantity: Float
}

"""
The EventPassPricing table stores pricing information related to each Event Pass. It includes the price amount, the currency in which the price is denoted, and the maximum quantity that can be ordered both overall and per user. Each row in the table represents a unique combination of these attributes for a specific Event Pass. This table is key in managing the sales and availability of Event Passes.
"""
type eventPassPricing {
  created_at: timestamptz!
  eventPassId: String!
  id: uuid!
  maxAmount: Int!
  maxAmountPerUser: Int
  priceAmount: Int!
  priceCurrency: currency_enum!
  timeBeforeDelete: Int!
  updated_at: timestamptz!
}

"""
aggregated selection of "eventPassPricing"
"""
type eventPassPricing_aggregate {
  aggregate: eventPassPricing_aggregate_fields
  nodes: [eventPassPricing!]!
}

"""
aggregate fields of "eventPassPricing"
"""
type eventPassPricing_aggregate_fields {
  avg: eventPassPricing_avg_fields
  count(columns: [eventPassPricing_select_column!], distinct: Boolean): Int!
  max: eventPassPricing_max_fields
  min: eventPassPricing_min_fields
  stddev: eventPassPricing_stddev_fields
  stddev_pop: eventPassPricing_stddev_pop_fields
  stddev_samp: eventPassPricing_stddev_samp_fields
  sum: eventPassPricing_sum_fields
  var_pop: eventPassPricing_var_pop_fields
  var_samp: eventPassPricing_var_samp_fields
  variance: eventPassPricing_variance_fields
}

"""aggregate avg on columns"""
type eventPassPricing_avg_fields {
  maxAmount: Float
  maxAmountPerUser: Float
  priceAmount: Float
  timeBeforeDelete: Float
}

"""
Boolean expression to filter rows from the table "eventPassPricing". All fields are combined with a logical 'AND'.
"""
input eventPassPricing_bool_exp {
  _and: [eventPassPricing_bool_exp!]
  _not: eventPassPricing_bool_exp
  _or: [eventPassPricing_bool_exp!]
  created_at: timestamptz_comparison_exp
  eventPassId: String_comparison_exp
  id: uuid_comparison_exp
  maxAmount: Int_comparison_exp
  maxAmountPerUser: Int_comparison_exp
  priceAmount: Int_comparison_exp
  priceCurrency: currency_enum_comparison_exp
  timeBeforeDelete: Int_comparison_exp
  updated_at: timestamptz_comparison_exp
}

"""
unique or primary key constraints on table "eventPassPricing"
"""
enum eventPassPricing_constraint {
  """
  unique or primary key constraint on columns "eventPassId"
  """
  eventPassPricing_eventPassId_key

  """
  unique or primary key constraint on columns "id"
  """
  eventPassPricing_pkey
}

"""
input type for incrementing numeric columns in table "eventPassPricing"
"""
input eventPassPricing_inc_input {
  maxAmount: Int
  maxAmountPerUser: Int
  priceAmount: Int
  timeBeforeDelete: Int
}

"""
input type for inserting data into table "eventPassPricing"
"""
input eventPassPricing_insert_input {
  created_at: timestamptz
  eventPassId: String
  id: uuid
  maxAmount: Int
  maxAmountPerUser: Int
  priceAmount: Int
  priceCurrency: currency_enum
  timeBeforeDelete: Int
  updated_at: timestamptz
}

"""aggregate max on columns"""
type eventPassPricing_max_fields {
  created_at: timestamptz
  eventPassId: String
  id: uuid
  maxAmount: Int
  maxAmountPerUser: Int
  priceAmount: Int
  timeBeforeDelete: Int
  updated_at: timestamptz
}

"""aggregate min on columns"""
type eventPassPricing_min_fields {
  created_at: timestamptz
  eventPassId: String
  id: uuid
  maxAmount: Int
  maxAmountPerUser: Int
  priceAmount: Int
  timeBeforeDelete: Int
  updated_at: timestamptz
}

"""
response of any mutation on the table "eventPassPricing"
"""
type eventPassPricing_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [eventPassPricing!]!
}

"""
input type for inserting object relation for remote table "eventPassPricing"
"""
input eventPassPricing_obj_rel_insert_input {
  data: eventPassPricing_insert_input!

  """upsert condition"""
  on_conflict: eventPassPricing_on_conflict
}

"""
on_conflict condition type for table "eventPassPricing"
"""
input eventPassPricing_on_conflict {
  constraint: eventPassPricing_constraint!
  update_columns: [eventPassPricing_update_column!]! = []
  where: eventPassPricing_bool_exp
}

"""Ordering options when selecting data from "eventPassPricing"."""
input eventPassPricing_order_by {
  created_at: order_by
  eventPassId: order_by
  id: order_by
  maxAmount: order_by
  maxAmountPerUser: order_by
  priceAmount: order_by
  priceCurrency: order_by
  timeBeforeDelete: order_by
  updated_at: order_by
}

"""primary key columns input for table: eventPassPricing"""
input eventPassPricing_pk_columns_input {
  id: uuid!
}

"""
select columns of table "eventPassPricing"
"""
enum eventPassPricing_select_column {
  """column name"""
  created_at

  """column name"""
  eventPassId

  """column name"""
  id

  """column name"""
  maxAmount

  """column name"""
  maxAmountPerUser

  """column name"""
  priceAmount

  """column name"""
  priceCurrency

  """column name"""
  timeBeforeDelete

  """column name"""
  updated_at
}

"""
input type for updating data in table "eventPassPricing"
"""
input eventPassPricing_set_input {
  created_at: timestamptz
  eventPassId: String
  id: uuid
  maxAmount: Int
  maxAmountPerUser: Int
  priceAmount: Int
  priceCurrency: currency_enum
  timeBeforeDelete: Int
  updated_at: timestamptz
}

"""aggregate stddev on columns"""
type eventPassPricing_stddev_fields {
  maxAmount: Float
  maxAmountPerUser: Float
  priceAmount: Float
  timeBeforeDelete: Float
}

"""aggregate stddev_pop on columns"""
type eventPassPricing_stddev_pop_fields {
  maxAmount: Float
  maxAmountPerUser: Float
  priceAmount: Float
  timeBeforeDelete: Float
}

"""aggregate stddev_samp on columns"""
type eventPassPricing_stddev_samp_fields {
  maxAmount: Float
  maxAmountPerUser: Float
  priceAmount: Float
  timeBeforeDelete: Float
}

"""
Streaming cursor of the table "eventPassPricing"
"""
input eventPassPricing_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: eventPassPricing_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input eventPassPricing_stream_cursor_value_input {
  created_at: timestamptz
  eventPassId: String
  id: uuid
  maxAmount: Int
  maxAmountPerUser: Int
  priceAmount: Int
  priceCurrency: currency_enum
  timeBeforeDelete: Int
  updated_at: timestamptz
}

"""aggregate sum on columns"""
type eventPassPricing_sum_fields {
  maxAmount: Int
  maxAmountPerUser: Int
  priceAmount: Int
  timeBeforeDelete: Int
}

"""
update columns of table "eventPassPricing"
"""
enum eventPassPricing_update_column {
  """column name"""
  created_at

  """column name"""
  eventPassId

  """column name"""
  id

  """column name"""
  maxAmount

  """column name"""
  maxAmountPerUser

  """column name"""
  priceAmount

  """column name"""
  priceCurrency

  """column name"""
  timeBeforeDelete

  """column name"""
  updated_at
}

input eventPassPricing_updates {
  """increments the numeric columns with given value of the filtered values"""
  _inc: eventPassPricing_inc_input

  """sets the columns of the filtered rows to the given values"""
  _set: eventPassPricing_set_input

  """filter the rows which have to be updated"""
  where: eventPassPricing_bool_exp!
}

"""aggregate var_pop on columns"""
type eventPassPricing_var_pop_fields {
  maxAmount: Float
  maxAmountPerUser: Float
  priceAmount: Float
  timeBeforeDelete: Float
}

"""aggregate var_samp on columns"""
type eventPassPricing_var_samp_fields {
  maxAmount: Float
  maxAmountPerUser: Float
  priceAmount: Float
  timeBeforeDelete: Float
}

"""aggregate variance on columns"""
type eventPassPricing_variance_fields {
  maxAmount: Float
  maxAmountPerUser: Float
  priceAmount: Float
  timeBeforeDelete: Float
}

"""
Stores follow relationships. Each row represents an account following an organizer.
"""
type follow {
  """
  References the unique identifier of the account that is following an organizer.
  """
  accountId: uuid!
  created_at: timestamptz!

  """
  Represents the unique slug of the organizer being followed. Slugs are user-friendly identifiers that uniquely identify organizers.
  """
  organizerSlug: String!
}

"""
aggregated selection of "follow"
"""
type follow_aggregate {
  aggregate: follow_aggregate_fields
  nodes: [follow!]!
}

"""
aggregate fields of "follow"
"""
type follow_aggregate_fields {
  count(columns: [follow_select_column!], distinct: Boolean): Int!
  max: follow_max_fields
  min: follow_min_fields
}

"""
Boolean expression to filter rows from the table "follow". All fields are combined with a logical 'AND'.
"""
input follow_bool_exp {
  _and: [follow_bool_exp!]
  _not: follow_bool_exp
  _or: [follow_bool_exp!]
  accountId: uuid_comparison_exp
  created_at: timestamptz_comparison_exp
  organizerSlug: String_comparison_exp
}

"""
unique or primary key constraints on table "follow"
"""
enum follow_constraint {
  """
  unique or primary key constraint on columns "accountId", "organizerSlug"
  """
  follow_pkey
}

"""
input type for inserting data into table "follow"
"""
input follow_insert_input {
  """
  References the unique identifier of the account that is following an organizer.
  """
  accountId: uuid
  created_at: timestamptz

  """
  Represents the unique slug of the organizer being followed. Slugs are user-friendly identifiers that uniquely identify organizers.
  """
  organizerSlug: String
}

"""aggregate max on columns"""
type follow_max_fields {
  """
  References the unique identifier of the account that is following an organizer.
  """
  accountId: uuid
  created_at: timestamptz

  """
  Represents the unique slug of the organizer being followed. Slugs are user-friendly identifiers that uniquely identify organizers.
  """
  organizerSlug: String
}

"""aggregate min on columns"""
type follow_min_fields {
  """
  References the unique identifier of the account that is following an organizer.
  """
  accountId: uuid
  created_at: timestamptz

  """
  Represents the unique slug of the organizer being followed. Slugs are user-friendly identifiers that uniquely identify organizers.
  """
  organizerSlug: String
}

"""
response of any mutation on the table "follow"
"""
type follow_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [follow!]!
}

"""
on_conflict condition type for table "follow"
"""
input follow_on_conflict {
  constraint: follow_constraint!
  update_columns: [follow_update_column!]! = []
  where: follow_bool_exp
}

"""Ordering options when selecting data from "follow"."""
input follow_order_by {
  accountId: order_by
  created_at: order_by
  organizerSlug: order_by
}

"""primary key columns input for table: follow"""
input follow_pk_columns_input {
  """
  References the unique identifier of the account that is following an organizer.
  """
  accountId: uuid!

  """
  Represents the unique slug of the organizer being followed. Slugs are user-friendly identifiers that uniquely identify organizers.
  """
  organizerSlug: String!
}

"""
select columns of table "follow"
"""
enum follow_select_column {
  """column name"""
  accountId

  """column name"""
  created_at

  """column name"""
  organizerSlug
}

"""
input type for updating data in table "follow"
"""
input follow_set_input {
  """
  References the unique identifier of the account that is following an organizer.
  """
  accountId: uuid
  created_at: timestamptz

  """
  Represents the unique slug of the organizer being followed. Slugs are user-friendly identifiers that uniquely identify organizers.
  """
  organizerSlug: String
}

"""
Streaming cursor of the table "follow"
"""
input follow_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: follow_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input follow_stream_cursor_value_input {
  """
  References the unique identifier of the account that is following an organizer.
  """
  accountId: uuid
  created_at: timestamptz

  """
  Represents the unique slug of the organizer being followed. Slugs are user-friendly identifiers that uniquely identify organizers.
  """
  organizerSlug: String
}

"""
update columns of table "follow"
"""
enum follow_update_column {
  """column name"""
  accountId

  """column name"""
  created_at

  """column name"""
  organizerSlug
}

input follow_updates {
  """sets the columns of the filtered rows to the given values"""
  _set: follow_set_input

  """filter the rows which have to be updated"""
  where: follow_bool_exp!
}

scalar inet

"""
Boolean expression to compare columns of type "inet". All fields are combined with logical 'AND'.
"""
input inet_comparison_exp {
  _eq: inet
  _gt: inet
  _gte: inet
  _in: [inet!]
  _is_null: Boolean
  _lt: inet
  _lte: inet
  _neq: inet
  _nin: [inet!]
}

scalar jsonb

input jsonb_cast_exp {
  String: String_comparison_exp
}

"""
Boolean expression to compare columns of type "jsonb". All fields are combined with logical 'AND'.
"""
input jsonb_comparison_exp {
  _cast: jsonb_cast_exp

  """is the column contained in the given json value"""
  _contained_in: jsonb

  """does the column contain the given json value at the top level"""
  _contains: jsonb
  _eq: jsonb
  _gt: jsonb
  _gte: jsonb

  """does the string exist as a top-level key in the column"""
  _has_key: String

  """do all of these strings exist as top-level keys in the column"""
  _has_keys_all: [String!]

  """do any of these strings exist as top-level keys in the column"""
  _has_keys_any: [String!]
  _in: [jsonb!]
  _is_null: Boolean
  _lt: jsonb
  _lte: jsonb
  _neq: jsonb
  _nin: [jsonb!]
}

"""
columns and relationships of "kyc"
"""
type kyc {
  """Unique identifier for the applicant provided by Sumsub."""
  applicantId: String!

  """
  The date and time when the applicant was created in Sumsub. Stored in UTC timestamp.
  """
  createDate: timestamptz!

  """UUID referencing to the user ID in the existing accounts table."""
  externalUserId: uuid!

  """Level of KYC verification, which refers to kycLevelName."""
  levelName: kycLevelName_enum

  """Status of the applicant’s review in Sumsub, which refers to kycStatus."""
  reviewStatus: kycStatus_enum

  """Timestamp automatically updated whenever the kyc row changes."""
  updated_at: timestamptz
}

"""KYC levels representing the level of verification for the applicant."""
type kycLevelName {
  """Level name for KYC verification."""
  value: String!
}

"""
aggregated selection of "kycLevelName"
"""
type kycLevelName_aggregate {
  aggregate: kycLevelName_aggregate_fields
  nodes: [kycLevelName!]!
}

"""
aggregate fields of "kycLevelName"
"""
type kycLevelName_aggregate_fields {
  count(columns: [kycLevelName_select_column!], distinct: Boolean): Int!
  max: kycLevelName_max_fields
  min: kycLevelName_min_fields
}

"""
Boolean expression to filter rows from the table "kycLevelName". All fields are combined with a logical 'AND'.
"""
input kycLevelName_bool_exp {
  _and: [kycLevelName_bool_exp!]
  _not: kycLevelName_bool_exp
  _or: [kycLevelName_bool_exp!]
  value: String_comparison_exp
}

"""
unique or primary key constraints on table "kycLevelName"
"""
enum kycLevelName_constraint {
  """
  unique or primary key constraint on columns "value"
  """
  kycLevelName_pkey
}

enum kycLevelName_enum {
  advanced_kyc_level
  basic_kyc_level
}

"""
Boolean expression to compare columns of type "kycLevelName_enum". All fields are combined with logical 'AND'.
"""
input kycLevelName_enum_comparison_exp {
  _eq: kycLevelName_enum
  _in: [kycLevelName_enum!]
  _is_null: Boolean
  _neq: kycLevelName_enum
  _nin: [kycLevelName_enum!]
}

"""
input type for inserting data into table "kycLevelName"
"""
input kycLevelName_insert_input {
  """Level name for KYC verification."""
  value: String
}

"""aggregate max on columns"""
type kycLevelName_max_fields {
  """Level name for KYC verification."""
  value: String
}

"""aggregate min on columns"""
type kycLevelName_min_fields {
  """Level name for KYC verification."""
  value: String
}

"""
response of any mutation on the table "kycLevelName"
"""
type kycLevelName_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [kycLevelName!]!
}

"""
on_conflict condition type for table "kycLevelName"
"""
input kycLevelName_on_conflict {
  constraint: kycLevelName_constraint!
  update_columns: [kycLevelName_update_column!]! = []
  where: kycLevelName_bool_exp
}

"""Ordering options when selecting data from "kycLevelName"."""
input kycLevelName_order_by {
  value: order_by
}

"""primary key columns input for table: kycLevelName"""
input kycLevelName_pk_columns_input {
  """Level name for KYC verification."""
  value: String!
}

"""
select columns of table "kycLevelName"
"""
enum kycLevelName_select_column {
  """column name"""
  value
}

"""
input type for updating data in table "kycLevelName"
"""
input kycLevelName_set_input {
  """Level name for KYC verification."""
  value: String
}

"""
Streaming cursor of the table "kycLevelName"
"""
input kycLevelName_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: kycLevelName_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input kycLevelName_stream_cursor_value_input {
  """Level name for KYC verification."""
  value: String
}

"""
update columns of table "kycLevelName"
"""
enum kycLevelName_update_column {
  """column name"""
  value
}

input kycLevelName_updates {
  """sets the columns of the filtered rows to the given values"""
  _set: kycLevelName_set_input

  """filter the rows which have to be updated"""
  where: kycLevelName_bool_exp!
}

"""Statuses of Know Your Customer (KYC) processes."""
type kycStatus {
  """Status value."""
  value: String!
}

"""
aggregated selection of "kycStatus"
"""
type kycStatus_aggregate {
  aggregate: kycStatus_aggregate_fields
  nodes: [kycStatus!]!
}

"""
aggregate fields of "kycStatus"
"""
type kycStatus_aggregate_fields {
  count(columns: [kycStatus_select_column!], distinct: Boolean): Int!
  max: kycStatus_max_fields
  min: kycStatus_min_fields
}

"""
Boolean expression to filter rows from the table "kycStatus". All fields are combined with a logical 'AND'.
"""
input kycStatus_bool_exp {
  _and: [kycStatus_bool_exp!]
  _not: kycStatus_bool_exp
  _or: [kycStatus_bool_exp!]
  value: String_comparison_exp
}

"""
unique or primary key constraints on table "kycStatus"
"""
enum kycStatus_constraint {
  """
  unique or primary key constraint on columns "value"
  """
  kycStatus_pkey
}

enum kycStatus_enum {
  completed
  init
  onHold
  pending
  prechecked
  queued
}

"""
Boolean expression to compare columns of type "kycStatus_enum". All fields are combined with logical 'AND'.
"""
input kycStatus_enum_comparison_exp {
  _eq: kycStatus_enum
  _in: [kycStatus_enum!]
  _is_null: Boolean
  _neq: kycStatus_enum
  _nin: [kycStatus_enum!]
}

"""
input type for inserting data into table "kycStatus"
"""
input kycStatus_insert_input {
  """Status value."""
  value: String
}

"""aggregate max on columns"""
type kycStatus_max_fields {
  """Status value."""
  value: String
}

"""aggregate min on columns"""
type kycStatus_min_fields {
  """Status value."""
  value: String
}

"""
response of any mutation on the table "kycStatus"
"""
type kycStatus_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [kycStatus!]!
}

"""
on_conflict condition type for table "kycStatus"
"""
input kycStatus_on_conflict {
  constraint: kycStatus_constraint!
  update_columns: [kycStatus_update_column!]! = []
  where: kycStatus_bool_exp
}

"""Ordering options when selecting data from "kycStatus"."""
input kycStatus_order_by {
  value: order_by
}

"""primary key columns input for table: kycStatus"""
input kycStatus_pk_columns_input {
  """Status value."""
  value: String!
}

"""
select columns of table "kycStatus"
"""
enum kycStatus_select_column {
  """column name"""
  value
}

"""
input type for updating data in table "kycStatus"
"""
input kycStatus_set_input {
  """Status value."""
  value: String
}

"""
Streaming cursor of the table "kycStatus"
"""
input kycStatus_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: kycStatus_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input kycStatus_stream_cursor_value_input {
  """Status value."""
  value: String
}

"""
update columns of table "kycStatus"
"""
enum kycStatus_update_column {
  """column name"""
  value
}

input kycStatus_updates {
  """sets the columns of the filtered rows to the given values"""
  _set: kycStatus_set_input

  """filter the rows which have to be updated"""
  where: kycStatus_bool_exp!
}

"""
aggregated selection of "kyc"
"""
type kyc_aggregate {
  aggregate: kyc_aggregate_fields
  nodes: [kyc!]!
}

"""
aggregate fields of "kyc"
"""
type kyc_aggregate_fields {
  count(columns: [kyc_select_column!], distinct: Boolean): Int!
  max: kyc_max_fields
  min: kyc_min_fields
}

"""
Boolean expression to filter rows from the table "kyc". All fields are combined with a logical 'AND'.
"""
input kyc_bool_exp {
  _and: [kyc_bool_exp!]
  _not: kyc_bool_exp
  _or: [kyc_bool_exp!]
  applicantId: String_comparison_exp
  createDate: timestamptz_comparison_exp
  externalUserId: uuid_comparison_exp
  levelName: kycLevelName_enum_comparison_exp
  reviewStatus: kycStatus_enum_comparison_exp
  updated_at: timestamptz_comparison_exp
}

"""
unique or primary key constraints on table "kyc"
"""
enum kyc_constraint {
  """
  unique or primary key constraint on columns "externalUserId"
  """
  kyc_externalUserId_key

  """
  unique or primary key constraint on columns "externalUserId"
  """
  kyc_pkey
}

"""
input type for inserting data into table "kyc"
"""
input kyc_insert_input {
  """Unique identifier for the applicant provided by Sumsub."""
  applicantId: String

  """
  The date and time when the applicant was created in Sumsub. Stored in UTC timestamp.
  """
  createDate: timestamptz

  """UUID referencing to the user ID in the existing accounts table."""
  externalUserId: uuid

  """Level of KYC verification, which refers to kycLevelName."""
  levelName: kycLevelName_enum

  """Status of the applicant’s review in Sumsub, which refers to kycStatus."""
  reviewStatus: kycStatus_enum

  """Timestamp automatically updated whenever the kyc row changes."""
  updated_at: timestamptz
}

"""aggregate max on columns"""
type kyc_max_fields {
  """Unique identifier for the applicant provided by Sumsub."""
  applicantId: String

  """
  The date and time when the applicant was created in Sumsub. Stored in UTC timestamp.
  """
  createDate: timestamptz

  """UUID referencing to the user ID in the existing accounts table."""
  externalUserId: uuid

  """Timestamp automatically updated whenever the kyc row changes."""
  updated_at: timestamptz
}

"""aggregate min on columns"""
type kyc_min_fields {
  """Unique identifier for the applicant provided by Sumsub."""
  applicantId: String

  """
  The date and time when the applicant was created in Sumsub. Stored in UTC timestamp.
  """
  createDate: timestamptz

  """UUID referencing to the user ID in the existing accounts table."""
  externalUserId: uuid

  """Timestamp automatically updated whenever the kyc row changes."""
  updated_at: timestamptz
}

"""
response of any mutation on the table "kyc"
"""
type kyc_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [kyc!]!
}

"""
input type for inserting object relation for remote table "kyc"
"""
input kyc_obj_rel_insert_input {
  data: kyc_insert_input!

  """upsert condition"""
  on_conflict: kyc_on_conflict
}

"""
on_conflict condition type for table "kyc"
"""
input kyc_on_conflict {
  constraint: kyc_constraint!
  update_columns: [kyc_update_column!]! = []
  where: kyc_bool_exp
}

"""Ordering options when selecting data from "kyc"."""
input kyc_order_by {
  applicantId: order_by
  createDate: order_by
  externalUserId: order_by
  levelName: order_by
  reviewStatus: order_by
  updated_at: order_by
}

"""primary key columns input for table: kyc"""
input kyc_pk_columns_input {
  """UUID referencing to the user ID in the existing accounts table."""
  externalUserId: uuid!
}

"""
select columns of table "kyc"
"""
enum kyc_select_column {
  """column name"""
  applicantId

  """column name"""
  createDate

  """column name"""
  externalUserId

  """column name"""
  levelName

  """column name"""
  reviewStatus

  """column name"""
  updated_at
}

"""
input type for updating data in table "kyc"
"""
input kyc_set_input {
  """Unique identifier for the applicant provided by Sumsub."""
  applicantId: String

  """
  The date and time when the applicant was created in Sumsub. Stored in UTC timestamp.
  """
  createDate: timestamptz

  """UUID referencing to the user ID in the existing accounts table."""
  externalUserId: uuid

  """Level of KYC verification, which refers to kycLevelName."""
  levelName: kycLevelName_enum

  """Status of the applicant’s review in Sumsub, which refers to kycStatus."""
  reviewStatus: kycStatus_enum

  """Timestamp automatically updated whenever the kyc row changes."""
  updated_at: timestamptz
}

"""
Streaming cursor of the table "kyc"
"""
input kyc_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: kyc_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input kyc_stream_cursor_value_input {
  """Unique identifier for the applicant provided by Sumsub."""
  applicantId: String

  """
  The date and time when the applicant was created in Sumsub. Stored in UTC timestamp.
  """
  createDate: timestamptz

  """UUID referencing to the user ID in the existing accounts table."""
  externalUserId: uuid

  """Level of KYC verification, which refers to kycLevelName."""
  levelName: kycLevelName_enum

  """Status of the applicant’s review in Sumsub, which refers to kycStatus."""
  reviewStatus: kycStatus_enum

  """Timestamp automatically updated whenever the kyc row changes."""
  updated_at: timestamptz
}

"""
update columns of table "kyc"
"""
enum kyc_update_column {
  """column name"""
  applicantId

  """column name"""
  createDate

  """column name"""
  externalUserId

  """column name"""
  levelName

  """column name"""
  reviewStatus

  """column name"""
  updated_at
}

input kyc_updates {
  """sets the columns of the filtered rows to the given values"""
  _set: kyc_set_input

  """filter the rows which have to be updated"""
  where: kyc_bool_exp!
}

"""mutation root"""
type mutation_root {
  """Create one asset"""
  createAsset(data: AssetCreateInput!): Asset

  """Create one event"""
  createEvent(data: EventCreateInput!): Event

  """Create one eventPass"""
  createEventPass(data: EventPassCreateInput!): EventPass

  """Create one eventPassDelayedRevealed"""
  createEventPassDelayedRevealed(data: EventPassDelayedRevealedCreateInput!): EventPassDelayedRevealed

  """Create one organizer"""
  createOrganizer(data: OrganizerCreateInput!): Organizer

  """Create one scheduledRelease"""
  createScheduledRelease(data: ScheduledReleaseCreateInput!): ScheduledRelease

  """Delete one asset from _all_ existing stages. Returns deleted document."""
  deleteAsset(
    """Document to delete"""
    where: AssetWhereUniqueInput!
  ): Asset

  """Delete one event from _all_ existing stages. Returns deleted document."""
  deleteEvent(
    """Document to delete"""
    where: EventWhereUniqueInput!
  ): Event

  """
  Delete one eventPass from _all_ existing stages. Returns deleted document.
  """
  deleteEventPass(
    """Document to delete"""
    where: EventPassWhereUniqueInput!
  ): EventPass

  """
  Delete one eventPassDelayedRevealed from _all_ existing stages. Returns deleted document.
  """
  deleteEventPassDelayedRevealed(
    """Document to delete"""
    where: EventPassDelayedRevealedWhereUniqueInput!
  ): EventPassDelayedRevealed

  """Delete many Asset documents"""
  deleteManyAssets(
    """Documents to delete"""
    where: AssetManyWhereInput
  ): BatchPayload!

  """Delete many Asset documents, return deleted documents"""
  deleteManyAssetsConnection(
    after: ID
    before: ID
    first: Int
    last: Int
    skip: Int

    """Documents to delete"""
    where: AssetManyWhereInput
  ): AssetConnection!

  """Delete many EventPass documents"""
  deleteManyEventPasses(
    """Documents to delete"""
    where: EventPassManyWhereInput
  ): BatchPayload!

  """Delete many EventPass documents, return deleted documents"""
  deleteManyEventPassesConnection(
    after: ID
    before: ID
    first: Int
    last: Int
    skip: Int

    """Documents to delete"""
    where: EventPassManyWhereInput
  ): EventPassConnection!

  """Delete many EventPassDelayedRevealed documents"""
  deleteManyEventPassesDelayedRevealed(
    """Documents to delete"""
    where: EventPassDelayedRevealedManyWhereInput
  ): BatchPayload!

  """
  Delete many EventPassDelayedRevealed documents, return deleted documents
  """
  deleteManyEventPassesDelayedRevealedConnection(
    after: ID
    before: ID
    first: Int
    last: Int
    skip: Int

    """Documents to delete"""
    where: EventPassDelayedRevealedManyWhereInput
  ): EventPassDelayedRevealedConnection!

  """Delete many Event documents"""
  deleteManyEvents(
    """Documents to delete"""
    where: EventManyWhereInput
  ): BatchPayload!

  """Delete many Event documents, return deleted documents"""
  deleteManyEventsConnection(
    after: ID
    before: ID
    first: Int
    last: Int
    skip: Int

    """Documents to delete"""
    where: EventManyWhereInput
  ): EventConnection!

  """Delete many Organizer documents"""
  deleteManyOrganizers(
    """Documents to delete"""
    where: OrganizerManyWhereInput
  ): BatchPayload!

  """Delete many Organizer documents, return deleted documents"""
  deleteManyOrganizersConnection(
    after: ID
    before: ID
    first: Int
    last: Int
    skip: Int

    """Documents to delete"""
    where: OrganizerManyWhereInput
  ): OrganizerConnection!

  """
  Delete one organizer from _all_ existing stages. Returns deleted document.
  """
  deleteOrganizer(
    """Document to delete"""
    where: OrganizerWhereUniqueInput!
  ): Organizer

  """Delete and return scheduled operation"""
  deleteScheduledOperation(
    """Document to delete"""
    where: ScheduledOperationWhereUniqueInput!
  ): ScheduledOperation

  """
  Delete one scheduledRelease from _all_ existing stages. Returns deleted document.
  """
  deleteScheduledRelease(
    """Document to delete"""
    where: ScheduledReleaseWhereUniqueInput!
  ): ScheduledRelease

  """
  delete data from the table: "account"
  """
  delete_account(
    """filter the rows which have to be deleted"""
    where: account_bool_exp!
  ): account_mutation_response

  """
  delete single row from the table: "account"
  """
  delete_account_by_pk(id: uuid!): account

  """
  delete data from the table: "audit.logged_actions"
  """
  delete_audit_logged_actions(
    """filter the rows which have to be deleted"""
    where: audit_logged_actions_bool_exp!
  ): audit_logged_actions_mutation_response

  """
  delete single row from the table: "audit.logged_actions"
  """
  delete_audit_logged_actions_by_pk(
    """Unique identifier for each auditable event"""
    event_id: bigint!
  ): audit_logged_actions

  """
  delete data from the table: "currency"
  """
  delete_currency(
    """filter the rows which have to be deleted"""
    where: currency_bool_exp!
  ): currency_mutation_response

  """
  delete single row from the table: "currency"
  """
  delete_currency_by_pk(value: String!): currency

  """
  delete data from the table: "eventParameters"
  """
  delete_eventParameters(
    """filter the rows which have to be deleted"""
    where: eventParameters_bool_exp!
  ): eventParameters_mutation_response

  """
  delete single row from the table: "eventParameters"
  """
  delete_eventParameters_by_pk(id: uuid!): eventParameters

  """
  delete data from the table: "eventPassNft"
  """
  delete_eventPassNft(
    """filter the rows which have to be deleted"""
    where: eventPassNft_bool_exp!
  ): eventPassNft_mutation_response

  """
  delete data from the table: "eventPassNftContract"
  """
  delete_eventPassNftContract(
    """filter the rows which have to be deleted"""
    where: eventPassNftContract_bool_exp!
  ): eventPassNftContract_mutation_response

  """
  delete data from the table: "eventPassNftContractType"
  """
  delete_eventPassNftContractType(
    """filter the rows which have to be deleted"""
    where: eventPassNftContractType_bool_exp!
  ): eventPassNftContractType_mutation_response

  """
  delete single row from the table: "eventPassNftContractType"
  """
  delete_eventPassNftContractType_by_pk(
    """Type name for event pass NFT contract."""
    value: String!
  ): eventPassNftContractType

  """
  delete single row from the table: "eventPassNft"
  """
  delete_eventPassNft_by_pk(id: uuid!): eventPassNft

  """
  delete data from the table: "eventPassOrder"
  """
  delete_eventPassOrder(
    """filter the rows which have to be deleted"""
    where: eventPassOrder_bool_exp!
  ): eventPassOrder_mutation_response

  """
  delete data from the table: "eventPassOrderSums"
  """
  delete_eventPassOrderSums(
    """filter the rows which have to be deleted"""
    where: eventPassOrderSums_bool_exp!
  ): eventPassOrderSums_mutation_response

  """
  delete single row from the table: "eventPassOrderSums"
  """
  delete_eventPassOrderSums_by_pk(eventPassId: String!): eventPassOrderSums

  """
  delete single row from the table: "eventPassOrder"
  """
  delete_eventPassOrder_by_pk(id: uuid!): eventPassOrder

  """
  delete data from the table: "eventPassPendingOrder"
  """
  delete_eventPassPendingOrder(
    """filter the rows which have to be deleted"""
    where: eventPassPendingOrder_bool_exp!
  ): eventPassPendingOrder_mutation_response

  """
  delete single row from the table: "eventPassPendingOrder"
  """
  delete_eventPassPendingOrder_by_pk(id: uuid!): eventPassPendingOrder

  """
  delete data from the table: "eventPassPricing"
  """
  delete_eventPassPricing(
    """filter the rows which have to be deleted"""
    where: eventPassPricing_bool_exp!
  ): eventPassPricing_mutation_response

  """
  delete single row from the table: "eventPassPricing"
  """
  delete_eventPassPricing_by_pk(id: uuid!): eventPassPricing

  """
  delete data from the table: "follow"
  """
  delete_follow(
    """filter the rows which have to be deleted"""
    where: follow_bool_exp!
  ): follow_mutation_response

  """
  delete single row from the table: "follow"
  """
  delete_follow_by_pk(
    """
    References the unique identifier of the account that is following an organizer.
    """
    accountId: uuid!

    """
    Represents the unique slug of the organizer being followed. Slugs are user-friendly identifiers that uniquely identify organizers.
    """
    organizerSlug: String!
  ): follow

  """
  delete data from the table: "kyc"
  """
  delete_kyc(
    """filter the rows which have to be deleted"""
    where: kyc_bool_exp!
  ): kyc_mutation_response

  """
  delete data from the table: "kycLevelName"
  """
  delete_kycLevelName(
    """filter the rows which have to be deleted"""
    where: kycLevelName_bool_exp!
  ): kycLevelName_mutation_response

  """
  delete single row from the table: "kycLevelName"
  """
  delete_kycLevelName_by_pk(
    """Level name for KYC verification."""
    value: String!
  ): kycLevelName

  """
  delete data from the table: "kycStatus"
  """
  delete_kycStatus(
    """filter the rows which have to be deleted"""
    where: kycStatus_bool_exp!
  ): kycStatus_mutation_response

  """
  delete single row from the table: "kycStatus"
  """
  delete_kycStatus_by_pk(
    """Status value."""
    value: String!
  ): kycStatus

  """
  delete single row from the table: "kyc"
  """
  delete_kyc_by_pk(
    """UUID referencing to the user ID in the existing accounts table."""
    externalUserId: uuid!
  ): kyc

  """
  delete data from the table: "nftTransfer"
  """
  delete_nftTransfer(
    """filter the rows which have to be deleted"""
    where: nftTransfer_bool_exp!
  ): nftTransfer_mutation_response

  """
  delete single row from the table: "nftTransfer"
  """
  delete_nftTransfer_by_pk(id: uuid!): nftTransfer

  """
  delete data from the table: "orderStatus"
  """
  delete_orderStatus(
    """filter the rows which have to be deleted"""
    where: orderStatus_bool_exp!
  ): orderStatus_mutation_response

  """
  delete single row from the table: "orderStatus"
  """
  delete_orderStatus_by_pk(value: String!): orderStatus

  """
  delete data from the table: "packNftContract"
  """
  delete_packNftContract(
    """filter the rows which have to be deleted"""
    where: packNftContract_bool_exp!
  ): packNftContract_mutation_response

  """
  delete single row from the table: "packNftContract"
  """
  delete_packNftContract_by_pk(id: uuid!): packNftContract

  """
  delete data from the table: "roleAssignments"
  """
  delete_roleAssignments(
    """filter the rows which have to be deleted"""
    where: roleAssignments_bool_exp!
  ): roleAssignments_mutation_response

  """
  delete data from the table: "roles"
  """
  delete_roles(
    """filter the rows which have to be deleted"""
    where: roles_bool_exp!
  ): roles_mutation_response

  """
  delete single row from the table: "roles"
  """
  delete_roles_by_pk(
    "\n    organizer_super_admin: Full Read & Write permissions on web2 and web3 components. Can assign roles and access system configurations.\n    organizer_admin: Full Read & Write permissions on web2 and web3 components.\n    organizer_operations_manager: Read & Write access to web2 components. Handles event setup, monitoring, analytics, etc.\n    organizer_finance_manager: Read & Write access to web3 components. Manages fund transfers, balance checks, and transaction approvals within limits.\n    organizer_content_manager: Read & Write access to web2 components. Manages content creation, editing, media uploads, and metadata modifications.\n    organizer_validator: Read & Write access on web2 and web3. Updates NFT traits and validates tickets and exclusive access during events.\n    organizer_auditor: Read-only access on web2 and web3. Conducts compliance checks and reviews transactions and operations.\n    organizer_guest: Limited access to web2. Can view public content without web3 permissions.\n    organizer_human_resources: Administrative permissions. Can invite new members for the organization and assign roles (except super admin and human resources).\n"
    value: String!
  ): roles

  """
  delete data from the table: "stripeCheckoutSession"
  """
  delete_stripeCheckoutSession(
    """filter the rows which have to be deleted"""
    where: stripeCheckoutSession_bool_exp!
  ): stripeCheckoutSession_mutation_response

  """
  delete data from the table: "stripeCheckoutSessionType"
  """
  delete_stripeCheckoutSessionType(
    """filter the rows which have to be deleted"""
    where: stripeCheckoutSessionType_bool_exp!
  ): stripeCheckoutSessionType_mutation_response

  """
  delete single row from the table: "stripeCheckoutSessionType"
  """
  delete_stripeCheckoutSessionType_by_pk(
    """Type value."""
    value: String!
  ): stripeCheckoutSessionType

  """
  delete single row from the table: "stripeCheckoutSession"
  """
  delete_stripeCheckoutSession_by_pk(
    """Unique identifier for the Stripe Checkout Session."""
    stripeSessionId: String!
  ): stripeCheckoutSession

  """
  delete data from the table: "stripeCustomer"
  """
  delete_stripeCustomer(
    """filter the rows which have to be deleted"""
    where: stripeCustomer_bool_exp!
  ): stripeCustomer_mutation_response

  """
  delete single row from the table: "stripeCustomer"
  """
  delete_stripeCustomer_by_pk(
    """Unique identifier for the Stripe Customer."""
    stripeCustomerId: String!
  ): stripeCustomer

  """
  delete data from the table: "timezone"
  """
  delete_timezone(
    """filter the rows which have to be deleted"""
    where: timezone_bool_exp!
  ): timezone_mutation_response

  """
  delete single row from the table: "timezone"
  """
  delete_timezone_by_pk(value: String!): timezone

  """
  insert data into the table: "account"
  """
  insert_account(
    """the rows to be inserted"""
    objects: [account_insert_input!]!

    """upsert condition"""
    on_conflict: account_on_conflict
  ): account_mutation_response

  """
  insert a single row into the table: "account"
  """
  insert_account_one(
    """the row to be inserted"""
    object: account_insert_input!

    """upsert condition"""
    on_conflict: account_on_conflict
  ): account

  """
  insert data into the table: "audit.logged_actions"
  """
  insert_audit_logged_actions(
    """the rows to be inserted"""
    objects: [audit_logged_actions_insert_input!]!

    """upsert condition"""
    on_conflict: audit_logged_actions_on_conflict
  ): audit_logged_actions_mutation_response

  """
  insert a single row into the table: "audit.logged_actions"
  """
  insert_audit_logged_actions_one(
    """the row to be inserted"""
    object: audit_logged_actions_insert_input!

    """upsert condition"""
    on_conflict: audit_logged_actions_on_conflict
  ): audit_logged_actions

  """
  insert data into the table: "currency"
  """
  insert_currency(
    """the rows to be inserted"""
    objects: [currency_insert_input!]!

    """upsert condition"""
    on_conflict: currency_on_conflict
  ): currency_mutation_response

  """
  insert a single row into the table: "currency"
  """
  insert_currency_one(
    """the row to be inserted"""
    object: currency_insert_input!

    """upsert condition"""
    on_conflict: currency_on_conflict
  ): currency

  """
  insert data into the table: "eventParameters"
  """
  insert_eventParameters(
    """the rows to be inserted"""
    objects: [eventParameters_insert_input!]!

    """upsert condition"""
    on_conflict: eventParameters_on_conflict
  ): eventParameters_mutation_response

  """
  insert a single row into the table: "eventParameters"
  """
  insert_eventParameters_one(
    """the row to be inserted"""
    object: eventParameters_insert_input!

    """upsert condition"""
    on_conflict: eventParameters_on_conflict
  ): eventParameters

  """
  insert data into the table: "eventPassNft"
  """
  insert_eventPassNft(
    """the rows to be inserted"""
    objects: [eventPassNft_insert_input!]!

    """upsert condition"""
    on_conflict: eventPassNft_on_conflict
  ): eventPassNft_mutation_response

  """
  insert data into the table: "eventPassNftContract"
  """
  insert_eventPassNftContract(
    """the rows to be inserted"""
    objects: [eventPassNftContract_insert_input!]!

    """upsert condition"""
    on_conflict: eventPassNftContract_on_conflict
  ): eventPassNftContract_mutation_response

  """
  insert data into the table: "eventPassNftContractType"
  """
  insert_eventPassNftContractType(
    """the rows to be inserted"""
    objects: [eventPassNftContractType_insert_input!]!

    """upsert condition"""
    on_conflict: eventPassNftContractType_on_conflict
  ): eventPassNftContractType_mutation_response

  """
  insert a single row into the table: "eventPassNftContractType"
  """
  insert_eventPassNftContractType_one(
    """the row to be inserted"""
    object: eventPassNftContractType_insert_input!

    """upsert condition"""
    on_conflict: eventPassNftContractType_on_conflict
  ): eventPassNftContractType

  """
  insert a single row into the table: "eventPassNftContract"
  """
  insert_eventPassNftContract_one(
    """the row to be inserted"""
    object: eventPassNftContract_insert_input!

    """upsert condition"""
    on_conflict: eventPassNftContract_on_conflict
  ): eventPassNftContract

  """
  insert a single row into the table: "eventPassNft"
  """
  insert_eventPassNft_one(
    """the row to be inserted"""
    object: eventPassNft_insert_input!

    """upsert condition"""
    on_conflict: eventPassNft_on_conflict
  ): eventPassNft

  """
  insert data into the table: "eventPassOrder"
  """
  insert_eventPassOrder(
    """the rows to be inserted"""
    objects: [eventPassOrder_insert_input!]!

    """upsert condition"""
    on_conflict: eventPassOrder_on_conflict
  ): eventPassOrder_mutation_response

  """
  insert data into the table: "eventPassOrderSums"
  """
  insert_eventPassOrderSums(
    """the rows to be inserted"""
    objects: [eventPassOrderSums_insert_input!]!

    """upsert condition"""
    on_conflict: eventPassOrderSums_on_conflict
  ): eventPassOrderSums_mutation_response

  """
  insert a single row into the table: "eventPassOrderSums"
  """
  insert_eventPassOrderSums_one(
    """the row to be inserted"""
    object: eventPassOrderSums_insert_input!

    """upsert condition"""
    on_conflict: eventPassOrderSums_on_conflict
  ): eventPassOrderSums

  """
  insert a single row into the table: "eventPassOrder"
  """
  insert_eventPassOrder_one(
    """the row to be inserted"""
    object: eventPassOrder_insert_input!

    """upsert condition"""
    on_conflict: eventPassOrder_on_conflict
  ): eventPassOrder

  """
  insert data into the table: "eventPassPendingOrder"
  """
  insert_eventPassPendingOrder(
    """the rows to be inserted"""
    objects: [eventPassPendingOrder_insert_input!]!

    """upsert condition"""
    on_conflict: eventPassPendingOrder_on_conflict
  ): eventPassPendingOrder_mutation_response

  """
  insert a single row into the table: "eventPassPendingOrder"
  """
  insert_eventPassPendingOrder_one(
    """the row to be inserted"""
    object: eventPassPendingOrder_insert_input!

    """upsert condition"""
    on_conflict: eventPassPendingOrder_on_conflict
  ): eventPassPendingOrder

  """
  insert data into the table: "eventPassPricing"
  """
  insert_eventPassPricing(
    """the rows to be inserted"""
    objects: [eventPassPricing_insert_input!]!

    """upsert condition"""
    on_conflict: eventPassPricing_on_conflict
  ): eventPassPricing_mutation_response

  """
  insert a single row into the table: "eventPassPricing"
  """
  insert_eventPassPricing_one(
    """the row to be inserted"""
    object: eventPassPricing_insert_input!

    """upsert condition"""
    on_conflict: eventPassPricing_on_conflict
  ): eventPassPricing

  """
  insert data into the table: "follow"
  """
  insert_follow(
    """the rows to be inserted"""
    objects: [follow_insert_input!]!

    """upsert condition"""
    on_conflict: follow_on_conflict
  ): follow_mutation_response

  """
  insert a single row into the table: "follow"
  """
  insert_follow_one(
    """the row to be inserted"""
    object: follow_insert_input!

    """upsert condition"""
    on_conflict: follow_on_conflict
  ): follow

  """
  insert data into the table: "kyc"
  """
  insert_kyc(
    """the rows to be inserted"""
    objects: [kyc_insert_input!]!

    """upsert condition"""
    on_conflict: kyc_on_conflict
  ): kyc_mutation_response

  """
  insert data into the table: "kycLevelName"
  """
  insert_kycLevelName(
    """the rows to be inserted"""
    objects: [kycLevelName_insert_input!]!

    """upsert condition"""
    on_conflict: kycLevelName_on_conflict
  ): kycLevelName_mutation_response

  """
  insert a single row into the table: "kycLevelName"
  """
  insert_kycLevelName_one(
    """the row to be inserted"""
    object: kycLevelName_insert_input!

    """upsert condition"""
    on_conflict: kycLevelName_on_conflict
  ): kycLevelName

  """
  insert data into the table: "kycStatus"
  """
  insert_kycStatus(
    """the rows to be inserted"""
    objects: [kycStatus_insert_input!]!

    """upsert condition"""
    on_conflict: kycStatus_on_conflict
  ): kycStatus_mutation_response

  """
  insert a single row into the table: "kycStatus"
  """
  insert_kycStatus_one(
    """the row to be inserted"""
    object: kycStatus_insert_input!

    """upsert condition"""
    on_conflict: kycStatus_on_conflict
  ): kycStatus

  """
  insert a single row into the table: "kyc"
  """
  insert_kyc_one(
    """the row to be inserted"""
    object: kyc_insert_input!

    """upsert condition"""
    on_conflict: kyc_on_conflict
  ): kyc

  """
  insert data into the table: "nftTransfer"
  """
  insert_nftTransfer(
    """the rows to be inserted"""
    objects: [nftTransfer_insert_input!]!

    """upsert condition"""
    on_conflict: nftTransfer_on_conflict
  ): nftTransfer_mutation_response

  """
  insert a single row into the table: "nftTransfer"
  """
  insert_nftTransfer_one(
    """the row to be inserted"""
    object: nftTransfer_insert_input!

    """upsert condition"""
    on_conflict: nftTransfer_on_conflict
  ): nftTransfer

  """
  insert data into the table: "orderStatus"
  """
  insert_orderStatus(
    """the rows to be inserted"""
    objects: [orderStatus_insert_input!]!

    """upsert condition"""
    on_conflict: orderStatus_on_conflict
  ): orderStatus_mutation_response

  """
  insert a single row into the table: "orderStatus"
  """
  insert_orderStatus_one(
    """the row to be inserted"""
    object: orderStatus_insert_input!

    """upsert condition"""
    on_conflict: orderStatus_on_conflict
  ): orderStatus

  """
  insert data into the table: "packNftContract"
  """
  insert_packNftContract(
    """the rows to be inserted"""
    objects: [packNftContract_insert_input!]!

    """upsert condition"""
    on_conflict: packNftContract_on_conflict
  ): packNftContract_mutation_response

  """
  insert a single row into the table: "packNftContract"
  """
  insert_packNftContract_one(
    """the row to be inserted"""
    object: packNftContract_insert_input!

    """upsert condition"""
    on_conflict: packNftContract_on_conflict
  ): packNftContract

  """
  insert data into the table: "roleAssignments"
  """
  insert_roleAssignments(
    """the rows to be inserted"""
    objects: [roleAssignments_insert_input!]!

    """upsert condition"""
    on_conflict: roleAssignments_on_conflict
  ): roleAssignments_mutation_response

  """
  insert a single row into the table: "roleAssignments"
  """
  insert_roleAssignments_one(
    """the row to be inserted"""
    object: roleAssignments_insert_input!

    """upsert condition"""
    on_conflict: roleAssignments_on_conflict
  ): roleAssignments

  """
  insert data into the table: "roles"
  """
  insert_roles(
    """the rows to be inserted"""
    objects: [roles_insert_input!]!

    """upsert condition"""
    on_conflict: roles_on_conflict
  ): roles_mutation_response

  """
  insert a single row into the table: "roles"
  """
  insert_roles_one(
    """the row to be inserted"""
    object: roles_insert_input!

    """upsert condition"""
    on_conflict: roles_on_conflict
  ): roles

  """
  insert data into the table: "stripeCheckoutSession"
  """
  insert_stripeCheckoutSession(
    """the rows to be inserted"""
    objects: [stripeCheckoutSession_insert_input!]!

    """upsert condition"""
    on_conflict: stripeCheckoutSession_on_conflict
  ): stripeCheckoutSession_mutation_response

  """
  insert data into the table: "stripeCheckoutSessionType"
  """
  insert_stripeCheckoutSessionType(
    """the rows to be inserted"""
    objects: [stripeCheckoutSessionType_insert_input!]!

    """upsert condition"""
    on_conflict: stripeCheckoutSessionType_on_conflict
  ): stripeCheckoutSessionType_mutation_response

  """
  insert a single row into the table: "stripeCheckoutSessionType"
  """
  insert_stripeCheckoutSessionType_one(
    """the row to be inserted"""
    object: stripeCheckoutSessionType_insert_input!

    """upsert condition"""
    on_conflict: stripeCheckoutSessionType_on_conflict
  ): stripeCheckoutSessionType

  """
  insert a single row into the table: "stripeCheckoutSession"
  """
  insert_stripeCheckoutSession_one(
    """the row to be inserted"""
    object: stripeCheckoutSession_insert_input!

    """upsert condition"""
    on_conflict: stripeCheckoutSession_on_conflict
  ): stripeCheckoutSession

  """
  insert data into the table: "stripeCustomer"
  """
  insert_stripeCustomer(
    """the rows to be inserted"""
    objects: [stripeCustomer_insert_input!]!

    """upsert condition"""
    on_conflict: stripeCustomer_on_conflict
  ): stripeCustomer_mutation_response

  """
  insert a single row into the table: "stripeCustomer"
  """
  insert_stripeCustomer_one(
    """the row to be inserted"""
    object: stripeCustomer_insert_input!

    """upsert condition"""
    on_conflict: stripeCustomer_on_conflict
  ): stripeCustomer

  """
  insert data into the table: "timezone"
  """
  insert_timezone(
    """the rows to be inserted"""
    objects: [timezone_insert_input!]!

    """upsert condition"""
    on_conflict: timezone_on_conflict
  ): timezone_mutation_response

  """
  insert a single row into the table: "timezone"
  """
  insert_timezone_one(
    """the row to be inserted"""
    object: timezone_insert_input!

    """upsert condition"""
    on_conflict: timezone_on_conflict
  ): timezone

  """Publish one asset"""
  publishAsset(
    """Optional localizations to publish"""
    locales: [Locale!]

    """Whether to publish the base document"""
    publishBase: Boolean = true

    """Publishing target stage"""
    to: [Stage!]! = [PUBLISHED]

    """Document to publish"""
    where: AssetWhereUniqueInput!

    """Whether to include the default locale when publishBase is set"""
    withDefaultLocale: Boolean = true
  ): Asset

  """Publish one event"""
  publishEvent(
    """Optional localizations to publish"""
    locales: [Locale!]

    """Whether to publish the base document"""
    publishBase: Boolean = true

    """Publishing target stage"""
    to: [Stage!]! = [PUBLISHED]

    """Document to publish"""
    where: EventWhereUniqueInput!

    """Whether to include the default locale when publishBase is set"""
    withDefaultLocale: Boolean = true
  ): Event

  """Publish one eventPass"""
  publishEventPass(
    """Optional localizations to publish"""
    locales: [Locale!]

    """Whether to publish the base document"""
    publishBase: Boolean = true

    """Publishing target stage"""
    to: [Stage!]! = [PUBLISHED]

    """Document to publish"""
    where: EventPassWhereUniqueInput!

    """Whether to include the default locale when publishBase is set"""
    withDefaultLocale: Boolean = true
  ): EventPass

  """Publish one eventPassDelayedRevealed"""
  publishEventPassDelayedRevealed(
    """Optional localizations to publish"""
    locales: [Locale!]

    """Whether to publish the base document"""
    publishBase: Boolean = true

    """Publishing target stage"""
    to: [Stage!]! = [PUBLISHED]

    """Document to publish"""
    where: EventPassDelayedRevealedWhereUniqueInput!

    """Whether to include the default locale when publishBase is set"""
    withDefaultLocale: Boolean = true
  ): EventPassDelayedRevealed

  """Publish many Asset documents"""
  publishManyAssets(
    """Document localizations to publish"""
    locales: [Locale!]

    """Whether to publish the base document"""
    publishBase: Boolean = true

    """Stages to publish documents to"""
    to: [Stage!]! = [PUBLISHED]

    """Identifies documents in each stage to be published"""
    where: AssetManyWhereInput

    """Whether to include the default locale when publishBase is true"""
    withDefaultLocale: Boolean = true
  ): BatchPayload!

  """Publish many Asset documents"""
  publishManyAssetsConnection(
    after: ID
    before: ID
    first: Int

    """Stage to find matching documents in"""
    from: Stage = DRAFT
    last: Int

    """Document localizations to publish"""
    locales: [Locale!]

    """Whether to publish the base document"""
    publishBase: Boolean = true
    skip: Int

    """Stages to publish documents to"""
    to: [Stage!]! = [PUBLISHED]

    """Identifies documents in each stage to be published"""
    where: AssetManyWhereInput

    """Whether to include the default locale when publishBase is true"""
    withDefaultLocale: Boolean = true
  ): AssetConnection!

  """Publish many EventPass documents"""
  publishManyEventPasses(
    """Document localizations to publish"""
    locales: [Locale!]

    """Whether to publish the base document"""
    publishBase: Boolean = true

    """Stages to publish documents to"""
    to: [Stage!]! = [PUBLISHED]

    """Identifies documents in each stage to be published"""
    where: EventPassManyWhereInput

    """Whether to include the default locale when publishBase is true"""
    withDefaultLocale: Boolean = true
  ): BatchPayload!

  """Publish many EventPass documents"""
  publishManyEventPassesConnection(
    after: ID
    before: ID
    first: Int

    """Stage to find matching documents in"""
    from: Stage = DRAFT
    last: Int

    """Document localizations to publish"""
    locales: [Locale!]

    """Whether to publish the base document"""
    publishBase: Boolean = true
    skip: Int

    """Stages to publish documents to"""
    to: [Stage!]! = [PUBLISHED]

    """Identifies documents in each stage to be published"""
    where: EventPassManyWhereInput

    """Whether to include the default locale when publishBase is true"""
    withDefaultLocale: Boolean = true
  ): EventPassConnection!

  """Publish many EventPassDelayedRevealed documents"""
  publishManyEventPassesDelayedRevealed(
    """Document localizations to publish"""
    locales: [Locale!]

    """Whether to publish the base document"""
    publishBase: Boolean = true

    """Stages to publish documents to"""
    to: [Stage!]! = [PUBLISHED]

    """Identifies documents in each stage to be published"""
    where: EventPassDelayedRevealedManyWhereInput

    """Whether to include the default locale when publishBase is true"""
    withDefaultLocale: Boolean = true
  ): BatchPayload!

  """Publish many EventPassDelayedRevealed documents"""
  publishManyEventPassesDelayedRevealedConnection(
    after: ID
    before: ID
    first: Int

    """Stage to find matching documents in"""
    from: Stage = DRAFT
    last: Int

    """Document localizations to publish"""
    locales: [Locale!]

    """Whether to publish the base document"""
    publishBase: Boolean = true
    skip: Int

    """Stages to publish documents to"""
    to: [Stage!]! = [PUBLISHED]

    """Identifies documents in each stage to be published"""
    where: EventPassDelayedRevealedManyWhereInput

    """Whether to include the default locale when publishBase is true"""
    withDefaultLocale: Boolean = true
  ): EventPassDelayedRevealedConnection!

  """Publish many Event documents"""
  publishManyEvents(
    """Document localizations to publish"""
    locales: [Locale!]

    """Whether to publish the base document"""
    publishBase: Boolean = true

    """Stages to publish documents to"""
    to: [Stage!]! = [PUBLISHED]

    """Identifies documents in each stage to be published"""
    where: EventManyWhereInput

    """Whether to include the default locale when publishBase is true"""
    withDefaultLocale: Boolean = true
  ): BatchPayload!

  """Publish many Event documents"""
  publishManyEventsConnection(
    after: ID
    before: ID
    first: Int

    """Stage to find matching documents in"""
    from: Stage = DRAFT
    last: Int

    """Document localizations to publish"""
    locales: [Locale!]

    """Whether to publish the base document"""
    publishBase: Boolean = true
    skip: Int

    """Stages to publish documents to"""
    to: [Stage!]! = [PUBLISHED]

    """Identifies documents in each stage to be published"""
    where: EventManyWhereInput

    """Whether to include the default locale when publishBase is true"""
    withDefaultLocale: Boolean = true
  ): EventConnection!

  """Publish many Organizer documents"""
  publishManyOrganizers(
    """Document localizations to publish"""
    locales: [Locale!]

    """Whether to publish the base document"""
    publishBase: Boolean = true

    """Stages to publish documents to"""
    to: [Stage!]! = [PUBLISHED]

    """Identifies documents in each stage to be published"""
    where: OrganizerManyWhereInput

    """Whether to include the default locale when publishBase is true"""
    withDefaultLocale: Boolean = true
  ): BatchPayload!

  """Publish many Organizer documents"""
  publishManyOrganizersConnection(
    after: ID
    before: ID
    first: Int

    """Stage to find matching documents in"""
    from: Stage = DRAFT
    last: Int

    """Document localizations to publish"""
    locales: [Locale!]

    """Whether to publish the base document"""
    publishBase: Boolean = true
    skip: Int

    """Stages to publish documents to"""
    to: [Stage!]! = [PUBLISHED]

    """Identifies documents in each stage to be published"""
    where: OrganizerManyWhereInput

    """Whether to include the default locale when publishBase is true"""
    withDefaultLocale: Boolean = true
  ): OrganizerConnection!

  """Publish one organizer"""
  publishOrganizer(
    """Optional localizations to publish"""
    locales: [Locale!]

    """Whether to publish the base document"""
    publishBase: Boolean = true

    """Publishing target stage"""
    to: [Stage!]! = [PUBLISHED]

    """Document to publish"""
    where: OrganizerWhereUniqueInput!

    """Whether to include the default locale when publishBase is set"""
    withDefaultLocale: Boolean = true
  ): Organizer

  """Schedule to publish one asset"""
  schedulePublishAsset(
    """Optional localizations to publish"""
    locales: [Locale!]

    """Whether to publish the base document"""
    publishBase: Boolean = true

    """
    Release at point in time, will create new release containing this operation
    """
    releaseAt: DateTime

    """Optionally attach this scheduled operation to an existing release"""
    releaseId: String

    """Publishing target stage"""
    to: [Stage!]! = [PUBLISHED]

    """Document to publish"""
    where: AssetWhereUniqueInput!

    """Whether to include the default locale when publishBase is set"""
    withDefaultLocale: Boolean = true
  ): Asset

  """Schedule to publish one event"""
  schedulePublishEvent(
    """Optional localizations to publish"""
    locales: [Locale!]

    """Whether to publish the base document"""
    publishBase: Boolean = true

    """
    Release at point in time, will create new release containing this operation
    """
    releaseAt: DateTime

    """Optionally attach this scheduled operation to an existing release"""
    releaseId: String

    """Publishing target stage"""
    to: [Stage!]! = [PUBLISHED]

    """Document to publish"""
    where: EventWhereUniqueInput!

    """Whether to include the default locale when publishBase is set"""
    withDefaultLocale: Boolean = true
  ): Event

  """Schedule to publish one eventPass"""
  schedulePublishEventPass(
    """Optional localizations to publish"""
    locales: [Locale!]

    """Whether to publish the base document"""
    publishBase: Boolean = true

    """
    Release at point in time, will create new release containing this operation
    """
    releaseAt: DateTime

    """Optionally attach this scheduled operation to an existing release"""
    releaseId: String

    """Publishing target stage"""
    to: [Stage!]! = [PUBLISHED]

    """Document to publish"""
    where: EventPassWhereUniqueInput!

    """Whether to include the default locale when publishBase is set"""
    withDefaultLocale: Boolean = true
  ): EventPass

  """Schedule to publish one eventPassDelayedRevealed"""
  schedulePublishEventPassDelayedRevealed(
    """Optional localizations to publish"""
    locales: [Locale!]

    """Whether to publish the base document"""
    publishBase: Boolean = true

    """
    Release at point in time, will create new release containing this operation
    """
    releaseAt: DateTime

    """Optionally attach this scheduled operation to an existing release"""
    releaseId: String

    """Publishing target stage"""
    to: [Stage!]! = [PUBLISHED]

    """Document to publish"""
    where: EventPassDelayedRevealedWhereUniqueInput!

    """Whether to include the default locale when publishBase is set"""
    withDefaultLocale: Boolean = true
  ): EventPassDelayedRevealed

  """Schedule to publish one organizer"""
  schedulePublishOrganizer(
    """Optional localizations to publish"""
    locales: [Locale!]

    """Whether to publish the base document"""
    publishBase: Boolean = true

    """
    Release at point in time, will create new release containing this operation
    """
    releaseAt: DateTime

    """Optionally attach this scheduled operation to an existing release"""
    releaseId: String

    """Publishing target stage"""
    to: [Stage!]! = [PUBLISHED]

    """Document to publish"""
    where: OrganizerWhereUniqueInput!

    """Whether to include the default locale when publishBase is set"""
    withDefaultLocale: Boolean = true
  ): Organizer

  """
  Unpublish one asset from selected stages. Unpublish either the complete document with its relations, localizations and base data or specific localizations only.
  """
  scheduleUnpublishAsset(
    """Stages to unpublish document from"""
    from: [Stage!]! = [PUBLISHED]

    """
    Optional locales to unpublish. Unpublishing the default locale will completely remove the document from the selected stages
    """
    locales: [Locale!]

    """
    Release at point in time, will create new release containing this operation
    """
    releaseAt: DateTime

    """Optionally attach this scheduled operation to an existing release"""
    releaseId: String

    """
    Unpublish complete document including default localization and relations from stages. Can be disabled.
    """
    unpublishBase: Boolean = true

    """Document to unpublish"""
    where: AssetWhereUniqueInput!
  ): Asset

  """
  Unpublish one event from selected stages. Unpublish either the complete document with its relations, localizations and base data or specific localizations only.
  """
  scheduleUnpublishEvent(
    """Stages to unpublish document from"""
    from: [Stage!]! = [PUBLISHED]

    """
    Optional locales to unpublish. Unpublishing the default locale will completely remove the document from the selected stages
    """
    locales: [Locale!]

    """
    Release at point in time, will create new release containing this operation
    """
    releaseAt: DateTime

    """Optionally attach this scheduled operation to an existing release"""
    releaseId: String

    """
    Unpublish complete document including default localization and relations from stages. Can be disabled.
    """
    unpublishBase: Boolean = true

    """Document to unpublish"""
    where: EventWhereUniqueInput!
  ): Event

  """
  Unpublish one eventPass from selected stages. Unpublish either the complete document with its relations, localizations and base data or specific localizations only.
  """
  scheduleUnpublishEventPass(
    """Stages to unpublish document from"""
    from: [Stage!]! = [PUBLISHED]

    """
    Optional locales to unpublish. Unpublishing the default locale will completely remove the document from the selected stages
    """
    locales: [Locale!]

    """
    Release at point in time, will create new release containing this operation
    """
    releaseAt: DateTime

    """Optionally attach this scheduled operation to an existing release"""
    releaseId: String

    """
    Unpublish complete document including default localization and relations from stages. Can be disabled.
    """
    unpublishBase: Boolean = true

    """Document to unpublish"""
    where: EventPassWhereUniqueInput!
  ): EventPass

  """
  Unpublish one eventPassDelayedRevealed from selected stages. Unpublish either the complete document with its relations, localizations and base data or specific localizations only.
  """
  scheduleUnpublishEventPassDelayedRevealed(
    """Stages to unpublish document from"""
    from: [Stage!]! = [PUBLISHED]

    """
    Optional locales to unpublish. Unpublishing the default locale will completely remove the document from the selected stages
    """
    locales: [Locale!]

    """
    Release at point in time, will create new release containing this operation
    """
    releaseAt: DateTime

    """Optionally attach this scheduled operation to an existing release"""
    releaseId: String

    """
    Unpublish complete document including default localization and relations from stages. Can be disabled.
    """
    unpublishBase: Boolean = true

    """Document to unpublish"""
    where: EventPassDelayedRevealedWhereUniqueInput!
  ): EventPassDelayedRevealed

  """
  Unpublish one organizer from selected stages. Unpublish either the complete document with its relations, localizations and base data or specific localizations only.
  """
  scheduleUnpublishOrganizer(
    """Stages to unpublish document from"""
    from: [Stage!]! = [PUBLISHED]

    """
    Optional locales to unpublish. Unpublishing the default locale will completely remove the document from the selected stages
    """
    locales: [Locale!]

    """
    Release at point in time, will create new release containing this operation
    """
    releaseAt: DateTime

    """Optionally attach this scheduled operation to an existing release"""
    releaseId: String

    """
    Unpublish complete document including default localization and relations from stages. Can be disabled.
    """
    unpublishBase: Boolean = true

    """Document to unpublish"""
    where: OrganizerWhereUniqueInput!
  ): Organizer

  """
  Unpublish one asset from selected stages. Unpublish either the complete document with its relations, localizations and base data or specific localizations only.
  """
  unpublishAsset(
    """Stages to unpublish document from"""
    from: [Stage!]! = [PUBLISHED]

    """
    Optional locales to unpublish. Unpublishing the default locale will completely remove the document from the selected stages
    """
    locales: [Locale!]

    """
    Unpublish complete document including default localization and relations from stages. Can be disabled.
    """
    unpublishBase: Boolean = true

    """Document to unpublish"""
    where: AssetWhereUniqueInput!
  ): Asset

  """
  Unpublish one event from selected stages. Unpublish either the complete document with its relations, localizations and base data or specific localizations only.
  """
  unpublishEvent(
    """Stages to unpublish document from"""
    from: [Stage!]! = [PUBLISHED]

    """
    Optional locales to unpublish. Unpublishing the default locale will completely remove the document from the selected stages
    """
    locales: [Locale!]

    """
    Unpublish complete document including default localization and relations from stages. Can be disabled.
    """
    unpublishBase: Boolean = true

    """Document to unpublish"""
    where: EventWhereUniqueInput!
  ): Event

  """
  Unpublish one eventPass from selected stages. Unpublish either the complete document with its relations, localizations and base data or specific localizations only.
  """
  unpublishEventPass(
    """Stages to unpublish document from"""
    from: [Stage!]! = [PUBLISHED]

    """
    Optional locales to unpublish. Unpublishing the default locale will completely remove the document from the selected stages
    """
    locales: [Locale!]

    """
    Unpublish complete document including default localization and relations from stages. Can be disabled.
    """
    unpublishBase: Boolean = true

    """Document to unpublish"""
    where: EventPassWhereUniqueInput!
  ): EventPass

  """
  Unpublish one eventPassDelayedRevealed from selected stages. Unpublish either the complete document with its relations, localizations and base data or specific localizations only.
  """
  unpublishEventPassDelayedRevealed(
    """Stages to unpublish document from"""
    from: [Stage!]! = [PUBLISHED]

    """
    Optional locales to unpublish. Unpublishing the default locale will completely remove the document from the selected stages
    """
    locales: [Locale!]

    """
    Unpublish complete document including default localization and relations from stages. Can be disabled.
    """
    unpublishBase: Boolean = true

    """Document to unpublish"""
    where: EventPassDelayedRevealedWhereUniqueInput!
  ): EventPassDelayedRevealed

  """Unpublish many Asset documents"""
  unpublishManyAssets(
    """Stages to unpublish documents from"""
    from: [Stage!]! = [PUBLISHED]

    """Locales to unpublish"""
    locales: [Locale!]

    """Whether to unpublish the base document and default localization"""
    unpublishBase: Boolean = true

    """Identifies documents in each stage"""
    where: AssetManyWhereInput
  ): BatchPayload!

  """
  Find many Asset documents that match criteria in specified stage and unpublish from target stages
  """
  unpublishManyAssetsConnection(
    after: ID
    before: ID
    first: Int

    """Stages to unpublish documents from"""
    from: [Stage!]! = [PUBLISHED]
    last: Int

    """Locales to unpublish"""
    locales: [Locale!]
    skip: Int

    """Stage to find matching documents in"""
    stage: Stage = DRAFT

    """Whether to unpublish the base document and default localization"""
    unpublishBase: Boolean = true

    """Identifies documents in draft stage"""
    where: AssetManyWhereInput
  ): AssetConnection!

  """Unpublish many EventPass documents"""
  unpublishManyEventPasses(
    """Stages to unpublish documents from"""
    from: [Stage!]! = [PUBLISHED]

    """Locales to unpublish"""
    locales: [Locale!]

    """Whether to unpublish the base document and default localization"""
    unpublishBase: Boolean = true

    """Identifies documents in each stage"""
    where: EventPassManyWhereInput
  ): BatchPayload!

  """
  Find many EventPass documents that match criteria in specified stage and unpublish from target stages
  """
  unpublishManyEventPassesConnection(
    after: ID
    before: ID
    first: Int

    """Stages to unpublish documents from"""
    from: [Stage!]! = [PUBLISHED]
    last: Int

    """Locales to unpublish"""
    locales: [Locale!]
    skip: Int

    """Stage to find matching documents in"""
    stage: Stage = DRAFT

    """Whether to unpublish the base document and default localization"""
    unpublishBase: Boolean = true

    """Identifies documents in draft stage"""
    where: EventPassManyWhereInput
  ): EventPassConnection!

  """Unpublish many EventPassDelayedRevealed documents"""
  unpublishManyEventPassesDelayedRevealed(
    """Stages to unpublish documents from"""
    from: [Stage!]! = [PUBLISHED]

    """Locales to unpublish"""
    locales: [Locale!]

    """Whether to unpublish the base document and default localization"""
    unpublishBase: Boolean = true

    """Identifies documents in each stage"""
    where: EventPassDelayedRevealedManyWhereInput
  ): BatchPayload!

  """
  Find many EventPassDelayedRevealed documents that match criteria in specified stage and unpublish from target stages
  """
  unpublishManyEventPassesDelayedRevealedConnection(
    after: ID
    before: ID
    first: Int

    """Stages to unpublish documents from"""
    from: [Stage!]! = [PUBLISHED]
    last: Int

    """Locales to unpublish"""
    locales: [Locale!]
    skip: Int

    """Stage to find matching documents in"""
    stage: Stage = DRAFT

    """Whether to unpublish the base document and default localization"""
    unpublishBase: Boolean = true

    """Identifies documents in draft stage"""
    where: EventPassDelayedRevealedManyWhereInput
  ): EventPassDelayedRevealedConnection!

  """Unpublish many Event documents"""
  unpublishManyEvents(
    """Stages to unpublish documents from"""
    from: [Stage!]! = [PUBLISHED]

    """Locales to unpublish"""
    locales: [Locale!]

    """Whether to unpublish the base document and default localization"""
    unpublishBase: Boolean = true

    """Identifies documents in each stage"""
    where: EventManyWhereInput
  ): BatchPayload!

  """
  Find many Event documents that match criteria in specified stage and unpublish from target stages
  """
  unpublishManyEventsConnection(
    after: ID
    before: ID
    first: Int

    """Stages to unpublish documents from"""
    from: [Stage!]! = [PUBLISHED]
    last: Int

    """Locales to unpublish"""
    locales: [Locale!]
    skip: Int

    """Stage to find matching documents in"""
    stage: Stage = DRAFT

    """Whether to unpublish the base document and default localization"""
    unpublishBase: Boolean = true

    """Identifies documents in draft stage"""
    where: EventManyWhereInput
  ): EventConnection!

  """Unpublish many Organizer documents"""
  unpublishManyOrganizers(
    """Stages to unpublish documents from"""
    from: [Stage!]! = [PUBLISHED]

    """Locales to unpublish"""
    locales: [Locale!]

    """Whether to unpublish the base document and default localization"""
    unpublishBase: Boolean = true

    """Identifies documents in each stage"""
    where: OrganizerManyWhereInput
  ): BatchPayload!

  """
  Find many Organizer documents that match criteria in specified stage and unpublish from target stages
  """
  unpublishManyOrganizersConnection(
    after: ID
    before: ID
    first: Int

    """Stages to unpublish documents from"""
    from: [Stage!]! = [PUBLISHED]
    last: Int

    """Locales to unpublish"""
    locales: [Locale!]
    skip: Int

    """Stage to find matching documents in"""
    stage: Stage = DRAFT

    """Whether to unpublish the base document and default localization"""
    unpublishBase: Boolean = true

    """Identifies documents in draft stage"""
    where: OrganizerManyWhereInput
  ): OrganizerConnection!

  """
  Unpublish one organizer from selected stages. Unpublish either the complete document with its relations, localizations and base data or specific localizations only.
  """
  unpublishOrganizer(
    """Stages to unpublish document from"""
    from: [Stage!]! = [PUBLISHED]

    """
    Optional locales to unpublish. Unpublishing the default locale will completely remove the document from the selected stages
    """
    locales: [Locale!]

    """
    Unpublish complete document including default localization and relations from stages. Can be disabled.
    """
    unpublishBase: Boolean = true

    """Document to unpublish"""
    where: OrganizerWhereUniqueInput!
  ): Organizer

  """Update one asset"""
  updateAsset(data: AssetUpdateInput!, where: AssetWhereUniqueInput!): Asset

  """Update one event"""
  updateEvent(data: EventUpdateInput!, where: EventWhereUniqueInput!): Event

  """Update one eventPass"""
  updateEventPass(data: EventPassUpdateInput!, where: EventPassWhereUniqueInput!): EventPass

  """Update one eventPassDelayedRevealed"""
  updateEventPassDelayedRevealed(data: EventPassDelayedRevealedUpdateInput!, where: EventPassDelayedRevealedWhereUniqueInput!): EventPassDelayedRevealed

  """Update many assets"""
  updateManyAssets(
    """Updates to document content"""
    data: AssetUpdateManyInput!

    """Documents to apply update on"""
    where: AssetManyWhereInput
  ): BatchPayload!

  """Update many Asset documents"""
  updateManyAssetsConnection(
    after: ID
    before: ID

    """Updates to document content"""
    data: AssetUpdateManyInput!
    first: Int
    last: Int
    skip: Int

    """Documents to apply update on"""
    where: AssetManyWhereInput
  ): AssetConnection!

  """Update many eventPasses"""
  updateManyEventPasses(
    """Updates to document content"""
    data: EventPassUpdateManyInput!

    """Documents to apply update on"""
    where: EventPassManyWhereInput
  ): BatchPayload!

  """Update many EventPass documents"""
  updateManyEventPassesConnection(
    after: ID
    before: ID

    """Updates to document content"""
    data: EventPassUpdateManyInput!
    first: Int
    last: Int
    skip: Int

    """Documents to apply update on"""
    where: EventPassManyWhereInput
  ): EventPassConnection!

  """Update many eventPassesDelayedRevealed"""
  updateManyEventPassesDelayedRevealed(
    """Updates to document content"""
    data: EventPassDelayedRevealedUpdateManyInput!

    """Documents to apply update on"""
    where: EventPassDelayedRevealedManyWhereInput
  ): BatchPayload!

  """Update many EventPassDelayedRevealed documents"""
  updateManyEventPassesDelayedRevealedConnection(
    after: ID
    before: ID

    """Updates to document content"""
    data: EventPassDelayedRevealedUpdateManyInput!
    first: Int
    last: Int
    skip: Int

    """Documents to apply update on"""
    where: EventPassDelayedRevealedManyWhereInput
  ): EventPassDelayedRevealedConnection!

  """Update many events"""
  updateManyEvents(
    """Updates to document content"""
    data: EventUpdateManyInput!

    """Documents to apply update on"""
    where: EventManyWhereInput
  ): BatchPayload!

  """Update many Event documents"""
  updateManyEventsConnection(
    after: ID
    before: ID

    """Updates to document content"""
    data: EventUpdateManyInput!
    first: Int
    last: Int
    skip: Int

    """Documents to apply update on"""
    where: EventManyWhereInput
  ): EventConnection!

  """Update many organizers"""
  updateManyOrganizers(
    """Updates to document content"""
    data: OrganizerUpdateManyInput!

    """Documents to apply update on"""
    where: OrganizerManyWhereInput
  ): BatchPayload!

  """Update many Organizer documents"""
  updateManyOrganizersConnection(
    after: ID
    before: ID

    """Updates to document content"""
    data: OrganizerUpdateManyInput!
    first: Int
    last: Int
    skip: Int

    """Documents to apply update on"""
    where: OrganizerManyWhereInput
  ): OrganizerConnection!

  """Update one organizer"""
  updateOrganizer(data: OrganizerUpdateInput!, where: OrganizerWhereUniqueInput!): Organizer

  """Update one scheduledRelease"""
  updateScheduledRelease(data: ScheduledReleaseUpdateInput!, where: ScheduledReleaseWhereUniqueInput!): ScheduledRelease

  """
  update data of the table: "account"
  """
  update_account(
    """sets the columns of the filtered rows to the given values"""
    _set: account_set_input

    """filter the rows which have to be updated"""
    where: account_bool_exp!
  ): account_mutation_response

  """
  update single row of the table: "account"
  """
  update_account_by_pk(
    """sets the columns of the filtered rows to the given values"""
    _set: account_set_input
    pk_columns: account_pk_columns_input!
  ): account

  """
  update multiples rows of table: "account"
  """
  update_account_many(
    """updates to execute, in order"""
    updates: [account_updates!]!
  ): [account_mutation_response]

  """
  update data of the table: "audit.logged_actions"
  """
  update_audit_logged_actions(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: audit_logged_actions_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: audit_logged_actions_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: audit_logged_actions_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: audit_logged_actions_delete_key_input

    """increments the numeric columns with given value of the filtered values"""
    _inc: audit_logged_actions_inc_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: audit_logged_actions_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: audit_logged_actions_set_input

    """filter the rows which have to be updated"""
    where: audit_logged_actions_bool_exp!
  ): audit_logged_actions_mutation_response

  """
  update single row of the table: "audit.logged_actions"
  """
  update_audit_logged_actions_by_pk(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: audit_logged_actions_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: audit_logged_actions_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: audit_logged_actions_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: audit_logged_actions_delete_key_input

    """increments the numeric columns with given value of the filtered values"""
    _inc: audit_logged_actions_inc_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: audit_logged_actions_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: audit_logged_actions_set_input
    pk_columns: audit_logged_actions_pk_columns_input!
  ): audit_logged_actions

  """
  update multiples rows of table: "audit.logged_actions"
  """
  update_audit_logged_actions_many(
    """updates to execute, in order"""
    updates: [audit_logged_actions_updates!]!
  ): [audit_logged_actions_mutation_response]

  """
  update data of the table: "currency"
  """
  update_currency(
    """sets the columns of the filtered rows to the given values"""
    _set: currency_set_input

    """filter the rows which have to be updated"""
    where: currency_bool_exp!
  ): currency_mutation_response

  """
  update single row of the table: "currency"
  """
  update_currency_by_pk(
    """sets the columns of the filtered rows to the given values"""
    _set: currency_set_input
    pk_columns: currency_pk_columns_input!
  ): currency

  """
  update multiples rows of table: "currency"
  """
  update_currency_many(
    """updates to execute, in order"""
    updates: [currency_updates!]!
  ): [currency_mutation_response]

  """
  update data of the table: "eventParameters"
  """
  update_eventParameters(
    """sets the columns of the filtered rows to the given values"""
    _set: eventParameters_set_input

    """filter the rows which have to be updated"""
    where: eventParameters_bool_exp!
  ): eventParameters_mutation_response

  """
  update single row of the table: "eventParameters"
  """
  update_eventParameters_by_pk(
    """sets the columns of the filtered rows to the given values"""
    _set: eventParameters_set_input
    pk_columns: eventParameters_pk_columns_input!
  ): eventParameters

  """
  update multiples rows of table: "eventParameters"
  """
  update_eventParameters_many(
    """updates to execute, in order"""
    updates: [eventParameters_updates!]!
  ): [eventParameters_mutation_response]

  """
  update data of the table: "eventPassNft"
  """
  update_eventPassNft(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: eventPassNft_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: eventPassNft_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: eventPassNft_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: eventPassNft_delete_key_input

    """increments the numeric columns with given value of the filtered values"""
    _inc: eventPassNft_inc_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: eventPassNft_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: eventPassNft_set_input

    """filter the rows which have to be updated"""
    where: eventPassNft_bool_exp!
  ): eventPassNft_mutation_response

  """
  update data of the table: "eventPassNftContract"
  """
  update_eventPassNftContract(
    """sets the columns of the filtered rows to the given values"""
    _set: eventPassNftContract_set_input

    """filter the rows which have to be updated"""
    where: eventPassNftContract_bool_exp!
  ): eventPassNftContract_mutation_response

  """
  update data of the table: "eventPassNftContractType"
  """
  update_eventPassNftContractType(
    """sets the columns of the filtered rows to the given values"""
    _set: eventPassNftContractType_set_input

    """filter the rows which have to be updated"""
    where: eventPassNftContractType_bool_exp!
  ): eventPassNftContractType_mutation_response

  """
  update single row of the table: "eventPassNftContractType"
  """
  update_eventPassNftContractType_by_pk(
    """sets the columns of the filtered rows to the given values"""
    _set: eventPassNftContractType_set_input
    pk_columns: eventPassNftContractType_pk_columns_input!
  ): eventPassNftContractType

  """
  update multiples rows of table: "eventPassNftContractType"
  """
  update_eventPassNftContractType_many(
    """updates to execute, in order"""
    updates: [eventPassNftContractType_updates!]!
  ): [eventPassNftContractType_mutation_response]

  """
  update multiples rows of table: "eventPassNftContract"
  """
  update_eventPassNftContract_many(
    """updates to execute, in order"""
    updates: [eventPassNftContract_updates!]!
  ): [eventPassNftContract_mutation_response]

  """
  update single row of the table: "eventPassNft"
  """
  update_eventPassNft_by_pk(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: eventPassNft_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: eventPassNft_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: eventPassNft_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: eventPassNft_delete_key_input

    """increments the numeric columns with given value of the filtered values"""
    _inc: eventPassNft_inc_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: eventPassNft_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: eventPassNft_set_input
    pk_columns: eventPassNft_pk_columns_input!
  ): eventPassNft

  """
  update multiples rows of table: "eventPassNft"
  """
  update_eventPassNft_many(
    """updates to execute, in order"""
    updates: [eventPassNft_updates!]!
  ): [eventPassNft_mutation_response]

  """
  update data of the table: "eventPassOrder"
  """
  update_eventPassOrder(
    """increments the numeric columns with given value of the filtered values"""
    _inc: eventPassOrder_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: eventPassOrder_set_input

    """filter the rows which have to be updated"""
    where: eventPassOrder_bool_exp!
  ): eventPassOrder_mutation_response

  """
  update data of the table: "eventPassOrderSums"
  """
  update_eventPassOrderSums(
    """increments the numeric columns with given value of the filtered values"""
    _inc: eventPassOrderSums_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: eventPassOrderSums_set_input

    """filter the rows which have to be updated"""
    where: eventPassOrderSums_bool_exp!
  ): eventPassOrderSums_mutation_response

  """
  update single row of the table: "eventPassOrderSums"
  """
  update_eventPassOrderSums_by_pk(
    """increments the numeric columns with given value of the filtered values"""
    _inc: eventPassOrderSums_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: eventPassOrderSums_set_input
    pk_columns: eventPassOrderSums_pk_columns_input!
  ): eventPassOrderSums

  """
  update multiples rows of table: "eventPassOrderSums"
  """
  update_eventPassOrderSums_many(
    """updates to execute, in order"""
    updates: [eventPassOrderSums_updates!]!
  ): [eventPassOrderSums_mutation_response]

  """
  update single row of the table: "eventPassOrder"
  """
  update_eventPassOrder_by_pk(
    """increments the numeric columns with given value of the filtered values"""
    _inc: eventPassOrder_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: eventPassOrder_set_input
    pk_columns: eventPassOrder_pk_columns_input!
  ): eventPassOrder

  """
  update multiples rows of table: "eventPassOrder"
  """
  update_eventPassOrder_many(
    """updates to execute, in order"""
    updates: [eventPassOrder_updates!]!
  ): [eventPassOrder_mutation_response]

  """
  update data of the table: "eventPassPendingOrder"
  """
  update_eventPassPendingOrder(
    """increments the numeric columns with given value of the filtered values"""
    _inc: eventPassPendingOrder_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: eventPassPendingOrder_set_input

    """filter the rows which have to be updated"""
    where: eventPassPendingOrder_bool_exp!
  ): eventPassPendingOrder_mutation_response

  """
  update single row of the table: "eventPassPendingOrder"
  """
  update_eventPassPendingOrder_by_pk(
    """increments the numeric columns with given value of the filtered values"""
    _inc: eventPassPendingOrder_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: eventPassPendingOrder_set_input
    pk_columns: eventPassPendingOrder_pk_columns_input!
  ): eventPassPendingOrder

  """
  update multiples rows of table: "eventPassPendingOrder"
  """
  update_eventPassPendingOrder_many(
    """updates to execute, in order"""
    updates: [eventPassPendingOrder_updates!]!
  ): [eventPassPendingOrder_mutation_response]

  """
  update data of the table: "eventPassPricing"
  """
  update_eventPassPricing(
    """increments the numeric columns with given value of the filtered values"""
    _inc: eventPassPricing_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: eventPassPricing_set_input

    """filter the rows which have to be updated"""
    where: eventPassPricing_bool_exp!
  ): eventPassPricing_mutation_response

  """
  update single row of the table: "eventPassPricing"
  """
  update_eventPassPricing_by_pk(
    """increments the numeric columns with given value of the filtered values"""
    _inc: eventPassPricing_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: eventPassPricing_set_input
    pk_columns: eventPassPricing_pk_columns_input!
  ): eventPassPricing

  """
  update multiples rows of table: "eventPassPricing"
  """
  update_eventPassPricing_many(
    """updates to execute, in order"""
    updates: [eventPassPricing_updates!]!
  ): [eventPassPricing_mutation_response]

  """
  update data of the table: "follow"
  """
  update_follow(
    """sets the columns of the filtered rows to the given values"""
    _set: follow_set_input

    """filter the rows which have to be updated"""
    where: follow_bool_exp!
  ): follow_mutation_response

  """
  update single row of the table: "follow"
  """
  update_follow_by_pk(
    """sets the columns of the filtered rows to the given values"""
    _set: follow_set_input
    pk_columns: follow_pk_columns_input!
  ): follow

  """
  update multiples rows of table: "follow"
  """
  update_follow_many(
    """updates to execute, in order"""
    updates: [follow_updates!]!
  ): [follow_mutation_response]

  """
  update data of the table: "kyc"
  """
  update_kyc(
    """sets the columns of the filtered rows to the given values"""
    _set: kyc_set_input

    """filter the rows which have to be updated"""
    where: kyc_bool_exp!
  ): kyc_mutation_response

  """
  update data of the table: "kycLevelName"
  """
  update_kycLevelName(
    """sets the columns of the filtered rows to the given values"""
    _set: kycLevelName_set_input

    """filter the rows which have to be updated"""
    where: kycLevelName_bool_exp!
  ): kycLevelName_mutation_response

  """
  update single row of the table: "kycLevelName"
  """
  update_kycLevelName_by_pk(
    """sets the columns of the filtered rows to the given values"""
    _set: kycLevelName_set_input
    pk_columns: kycLevelName_pk_columns_input!
  ): kycLevelName

  """
  update multiples rows of table: "kycLevelName"
  """
  update_kycLevelName_many(
    """updates to execute, in order"""
    updates: [kycLevelName_updates!]!
  ): [kycLevelName_mutation_response]

  """
  update data of the table: "kycStatus"
  """
  update_kycStatus(
    """sets the columns of the filtered rows to the given values"""
    _set: kycStatus_set_input

    """filter the rows which have to be updated"""
    where: kycStatus_bool_exp!
  ): kycStatus_mutation_response

  """
  update single row of the table: "kycStatus"
  """
  update_kycStatus_by_pk(
    """sets the columns of the filtered rows to the given values"""
    _set: kycStatus_set_input
    pk_columns: kycStatus_pk_columns_input!
  ): kycStatus

  """
  update multiples rows of table: "kycStatus"
  """
  update_kycStatus_many(
    """updates to execute, in order"""
    updates: [kycStatus_updates!]!
  ): [kycStatus_mutation_response]

  """
  update single row of the table: "kyc"
  """
  update_kyc_by_pk(
    """sets the columns of the filtered rows to the given values"""
    _set: kyc_set_input
    pk_columns: kyc_pk_columns_input!
  ): kyc

  """
  update multiples rows of table: "kyc"
  """
  update_kyc_many(
    """updates to execute, in order"""
    updates: [kyc_updates!]!
  ): [kyc_mutation_response]

  """
  update data of the table: "nftTransfer"
  """
  update_nftTransfer(
    """increments the numeric columns with given value of the filtered values"""
    _inc: nftTransfer_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: nftTransfer_set_input

    """filter the rows which have to be updated"""
    where: nftTransfer_bool_exp!
  ): nftTransfer_mutation_response

  """
  update single row of the table: "nftTransfer"
  """
  update_nftTransfer_by_pk(
    """increments the numeric columns with given value of the filtered values"""
    _inc: nftTransfer_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: nftTransfer_set_input
    pk_columns: nftTransfer_pk_columns_input!
  ): nftTransfer

  """
  update multiples rows of table: "nftTransfer"
  """
  update_nftTransfer_many(
    """updates to execute, in order"""
    updates: [nftTransfer_updates!]!
  ): [nftTransfer_mutation_response]

  """
  update data of the table: "orderStatus"
  """
  update_orderStatus(
    """sets the columns of the filtered rows to the given values"""
    _set: orderStatus_set_input

    """filter the rows which have to be updated"""
    where: orderStatus_bool_exp!
  ): orderStatus_mutation_response

  """
  update single row of the table: "orderStatus"
  """
  update_orderStatus_by_pk(
    """sets the columns of the filtered rows to the given values"""
    _set: orderStatus_set_input
    pk_columns: orderStatus_pk_columns_input!
  ): orderStatus

  """
  update multiples rows of table: "orderStatus"
  """
  update_orderStatus_many(
    """updates to execute, in order"""
    updates: [orderStatus_updates!]!
  ): [orderStatus_mutation_response]

  """
  update data of the table: "packNftContract"
  """
  update_packNftContract(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: packNftContract_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: packNftContract_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: packNftContract_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: packNftContract_delete_key_input

    """increments the numeric columns with given value of the filtered values"""
    _inc: packNftContract_inc_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: packNftContract_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: packNftContract_set_input

    """filter the rows which have to be updated"""
    where: packNftContract_bool_exp!
  ): packNftContract_mutation_response

  """
  update single row of the table: "packNftContract"
  """
  update_packNftContract_by_pk(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: packNftContract_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: packNftContract_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: packNftContract_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: packNftContract_delete_key_input

    """increments the numeric columns with given value of the filtered values"""
    _inc: packNftContract_inc_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: packNftContract_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: packNftContract_set_input
    pk_columns: packNftContract_pk_columns_input!
  ): packNftContract

  """
  update multiples rows of table: "packNftContract"
  """
  update_packNftContract_many(
    """updates to execute, in order"""
    updates: [packNftContract_updates!]!
  ): [packNftContract_mutation_response]

  """
  update data of the table: "roleAssignments"
  """
  update_roleAssignments(
    """sets the columns of the filtered rows to the given values"""
    _set: roleAssignments_set_input

    """filter the rows which have to be updated"""
    where: roleAssignments_bool_exp!
  ): roleAssignments_mutation_response

  """
  update multiples rows of table: "roleAssignments"
  """
  update_roleAssignments_many(
    """updates to execute, in order"""
    updates: [roleAssignments_updates!]!
  ): [roleAssignments_mutation_response]

  """
  update data of the table: "roles"
  """
  update_roles(
    """sets the columns of the filtered rows to the given values"""
    _set: roles_set_input

    """filter the rows which have to be updated"""
    where: roles_bool_exp!
  ): roles_mutation_response

  """
  update single row of the table: "roles"
  """
  update_roles_by_pk(
    """sets the columns of the filtered rows to the given values"""
    _set: roles_set_input
    pk_columns: roles_pk_columns_input!
  ): roles

  """
  update multiples rows of table: "roles"
  """
  update_roles_many(
    """updates to execute, in order"""
    updates: [roles_updates!]!
  ): [roles_mutation_response]

  """
  update data of the table: "stripeCheckoutSession"
  """
  update_stripeCheckoutSession(
    """sets the columns of the filtered rows to the given values"""
    _set: stripeCheckoutSession_set_input

    """filter the rows which have to be updated"""
    where: stripeCheckoutSession_bool_exp!
  ): stripeCheckoutSession_mutation_response

  """
  update data of the table: "stripeCheckoutSessionType"
  """
  update_stripeCheckoutSessionType(
    """sets the columns of the filtered rows to the given values"""
    _set: stripeCheckoutSessionType_set_input

    """filter the rows which have to be updated"""
    where: stripeCheckoutSessionType_bool_exp!
  ): stripeCheckoutSessionType_mutation_response

  """
  update single row of the table: "stripeCheckoutSessionType"
  """
  update_stripeCheckoutSessionType_by_pk(
    """sets the columns of the filtered rows to the given values"""
    _set: stripeCheckoutSessionType_set_input
    pk_columns: stripeCheckoutSessionType_pk_columns_input!
  ): stripeCheckoutSessionType

  """
  update multiples rows of table: "stripeCheckoutSessionType"
  """
  update_stripeCheckoutSessionType_many(
    """updates to execute, in order"""
    updates: [stripeCheckoutSessionType_updates!]!
  ): [stripeCheckoutSessionType_mutation_response]

  """
  update single row of the table: "stripeCheckoutSession"
  """
  update_stripeCheckoutSession_by_pk(
    """sets the columns of the filtered rows to the given values"""
    _set: stripeCheckoutSession_set_input
    pk_columns: stripeCheckoutSession_pk_columns_input!
  ): stripeCheckoutSession

  """
  update multiples rows of table: "stripeCheckoutSession"
  """
  update_stripeCheckoutSession_many(
    """updates to execute, in order"""
    updates: [stripeCheckoutSession_updates!]!
  ): [stripeCheckoutSession_mutation_response]

  """
  update data of the table: "stripeCustomer"
  """
  update_stripeCustomer(
    """sets the columns of the filtered rows to the given values"""
    _set: stripeCustomer_set_input

    """filter the rows which have to be updated"""
    where: stripeCustomer_bool_exp!
  ): stripeCustomer_mutation_response

  """
  update single row of the table: "stripeCustomer"
  """
  update_stripeCustomer_by_pk(
    """sets the columns of the filtered rows to the given values"""
    _set: stripeCustomer_set_input
    pk_columns: stripeCustomer_pk_columns_input!
  ): stripeCustomer

  """
  update multiples rows of table: "stripeCustomer"
  """
  update_stripeCustomer_many(
    """updates to execute, in order"""
    updates: [stripeCustomer_updates!]!
  ): [stripeCustomer_mutation_response]

  """
  update data of the table: "timezone"
  """
  update_timezone(
    """sets the columns of the filtered rows to the given values"""
    _set: timezone_set_input

    """filter the rows which have to be updated"""
    where: timezone_bool_exp!
  ): timezone_mutation_response

  """
  update single row of the table: "timezone"
  """
  update_timezone_by_pk(
    """sets the columns of the filtered rows to the given values"""
    _set: timezone_set_input
    pk_columns: timezone_pk_columns_input!
  ): timezone

  """
  update multiples rows of table: "timezone"
  """
  update_timezone_many(
    """updates to execute, in order"""
    updates: [timezone_updates!]!
  ): [timezone_mutation_response]

  """Upsert one asset"""
  upsertAsset(upsert: AssetUpsertInput!, where: AssetWhereUniqueInput!): Asset

  """Upsert one event"""
  upsertEvent(upsert: EventUpsertInput!, where: EventWhereUniqueInput!): Event

  """Upsert one eventPass"""
  upsertEventPass(upsert: EventPassUpsertInput!, where: EventPassWhereUniqueInput!): EventPass

  """Upsert one eventPassDelayedRevealed"""
  upsertEventPassDelayedRevealed(upsert: EventPassDelayedRevealedUpsertInput!, where: EventPassDelayedRevealedWhereUniqueInput!): EventPassDelayedRevealed

  """Upsert one organizer"""
  upsertOrganizer(upsert: OrganizerUpsertInput!, where: OrganizerWhereUniqueInput!): Organizer
}

"""
The nftTransfer model is built to record and chronicle the transfer of NFTs between addresses. This model is crucial in tracing the movement of an NFT, especially when validating that an event pass has reached its intended recipient. Such a system facilitates debugging and reduces the need for excessive querying of our indexer. Entries in this table are populated through two primary avenues: either via an activity webhook responding to real-time NFT transfers or through a regular cron job as a failsafe, ensuring data integrity even if the webhook fails to capture certain events.
"""
type nftTransfer {
  """
  The specific block on the blockchain where this transfer was recorded. Allows for pinpointing the exact point of transfer in the blockchain's history.
  """
  blockNumber: bigint!

  """
  Indicates the specific blockchain or network where the NFT resides. Useful in a multi-chain environment to distinguish between various chains.
  """
  chainId: String!

  """
  Identifies the smart contract associated with the NFT. This provides a direct link to the NFT's origin and behavior on the blockchain.
  """
  contractAddress: String!
  created_at: timestamptz!

  """
  Refers to the associated event ID for which the NFT was transferred. Ties the NFT transfer to a particular event in the platform.
  """
  eventId: String!

  """
  Denotes the specific Event Pass associated with the NFT. Helps in tracking the lifecycle of a particular event pass.
  """
  eventPassId: String!

  """
  Denotes the source address from which the NFT was transferred. Essential to trace the sender in the NFT's movement.
  """
  fromAddress: String!
  id: uuid!

  """
  Identifies the organizer who facilitated the event linked to the NFT transfer. Aids in associating NFT movements with specific organizers.
  """
  organizerId: String!

  """
  Specifies the destination address receiving the NFT. Critical for determining the current holder of the NFT.
  """
  toAddress: String!

  """
  The unique identifier for the NFT within its associated smart contract. Maintains a constant reference to the NFT across platforms.
  """
  tokenId: bigint!

  """
  Represents the unique hash of the transaction in which the NFT was transferred. Ensures traceability and verification on the blockchain.
  """
  transactionHash: String!
}

"""
aggregated selection of "nftTransfer"
"""
type nftTransfer_aggregate {
  aggregate: nftTransfer_aggregate_fields
  nodes: [nftTransfer!]!
}

input nftTransfer_aggregate_bool_exp {
  count: nftTransfer_aggregate_bool_exp_count
}

input nftTransfer_aggregate_bool_exp_count {
  arguments: [nftTransfer_select_column!]
  distinct: Boolean
  filter: nftTransfer_bool_exp
  predicate: Int_comparison_exp!
}

"""
aggregate fields of "nftTransfer"
"""
type nftTransfer_aggregate_fields {
  avg: nftTransfer_avg_fields
  count(columns: [nftTransfer_select_column!], distinct: Boolean): Int!
  max: nftTransfer_max_fields
  min: nftTransfer_min_fields
  stddev: nftTransfer_stddev_fields
  stddev_pop: nftTransfer_stddev_pop_fields
  stddev_samp: nftTransfer_stddev_samp_fields
  sum: nftTransfer_sum_fields
  var_pop: nftTransfer_var_pop_fields
  var_samp: nftTransfer_var_samp_fields
  variance: nftTransfer_variance_fields
}

"""
order by aggregate values of table "nftTransfer"
"""
input nftTransfer_aggregate_order_by {
  avg: nftTransfer_avg_order_by
  count: order_by
  max: nftTransfer_max_order_by
  min: nftTransfer_min_order_by
  stddev: nftTransfer_stddev_order_by
  stddev_pop: nftTransfer_stddev_pop_order_by
  stddev_samp: nftTransfer_stddev_samp_order_by
  sum: nftTransfer_sum_order_by
  var_pop: nftTransfer_var_pop_order_by
  var_samp: nftTransfer_var_samp_order_by
  variance: nftTransfer_variance_order_by
}

"""
input type for inserting array relation for remote table "nftTransfer"
"""
input nftTransfer_arr_rel_insert_input {
  data: [nftTransfer_insert_input!]!

  """upsert condition"""
  on_conflict: nftTransfer_on_conflict
}

"""aggregate avg on columns"""
type nftTransfer_avg_fields {
  """
  The specific block on the blockchain where this transfer was recorded. Allows for pinpointing the exact point of transfer in the blockchain's history.
  """
  blockNumber: Float

  """
  The unique identifier for the NFT within its associated smart contract. Maintains a constant reference to the NFT across platforms.
  """
  tokenId: Float
}

"""
order by avg() on columns of table "nftTransfer"
"""
input nftTransfer_avg_order_by {
  """
  The specific block on the blockchain where this transfer was recorded. Allows for pinpointing the exact point of transfer in the blockchain's history.
  """
  blockNumber: order_by

  """
  The unique identifier for the NFT within its associated smart contract. Maintains a constant reference to the NFT across platforms.
  """
  tokenId: order_by
}

"""
Boolean expression to filter rows from the table "nftTransfer". All fields are combined with a logical 'AND'.
"""
input nftTransfer_bool_exp {
  _and: [nftTransfer_bool_exp!]
  _not: nftTransfer_bool_exp
  _or: [nftTransfer_bool_exp!]
  blockNumber: bigint_comparison_exp
  chainId: String_comparison_exp
  contractAddress: String_comparison_exp
  created_at: timestamptz_comparison_exp
  eventId: String_comparison_exp
  eventPassId: String_comparison_exp
  fromAddress: String_comparison_exp
  id: uuid_comparison_exp
  organizerId: String_comparison_exp
  toAddress: String_comparison_exp
  tokenId: bigint_comparison_exp
  transactionHash: String_comparison_exp
}

"""
unique or primary key constraints on table "nftTransfer"
"""
enum nftTransfer_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  nftTransfer_pkey

  """
  unique or primary key constraint on columns "transactionHash", "contractAddress", "tokenId"
  """
  nft_transfer_unique_transfer
}

"""
input type for incrementing numeric columns in table "nftTransfer"
"""
input nftTransfer_inc_input {
  """
  The specific block on the blockchain where this transfer was recorded. Allows for pinpointing the exact point of transfer in the blockchain's history.
  """
  blockNumber: bigint

  """
  The unique identifier for the NFT within its associated smart contract. Maintains a constant reference to the NFT across platforms.
  """
  tokenId: bigint
}

"""
input type for inserting data into table "nftTransfer"
"""
input nftTransfer_insert_input {
  """
  The specific block on the blockchain where this transfer was recorded. Allows for pinpointing the exact point of transfer in the blockchain's history.
  """
  blockNumber: bigint

  """
  Indicates the specific blockchain or network where the NFT resides. Useful in a multi-chain environment to distinguish between various chains.
  """
  chainId: String

  """
  Identifies the smart contract associated with the NFT. This provides a direct link to the NFT's origin and behavior on the blockchain.
  """
  contractAddress: String
  created_at: timestamptz

  """
  Refers to the associated event ID for which the NFT was transferred. Ties the NFT transfer to a particular event in the platform.
  """
  eventId: String

  """
  Denotes the specific Event Pass associated with the NFT. Helps in tracking the lifecycle of a particular event pass.
  """
  eventPassId: String

  """
  Denotes the source address from which the NFT was transferred. Essential to trace the sender in the NFT's movement.
  """
  fromAddress: String
  id: uuid

  """
  Identifies the organizer who facilitated the event linked to the NFT transfer. Aids in associating NFT movements with specific organizers.
  """
  organizerId: String

  """
  Specifies the destination address receiving the NFT. Critical for determining the current holder of the NFT.
  """
  toAddress: String

  """
  The unique identifier for the NFT within its associated smart contract. Maintains a constant reference to the NFT across platforms.
  """
  tokenId: bigint

  """
  Represents the unique hash of the transaction in which the NFT was transferred. Ensures traceability and verification on the blockchain.
  """
  transactionHash: String
}

"""aggregate max on columns"""
type nftTransfer_max_fields {
  """
  The specific block on the blockchain where this transfer was recorded. Allows for pinpointing the exact point of transfer in the blockchain's history.
  """
  blockNumber: bigint

  """
  Indicates the specific blockchain or network where the NFT resides. Useful in a multi-chain environment to distinguish between various chains.
  """
  chainId: String

  """
  Identifies the smart contract associated with the NFT. This provides a direct link to the NFT's origin and behavior on the blockchain.
  """
  contractAddress: String
  created_at: timestamptz

  """
  Refers to the associated event ID for which the NFT was transferred. Ties the NFT transfer to a particular event in the platform.
  """
  eventId: String

  """
  Denotes the specific Event Pass associated with the NFT. Helps in tracking the lifecycle of a particular event pass.
  """
  eventPassId: String

  """
  Denotes the source address from which the NFT was transferred. Essential to trace the sender in the NFT's movement.
  """
  fromAddress: String
  id: uuid

  """
  Identifies the organizer who facilitated the event linked to the NFT transfer. Aids in associating NFT movements with specific organizers.
  """
  organizerId: String

  """
  Specifies the destination address receiving the NFT. Critical for determining the current holder of the NFT.
  """
  toAddress: String

  """
  The unique identifier for the NFT within its associated smart contract. Maintains a constant reference to the NFT across platforms.
  """
  tokenId: bigint

  """
  Represents the unique hash of the transaction in which the NFT was transferred. Ensures traceability and verification on the blockchain.
  """
  transactionHash: String
}

"""
order by max() on columns of table "nftTransfer"
"""
input nftTransfer_max_order_by {
  """
  The specific block on the blockchain where this transfer was recorded. Allows for pinpointing the exact point of transfer in the blockchain's history.
  """
  blockNumber: order_by

  """
  Indicates the specific blockchain or network where the NFT resides. Useful in a multi-chain environment to distinguish between various chains.
  """
  chainId: order_by

  """
  Identifies the smart contract associated with the NFT. This provides a direct link to the NFT's origin and behavior on the blockchain.
  """
  contractAddress: order_by
  created_at: order_by

  """
  Refers to the associated event ID for which the NFT was transferred. Ties the NFT transfer to a particular event in the platform.
  """
  eventId: order_by

  """
  Denotes the specific Event Pass associated with the NFT. Helps in tracking the lifecycle of a particular event pass.
  """
  eventPassId: order_by

  """
  Denotes the source address from which the NFT was transferred. Essential to trace the sender in the NFT's movement.
  """
  fromAddress: order_by
  id: order_by

  """
  Identifies the organizer who facilitated the event linked to the NFT transfer. Aids in associating NFT movements with specific organizers.
  """
  organizerId: order_by

  """
  Specifies the destination address receiving the NFT. Critical for determining the current holder of the NFT.
  """
  toAddress: order_by

  """
  The unique identifier for the NFT within its associated smart contract. Maintains a constant reference to the NFT across platforms.
  """
  tokenId: order_by

  """
  Represents the unique hash of the transaction in which the NFT was transferred. Ensures traceability and verification on the blockchain.
  """
  transactionHash: order_by
}

"""aggregate min on columns"""
type nftTransfer_min_fields {
  """
  The specific block on the blockchain where this transfer was recorded. Allows for pinpointing the exact point of transfer in the blockchain's history.
  """
  blockNumber: bigint

  """
  Indicates the specific blockchain or network where the NFT resides. Useful in a multi-chain environment to distinguish between various chains.
  """
  chainId: String

  """
  Identifies the smart contract associated with the NFT. This provides a direct link to the NFT's origin and behavior on the blockchain.
  """
  contractAddress: String
  created_at: timestamptz

  """
  Refers to the associated event ID for which the NFT was transferred. Ties the NFT transfer to a particular event in the platform.
  """
  eventId: String

  """
  Denotes the specific Event Pass associated with the NFT. Helps in tracking the lifecycle of a particular event pass.
  """
  eventPassId: String

  """
  Denotes the source address from which the NFT was transferred. Essential to trace the sender in the NFT's movement.
  """
  fromAddress: String
  id: uuid

  """
  Identifies the organizer who facilitated the event linked to the NFT transfer. Aids in associating NFT movements with specific organizers.
  """
  organizerId: String

  """
  Specifies the destination address receiving the NFT. Critical for determining the current holder of the NFT.
  """
  toAddress: String

  """
  The unique identifier for the NFT within its associated smart contract. Maintains a constant reference to the NFT across platforms.
  """
  tokenId: bigint

  """
  Represents the unique hash of the transaction in which the NFT was transferred. Ensures traceability and verification on the blockchain.
  """
  transactionHash: String
}

"""
order by min() on columns of table "nftTransfer"
"""
input nftTransfer_min_order_by {
  """
  The specific block on the blockchain where this transfer was recorded. Allows for pinpointing the exact point of transfer in the blockchain's history.
  """
  blockNumber: order_by

  """
  Indicates the specific blockchain or network where the NFT resides. Useful in a multi-chain environment to distinguish between various chains.
  """
  chainId: order_by

  """
  Identifies the smart contract associated with the NFT. This provides a direct link to the NFT's origin and behavior on the blockchain.
  """
  contractAddress: order_by
  created_at: order_by

  """
  Refers to the associated event ID for which the NFT was transferred. Ties the NFT transfer to a particular event in the platform.
  """
  eventId: order_by

  """
  Denotes the specific Event Pass associated with the NFT. Helps in tracking the lifecycle of a particular event pass.
  """
  eventPassId: order_by

  """
  Denotes the source address from which the NFT was transferred. Essential to trace the sender in the NFT's movement.
  """
  fromAddress: order_by
  id: order_by

  """
  Identifies the organizer who facilitated the event linked to the NFT transfer. Aids in associating NFT movements with specific organizers.
  """
  organizerId: order_by

  """
  Specifies the destination address receiving the NFT. Critical for determining the current holder of the NFT.
  """
  toAddress: order_by

  """
  The unique identifier for the NFT within its associated smart contract. Maintains a constant reference to the NFT across platforms.
  """
  tokenId: order_by

  """
  Represents the unique hash of the transaction in which the NFT was transferred. Ensures traceability and verification on the blockchain.
  """
  transactionHash: order_by
}

"""
response of any mutation on the table "nftTransfer"
"""
type nftTransfer_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [nftTransfer!]!
}

"""
input type for inserting object relation for remote table "nftTransfer"
"""
input nftTransfer_obj_rel_insert_input {
  data: nftTransfer_insert_input!

  """upsert condition"""
  on_conflict: nftTransfer_on_conflict
}

"""
on_conflict condition type for table "nftTransfer"
"""
input nftTransfer_on_conflict {
  constraint: nftTransfer_constraint!
  update_columns: [nftTransfer_update_column!]! = []
  where: nftTransfer_bool_exp
}

"""Ordering options when selecting data from "nftTransfer"."""
input nftTransfer_order_by {
  blockNumber: order_by
  chainId: order_by
  contractAddress: order_by
  created_at: order_by
  eventId: order_by
  eventPassId: order_by
  fromAddress: order_by
  id: order_by
  organizerId: order_by
  toAddress: order_by
  tokenId: order_by
  transactionHash: order_by
}

"""primary key columns input for table: nftTransfer"""
input nftTransfer_pk_columns_input {
  id: uuid!
}

"""
select columns of table "nftTransfer"
"""
enum nftTransfer_select_column {
  """column name"""
  blockNumber

  """column name"""
  chainId

  """column name"""
  contractAddress

  """column name"""
  created_at

  """column name"""
  eventId

  """column name"""
  eventPassId

  """column name"""
  fromAddress

  """column name"""
  id

  """column name"""
  organizerId

  """column name"""
  toAddress

  """column name"""
  tokenId

  """column name"""
  transactionHash
}

"""
input type for updating data in table "nftTransfer"
"""
input nftTransfer_set_input {
  """
  The specific block on the blockchain where this transfer was recorded. Allows for pinpointing the exact point of transfer in the blockchain's history.
  """
  blockNumber: bigint

  """
  Indicates the specific blockchain or network where the NFT resides. Useful in a multi-chain environment to distinguish between various chains.
  """
  chainId: String

  """
  Identifies the smart contract associated with the NFT. This provides a direct link to the NFT's origin and behavior on the blockchain.
  """
  contractAddress: String
  created_at: timestamptz

  """
  Refers to the associated event ID for which the NFT was transferred. Ties the NFT transfer to a particular event in the platform.
  """
  eventId: String

  """
  Denotes the specific Event Pass associated with the NFT. Helps in tracking the lifecycle of a particular event pass.
  """
  eventPassId: String

  """
  Denotes the source address from which the NFT was transferred. Essential to trace the sender in the NFT's movement.
  """
  fromAddress: String
  id: uuid

  """
  Identifies the organizer who facilitated the event linked to the NFT transfer. Aids in associating NFT movements with specific organizers.
  """
  organizerId: String

  """
  Specifies the destination address receiving the NFT. Critical for determining the current holder of the NFT.
  """
  toAddress: String

  """
  The unique identifier for the NFT within its associated smart contract. Maintains a constant reference to the NFT across platforms.
  """
  tokenId: bigint

  """
  Represents the unique hash of the transaction in which the NFT was transferred. Ensures traceability and verification on the blockchain.
  """
  transactionHash: String
}

"""aggregate stddev on columns"""
type nftTransfer_stddev_fields {
  """
  The specific block on the blockchain where this transfer was recorded. Allows for pinpointing the exact point of transfer in the blockchain's history.
  """
  blockNumber: Float

  """
  The unique identifier for the NFT within its associated smart contract. Maintains a constant reference to the NFT across platforms.
  """
  tokenId: Float
}

"""
order by stddev() on columns of table "nftTransfer"
"""
input nftTransfer_stddev_order_by {
  """
  The specific block on the blockchain where this transfer was recorded. Allows for pinpointing the exact point of transfer in the blockchain's history.
  """
  blockNumber: order_by

  """
  The unique identifier for the NFT within its associated smart contract. Maintains a constant reference to the NFT across platforms.
  """
  tokenId: order_by
}

"""aggregate stddev_pop on columns"""
type nftTransfer_stddev_pop_fields {
  """
  The specific block on the blockchain where this transfer was recorded. Allows for pinpointing the exact point of transfer in the blockchain's history.
  """
  blockNumber: Float

  """
  The unique identifier for the NFT within its associated smart contract. Maintains a constant reference to the NFT across platforms.
  """
  tokenId: Float
}

"""
order by stddev_pop() on columns of table "nftTransfer"
"""
input nftTransfer_stddev_pop_order_by {
  """
  The specific block on the blockchain where this transfer was recorded. Allows for pinpointing the exact point of transfer in the blockchain's history.
  """
  blockNumber: order_by

  """
  The unique identifier for the NFT within its associated smart contract. Maintains a constant reference to the NFT across platforms.
  """
  tokenId: order_by
}

"""aggregate stddev_samp on columns"""
type nftTransfer_stddev_samp_fields {
  """
  The specific block on the blockchain where this transfer was recorded. Allows for pinpointing the exact point of transfer in the blockchain's history.
  """
  blockNumber: Float

  """
  The unique identifier for the NFT within its associated smart contract. Maintains a constant reference to the NFT across platforms.
  """
  tokenId: Float
}

"""
order by stddev_samp() on columns of table "nftTransfer"
"""
input nftTransfer_stddev_samp_order_by {
  """
  The specific block on the blockchain where this transfer was recorded. Allows for pinpointing the exact point of transfer in the blockchain's history.
  """
  blockNumber: order_by

  """
  The unique identifier for the NFT within its associated smart contract. Maintains a constant reference to the NFT across platforms.
  """
  tokenId: order_by
}

"""
Streaming cursor of the table "nftTransfer"
"""
input nftTransfer_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: nftTransfer_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input nftTransfer_stream_cursor_value_input {
  """
  The specific block on the blockchain where this transfer was recorded. Allows for pinpointing the exact point of transfer in the blockchain's history.
  """
  blockNumber: bigint

  """
  Indicates the specific blockchain or network where the NFT resides. Useful in a multi-chain environment to distinguish between various chains.
  """
  chainId: String

  """
  Identifies the smart contract associated with the NFT. This provides a direct link to the NFT's origin and behavior on the blockchain.
  """
  contractAddress: String
  created_at: timestamptz

  """
  Refers to the associated event ID for which the NFT was transferred. Ties the NFT transfer to a particular event in the platform.
  """
  eventId: String

  """
  Denotes the specific Event Pass associated with the NFT. Helps in tracking the lifecycle of a particular event pass.
  """
  eventPassId: String

  """
  Denotes the source address from which the NFT was transferred. Essential to trace the sender in the NFT's movement.
  """
  fromAddress: String
  id: uuid

  """
  Identifies the organizer who facilitated the event linked to the NFT transfer. Aids in associating NFT movements with specific organizers.
  """
  organizerId: String

  """
  Specifies the destination address receiving the NFT. Critical for determining the current holder of the NFT.
  """
  toAddress: String

  """
  The unique identifier for the NFT within its associated smart contract. Maintains a constant reference to the NFT across platforms.
  """
  tokenId: bigint

  """
  Represents the unique hash of the transaction in which the NFT was transferred. Ensures traceability and verification on the blockchain.
  """
  transactionHash: String
}

"""aggregate sum on columns"""
type nftTransfer_sum_fields {
  """
  The specific block on the blockchain where this transfer was recorded. Allows for pinpointing the exact point of transfer in the blockchain's history.
  """
  blockNumber: bigint

  """
  The unique identifier for the NFT within its associated smart contract. Maintains a constant reference to the NFT across platforms.
  """
  tokenId: bigint
}

"""
order by sum() on columns of table "nftTransfer"
"""
input nftTransfer_sum_order_by {
  """
  The specific block on the blockchain where this transfer was recorded. Allows for pinpointing the exact point of transfer in the blockchain's history.
  """
  blockNumber: order_by

  """
  The unique identifier for the NFT within its associated smart contract. Maintains a constant reference to the NFT across platforms.
  """
  tokenId: order_by
}

"""
update columns of table "nftTransfer"
"""
enum nftTransfer_update_column {
  """column name"""
  blockNumber

  """column name"""
  chainId

  """column name"""
  contractAddress

  """column name"""
  created_at

  """column name"""
  eventId

  """column name"""
  eventPassId

  """column name"""
  fromAddress

  """column name"""
  id

  """column name"""
  organizerId

  """column name"""
  toAddress

  """column name"""
  tokenId

  """column name"""
  transactionHash
}

input nftTransfer_updates {
  """increments the numeric columns with given value of the filtered values"""
  _inc: nftTransfer_inc_input

  """sets the columns of the filtered rows to the given values"""
  _set: nftTransfer_set_input

  """filter the rows which have to be updated"""
  where: nftTransfer_bool_exp!
}

"""aggregate var_pop on columns"""
type nftTransfer_var_pop_fields {
  """
  The specific block on the blockchain where this transfer was recorded. Allows for pinpointing the exact point of transfer in the blockchain's history.
  """
  blockNumber: Float

  """
  The unique identifier for the NFT within its associated smart contract. Maintains a constant reference to the NFT across platforms.
  """
  tokenId: Float
}

"""
order by var_pop() on columns of table "nftTransfer"
"""
input nftTransfer_var_pop_order_by {
  """
  The specific block on the blockchain where this transfer was recorded. Allows for pinpointing the exact point of transfer in the blockchain's history.
  """
  blockNumber: order_by

  """
  The unique identifier for the NFT within its associated smart contract. Maintains a constant reference to the NFT across platforms.
  """
  tokenId: order_by
}

"""aggregate var_samp on columns"""
type nftTransfer_var_samp_fields {
  """
  The specific block on the blockchain where this transfer was recorded. Allows for pinpointing the exact point of transfer in the blockchain's history.
  """
  blockNumber: Float

  """
  The unique identifier for the NFT within its associated smart contract. Maintains a constant reference to the NFT across platforms.
  """
  tokenId: Float
}

"""
order by var_samp() on columns of table "nftTransfer"
"""
input nftTransfer_var_samp_order_by {
  """
  The specific block on the blockchain where this transfer was recorded. Allows for pinpointing the exact point of transfer in the blockchain's history.
  """
  blockNumber: order_by

  """
  The unique identifier for the NFT within its associated smart contract. Maintains a constant reference to the NFT across platforms.
  """
  tokenId: order_by
}

"""aggregate variance on columns"""
type nftTransfer_variance_fields {
  """
  The specific block on the blockchain where this transfer was recorded. Allows for pinpointing the exact point of transfer in the blockchain's history.
  """
  blockNumber: Float

  """
  The unique identifier for the NFT within its associated smart contract. Maintains a constant reference to the NFT across platforms.
  """
  tokenId: Float
}

"""
order by variance() on columns of table "nftTransfer"
"""
input nftTransfer_variance_order_by {
  """
  The specific block on the blockchain where this transfer was recorded. Allows for pinpointing the exact point of transfer in the blockchain's history.
  """
  blockNumber: order_by

  """
  The unique identifier for the NFT within its associated smart contract. Maintains a constant reference to the NFT across platforms.
  """
  tokenId: order_by
}

scalar oid

"""
Boolean expression to compare columns of type "oid". All fields are combined with logical 'AND'.
"""
input oid_comparison_exp {
  _eq: oid
  _gt: oid
  _gte: oid
  _in: [oid!]
  _is_null: Boolean
  _lt: oid
  _lte: oid
  _neq: oid
  _nin: [oid!]
}

"""
columns and relationships of "orderStatus"
"""
type orderStatus {
  value: String!
}

"""
aggregated selection of "orderStatus"
"""
type orderStatus_aggregate {
  aggregate: orderStatus_aggregate_fields
  nodes: [orderStatus!]!
}

"""
aggregate fields of "orderStatus"
"""
type orderStatus_aggregate_fields {
  count(columns: [orderStatus_select_column!], distinct: Boolean): Int!
  max: orderStatus_max_fields
  min: orderStatus_min_fields
}

"""
Boolean expression to filter rows from the table "orderStatus". All fields are combined with a logical 'AND'.
"""
input orderStatus_bool_exp {
  _and: [orderStatus_bool_exp!]
  _not: orderStatus_bool_exp
  _or: [orderStatus_bool_exp!]
  value: String_comparison_exp
}

"""
unique or primary key constraints on table "orderStatus"
"""
enum orderStatus_constraint {
  """
  unique or primary key constraint on columns "value"
  """
  orderStatus_pkey
}

enum orderStatus_enum {
  CANCELLED
  COMPLETED
  CONFIRMED
  ERROR
  IS_MINTING
  REFUNDED
  UNAUTHORIZED
}

"""
Boolean expression to compare columns of type "orderStatus_enum". All fields are combined with logical 'AND'.
"""
input orderStatus_enum_comparison_exp {
  _eq: orderStatus_enum
  _in: [orderStatus_enum!]
  _is_null: Boolean
  _neq: orderStatus_enum
  _nin: [orderStatus_enum!]
}

"""
input type for inserting data into table "orderStatus"
"""
input orderStatus_insert_input {
  value: String
}

"""aggregate max on columns"""
type orderStatus_max_fields {
  value: String
}

"""aggregate min on columns"""
type orderStatus_min_fields {
  value: String
}

"""
response of any mutation on the table "orderStatus"
"""
type orderStatus_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [orderStatus!]!
}

"""
on_conflict condition type for table "orderStatus"
"""
input orderStatus_on_conflict {
  constraint: orderStatus_constraint!
  update_columns: [orderStatus_update_column!]! = []
  where: orderStatus_bool_exp
}

"""Ordering options when selecting data from "orderStatus"."""
input orderStatus_order_by {
  value: order_by
}

"""primary key columns input for table: orderStatus"""
input orderStatus_pk_columns_input {
  value: String!
}

"""
select columns of table "orderStatus"
"""
enum orderStatus_select_column {
  """column name"""
  value
}

"""
input type for updating data in table "orderStatus"
"""
input orderStatus_set_input {
  value: String
}

"""
Streaming cursor of the table "orderStatus"
"""
input orderStatus_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: orderStatus_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input orderStatus_stream_cursor_value_input {
  value: String
}

"""
update columns of table "orderStatus"
"""
enum orderStatus_update_column {
  """column name"""
  value
}

input orderStatus_updates {
  """sets the columns of the filtered rows to the given values"""
  _set: orderStatus_set_input

  """filter the rows which have to be updated"""
  where: orderStatus_bool_exp!
}

"""column ordering options"""
enum order_by {
  """in ascending order, nulls last"""
  asc

  """in ascending order, nulls first"""
  asc_nulls_first

  """in ascending order, nulls last"""
  asc_nulls_last

  """in descending order, nulls first"""
  desc

  """in descending order, nulls first"""
  desc_nulls_first

  """in descending order, nulls last"""
  desc_nulls_last
}

"""packNftContract model to manage the NFTs associated with each pack."""
type packNftContract {
  chainId: String!
  contractAddress: String!
  created_at: timestamptz!
  eventId: String!
  eventPassIds(
    """JSON select path"""
    path: String
  ): jsonb!

  """An array relationship"""
  eventPassNfts(
    """distinct select on columns"""
    distinct_on: [eventPassNft_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [eventPassNft_order_by!]

    """filter the rows returned"""
    where: eventPassNft_bool_exp
  ): [eventPassNft!]!

  """An aggregate relationship"""
  eventPassNfts_aggregate(
    """distinct select on columns"""
    distinct_on: [eventPassNft_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [eventPassNft_order_by!]

    """filter the rows returned"""
    where: eventPassNft_bool_exp
  ): eventPassNft_aggregate!
  id: uuid!
  organizerId: String!
  packId: String!
  rewardsPerPack: Int!
  updated_at: timestamptz!
}

"""
aggregated selection of "packNftContract"
"""
type packNftContract_aggregate {
  aggregate: packNftContract_aggregate_fields
  nodes: [packNftContract!]!
}

"""
aggregate fields of "packNftContract"
"""
type packNftContract_aggregate_fields {
  avg: packNftContract_avg_fields
  count(columns: [packNftContract_select_column!], distinct: Boolean): Int!
  max: packNftContract_max_fields
  min: packNftContract_min_fields
  stddev: packNftContract_stddev_fields
  stddev_pop: packNftContract_stddev_pop_fields
  stddev_samp: packNftContract_stddev_samp_fields
  sum: packNftContract_sum_fields
  var_pop: packNftContract_var_pop_fields
  var_samp: packNftContract_var_samp_fields
  variance: packNftContract_variance_fields
}

"""append existing jsonb value of filtered columns with new jsonb value"""
input packNftContract_append_input {
  eventPassIds: jsonb
}

"""aggregate avg on columns"""
type packNftContract_avg_fields {
  rewardsPerPack: Float
}

"""
Boolean expression to filter rows from the table "packNftContract". All fields are combined with a logical 'AND'.
"""
input packNftContract_bool_exp {
  _and: [packNftContract_bool_exp!]
  _not: packNftContract_bool_exp
  _or: [packNftContract_bool_exp!]
  chainId: String_comparison_exp
  contractAddress: String_comparison_exp
  created_at: timestamptz_comparison_exp
  eventId: String_comparison_exp
  eventPassIds: jsonb_comparison_exp
  eventPassNfts: eventPassNft_bool_exp
  eventPassNfts_aggregate: eventPassNft_aggregate_bool_exp
  id: uuid_comparison_exp
  organizerId: String_comparison_exp
  packId: String_comparison_exp
  rewardsPerPack: Int_comparison_exp
  updated_at: timestamptz_comparison_exp
}

"""
unique or primary key constraints on table "packNftContract"
"""
enum packNftContract_constraint {
  """
  unique or primary key constraint on columns "chainId", "contractAddress"
  """
  packNftContract_contractAddress_chainId_key

  """
  unique or primary key constraint on columns "id"
  """
  packNftContract_pkey
}

"""
delete the field or element with specified path (for JSON arrays, negative integers count from the end)
"""
input packNftContract_delete_at_path_input {
  eventPassIds: [String!]
}

"""
delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
"""
input packNftContract_delete_elem_input {
  eventPassIds: Int
}

"""
delete key/value pair or string element. key/value pairs are matched based on their key value
"""
input packNftContract_delete_key_input {
  eventPassIds: String
}

"""
input type for incrementing numeric columns in table "packNftContract"
"""
input packNftContract_inc_input {
  rewardsPerPack: Int
}

"""
input type for inserting data into table "packNftContract"
"""
input packNftContract_insert_input {
  chainId: String
  contractAddress: String
  created_at: timestamptz
  eventId: String
  eventPassIds: jsonb
  eventPassNfts: eventPassNft_arr_rel_insert_input
  id: uuid
  organizerId: String
  packId: String
  rewardsPerPack: Int
  updated_at: timestamptz
}

"""aggregate max on columns"""
type packNftContract_max_fields {
  chainId: String
  contractAddress: String
  created_at: timestamptz
  eventId: String
  id: uuid
  organizerId: String
  packId: String
  rewardsPerPack: Int
  updated_at: timestamptz
}

"""aggregate min on columns"""
type packNftContract_min_fields {
  chainId: String
  contractAddress: String
  created_at: timestamptz
  eventId: String
  id: uuid
  organizerId: String
  packId: String
  rewardsPerPack: Int
  updated_at: timestamptz
}

"""
response of any mutation on the table "packNftContract"
"""
type packNftContract_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [packNftContract!]!
}

"""
input type for inserting object relation for remote table "packNftContract"
"""
input packNftContract_obj_rel_insert_input {
  data: packNftContract_insert_input!

  """upsert condition"""
  on_conflict: packNftContract_on_conflict
}

"""
on_conflict condition type for table "packNftContract"
"""
input packNftContract_on_conflict {
  constraint: packNftContract_constraint!
  update_columns: [packNftContract_update_column!]! = []
  where: packNftContract_bool_exp
}

"""Ordering options when selecting data from "packNftContract"."""
input packNftContract_order_by {
  chainId: order_by
  contractAddress: order_by
  created_at: order_by
  eventId: order_by
  eventPassIds: order_by
  eventPassNfts_aggregate: eventPassNft_aggregate_order_by
  id: order_by
  organizerId: order_by
  packId: order_by
  rewardsPerPack: order_by
  updated_at: order_by
}

"""primary key columns input for table: packNftContract"""
input packNftContract_pk_columns_input {
  id: uuid!
}

"""prepend existing jsonb value of filtered columns with new jsonb value"""
input packNftContract_prepend_input {
  eventPassIds: jsonb
}

"""
select columns of table "packNftContract"
"""
enum packNftContract_select_column {
  """column name"""
  chainId

  """column name"""
  contractAddress

  """column name"""
  created_at

  """column name"""
  eventId

  """column name"""
  eventPassIds

  """column name"""
  id

  """column name"""
  organizerId

  """column name"""
  packId

  """column name"""
  rewardsPerPack

  """column name"""
  updated_at
}

"""
input type for updating data in table "packNftContract"
"""
input packNftContract_set_input {
  chainId: String
  contractAddress: String
  created_at: timestamptz
  eventId: String
  eventPassIds: jsonb
  id: uuid
  organizerId: String
  packId: String
  rewardsPerPack: Int
  updated_at: timestamptz
}

"""aggregate stddev on columns"""
type packNftContract_stddev_fields {
  rewardsPerPack: Float
}

"""aggregate stddev_pop on columns"""
type packNftContract_stddev_pop_fields {
  rewardsPerPack: Float
}

"""aggregate stddev_samp on columns"""
type packNftContract_stddev_samp_fields {
  rewardsPerPack: Float
}

"""
Streaming cursor of the table "packNftContract"
"""
input packNftContract_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: packNftContract_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input packNftContract_stream_cursor_value_input {
  chainId: String
  contractAddress: String
  created_at: timestamptz
  eventId: String
  eventPassIds: jsonb
  id: uuid
  organizerId: String
  packId: String
  rewardsPerPack: Int
  updated_at: timestamptz
}

"""aggregate sum on columns"""
type packNftContract_sum_fields {
  rewardsPerPack: Int
}

"""
update columns of table "packNftContract"
"""
enum packNftContract_update_column {
  """column name"""
  chainId

  """column name"""
  contractAddress

  """column name"""
  created_at

  """column name"""
  eventId

  """column name"""
  eventPassIds

  """column name"""
  id

  """column name"""
  organizerId

  """column name"""
  packId

  """column name"""
  rewardsPerPack

  """column name"""
  updated_at
}

input packNftContract_updates {
  """append existing jsonb value of filtered columns with new jsonb value"""
  _append: packNftContract_append_input

  """
  delete the field or element with specified path (for JSON arrays, negative integers count from the end)
  """
  _delete_at_path: packNftContract_delete_at_path_input

  """
  delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
  """
  _delete_elem: packNftContract_delete_elem_input

  """
  delete key/value pair or string element. key/value pairs are matched based on their key value
  """
  _delete_key: packNftContract_delete_key_input

  """increments the numeric columns with given value of the filtered values"""
  _inc: packNftContract_inc_input

  """prepend existing jsonb value of filtered columns with new jsonb value"""
  _prepend: packNftContract_prepend_input

  """sets the columns of the filtered rows to the given values"""
  _set: packNftContract_set_input

  """filter the rows which have to be updated"""
  where: packNftContract_bool_exp!
}

"""aggregate var_pop on columns"""
type packNftContract_var_pop_fields {
  rewardsPerPack: Float
}

"""aggregate var_samp on columns"""
type packNftContract_var_samp_fields {
  rewardsPerPack: Float
}

"""aggregate variance on columns"""
type packNftContract_variance_fields {
  rewardsPerPack: Float
}

type query_root {
  """
  fetch data from the table: "account"
  """
  account(
    """distinct select on columns"""
    distinct_on: [account_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [account_order_by!]

    """filter the rows returned"""
    where: account_bool_exp
  ): [account!]!

  """
  fetch aggregated fields from the table: "account"
  """
  account_aggregate(
    """distinct select on columns"""
    distinct_on: [account_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [account_order_by!]

    """filter the rows returned"""
    where: account_bool_exp
  ): account_aggregate!

  """fetch data from the table: "account" using primary key columns"""
  account_by_pk(id: uuid!): account

  """Retrieve a single asset"""
  asset(
    """
    Defines which locales should be returned.
    
    Note that `Asset` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, entries with non matching locales will be filtered out.
    
    This argument may be overwritten by another locales definition in a relational child field, this will effectively use the overwritten argument for the affected query's subtree.
    """
    locales: [Locale!]! = [en]
    stage: Stage! = PUBLISHED
    where: AssetWhereUniqueInput!
  ): Asset

  """Retrieve document version"""
  assetVersion(where: VersionWhereInput!): DocumentVersion

  """Retrieve multiple assets"""
  assets(
    after: String
    before: String
    first: Int
    last: Int

    """
    Defines which locales should be returned.
    
    Note that `Asset` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, entries with non matching locales will be filtered out.
    
    This argument may be overwritten by another locales definition in a relational child field, this will effectively use the overwritten argument for the affected query's subtree.
    """
    locales: [Locale!]! = [en]
    orderBy: AssetOrderByInput
    skip: Int
    stage: Stage! = PUBLISHED
    where: AssetWhereInput
  ): [Asset!]!

  """Retrieve multiple assets using the Relay connection interface"""
  assetsConnection(
    after: String
    before: String
    first: Int
    last: Int

    """
    Defines which locales should be returned.
    
    Note that `Asset` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, entries with non matching locales will be filtered out.
    
    This argument may be overwritten by another locales definition in a relational child field, this will effectively use the overwritten argument for the affected query's subtree.
    """
    locales: [Locale!]! = [en]
    orderBy: AssetOrderByInput
    skip: Int
    stage: Stage! = PUBLISHED
    where: AssetWhereInput
  ): AssetConnection!

  """
  fetch data from the table: "audit.logged_actions"
  """
  audit_logged_actions(
    """distinct select on columns"""
    distinct_on: [audit_logged_actions_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [audit_logged_actions_order_by!]

    """filter the rows returned"""
    where: audit_logged_actions_bool_exp
  ): [audit_logged_actions!]!

  """
  fetch aggregated fields from the table: "audit.logged_actions"
  """
  audit_logged_actions_aggregate(
    """distinct select on columns"""
    distinct_on: [audit_logged_actions_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [audit_logged_actions_order_by!]

    """filter the rows returned"""
    where: audit_logged_actions_bool_exp
  ): audit_logged_actions_aggregate!

  """
  fetch data from the table: "audit.logged_actions" using primary key columns
  """
  audit_logged_actions_by_pk(
    """Unique identifier for each auditable event"""
    event_id: bigint!
  ): audit_logged_actions

  """
  fetch data from the table: "currency"
  """
  currency(
    """distinct select on columns"""
    distinct_on: [currency_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [currency_order_by!]

    """filter the rows returned"""
    where: currency_bool_exp
  ): [currency!]!

  """
  fetch aggregated fields from the table: "currency"
  """
  currency_aggregate(
    """distinct select on columns"""
    distinct_on: [currency_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [currency_order_by!]

    """filter the rows returned"""
    where: currency_bool_exp
  ): currency_aggregate!

  """fetch data from the table: "currency" using primary key columns"""
  currency_by_pk(value: String!): currency

  """Fetches an object given its ID"""
  entities(
    """The where parameters to query components"""
    where: [EntityWhereInput!]!
  ): [Entity!]

  """Retrieve a single event"""
  event(
    """
    Defines which locales should be returned.
    
    Note that `Event` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, entries with non matching locales will be filtered out.
    
    This argument may be overwritten by another locales definition in a relational child field, this will effectively use the overwritten argument for the affected query's subtree.
    """
    locales: [Locale!]! = [en]
    stage: Stage! = PUBLISHED
    where: EventWhereUniqueInput!
  ): Event

  """
  fetch data from the table: "eventParameters"
  """
  eventParameters(
    """distinct select on columns"""
    distinct_on: [eventParameters_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [eventParameters_order_by!]

    """filter the rows returned"""
    where: eventParameters_bool_exp
  ): [eventParameters!]!

  """
  fetch aggregated fields from the table: "eventParameters"
  """
  eventParameters_aggregate(
    """distinct select on columns"""
    distinct_on: [eventParameters_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [eventParameters_order_by!]

    """filter the rows returned"""
    where: eventParameters_bool_exp
  ): eventParameters_aggregate!

  """fetch data from the table: "eventParameters" using primary key columns"""
  eventParameters_by_pk(id: uuid!): eventParameters

  """Retrieve a single eventPass"""
  eventPass(
    """
    Defines which locales should be returned.
    
    Note that `EventPass` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, entries with non matching locales will be filtered out.
    
    This argument may be overwritten by another locales definition in a relational child field, this will effectively use the overwritten argument for the affected query's subtree.
    """
    locales: [Locale!]! = [en]
    stage: Stage! = PUBLISHED
    where: EventPassWhereUniqueInput!
  ): EventPass

  """Retrieve a single eventPassDelayedRevealed"""
  eventPassDelayedRevealed(
    """
    Defines which locales should be returned.
    
    Note that `EventPassDelayedRevealed` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, entries with non matching locales will be filtered out.
    
    This argument may be overwritten by another locales definition in a relational child field, this will effectively use the overwritten argument for the affected query's subtree.
    """
    locales: [Locale!]! = [en]
    stage: Stage! = PUBLISHED
    where: EventPassDelayedRevealedWhereUniqueInput!
  ): EventPassDelayedRevealed

  """Retrieve document version"""
  eventPassDelayedRevealedVersion(where: VersionWhereInput!): DocumentVersion

  """
  fetch data from the table: "eventPassNft"
  """
  eventPassNft(
    """distinct select on columns"""
    distinct_on: [eventPassNft_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [eventPassNft_order_by!]

    """filter the rows returned"""
    where: eventPassNft_bool_exp
  ): [eventPassNft!]!

  """
  fetch data from the table: "eventPassNftContract"
  """
  eventPassNftContract(
    """distinct select on columns"""
    distinct_on: [eventPassNftContract_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [eventPassNftContract_order_by!]

    """filter the rows returned"""
    where: eventPassNftContract_bool_exp
  ): [eventPassNftContract!]!

  """
  fetch data from the table: "eventPassNftContractType"
  """
  eventPassNftContractType(
    """distinct select on columns"""
    distinct_on: [eventPassNftContractType_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [eventPassNftContractType_order_by!]

    """filter the rows returned"""
    where: eventPassNftContractType_bool_exp
  ): [eventPassNftContractType!]!

  """
  fetch aggregated fields from the table: "eventPassNftContractType"
  """
  eventPassNftContractType_aggregate(
    """distinct select on columns"""
    distinct_on: [eventPassNftContractType_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [eventPassNftContractType_order_by!]

    """filter the rows returned"""
    where: eventPassNftContractType_bool_exp
  ): eventPassNftContractType_aggregate!

  """
  fetch data from the table: "eventPassNftContractType" using primary key columns
  """
  eventPassNftContractType_by_pk(
    """Type name for event pass NFT contract."""
    value: String!
  ): eventPassNftContractType

  """
  fetch aggregated fields from the table: "eventPassNftContract"
  """
  eventPassNftContract_aggregate(
    """distinct select on columns"""
    distinct_on: [eventPassNftContract_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [eventPassNftContract_order_by!]

    """filter the rows returned"""
    where: eventPassNftContract_bool_exp
  ): eventPassNftContract_aggregate!

  """
  fetch aggregated fields from the table: "eventPassNft"
  """
  eventPassNft_aggregate(
    """distinct select on columns"""
    distinct_on: [eventPassNft_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [eventPassNft_order_by!]

    """filter the rows returned"""
    where: eventPassNft_bool_exp
  ): eventPassNft_aggregate!

  """fetch data from the table: "eventPassNft" using primary key columns"""
  eventPassNft_by_pk(id: uuid!): eventPassNft

  """
  fetch data from the table: "eventPassOrder"
  """
  eventPassOrder(
    """distinct select on columns"""
    distinct_on: [eventPassOrder_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [eventPassOrder_order_by!]

    """filter the rows returned"""
    where: eventPassOrder_bool_exp
  ): [eventPassOrder!]!

  """
  fetch data from the table: "eventPassOrderSums"
  """
  eventPassOrderSums(
    """distinct select on columns"""
    distinct_on: [eventPassOrderSums_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [eventPassOrderSums_order_by!]

    """filter the rows returned"""
    where: eventPassOrderSums_bool_exp
  ): [eventPassOrderSums!]!

  """
  fetch aggregated fields from the table: "eventPassOrderSums"
  """
  eventPassOrderSums_aggregate(
    """distinct select on columns"""
    distinct_on: [eventPassOrderSums_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [eventPassOrderSums_order_by!]

    """filter the rows returned"""
    where: eventPassOrderSums_bool_exp
  ): eventPassOrderSums_aggregate!

  """
  fetch data from the table: "eventPassOrderSums" using primary key columns
  """
  eventPassOrderSums_by_pk(eventPassId: String!): eventPassOrderSums

  """
  fetch aggregated fields from the table: "eventPassOrder"
  """
  eventPassOrder_aggregate(
    """distinct select on columns"""
    distinct_on: [eventPassOrder_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [eventPassOrder_order_by!]

    """filter the rows returned"""
    where: eventPassOrder_bool_exp
  ): eventPassOrder_aggregate!

  """fetch data from the table: "eventPassOrder" using primary key columns"""
  eventPassOrder_by_pk(id: uuid!): eventPassOrder

  """
  fetch data from the table: "eventPassPendingOrder"
  """
  eventPassPendingOrder(
    """distinct select on columns"""
    distinct_on: [eventPassPendingOrder_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [eventPassPendingOrder_order_by!]

    """filter the rows returned"""
    where: eventPassPendingOrder_bool_exp
  ): [eventPassPendingOrder!]!

  """
  fetch aggregated fields from the table: "eventPassPendingOrder"
  """
  eventPassPendingOrder_aggregate(
    """distinct select on columns"""
    distinct_on: [eventPassPendingOrder_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [eventPassPendingOrder_order_by!]

    """filter the rows returned"""
    where: eventPassPendingOrder_bool_exp
  ): eventPassPendingOrder_aggregate!

  """
  fetch data from the table: "eventPassPendingOrder" using primary key columns
  """
  eventPassPendingOrder_by_pk(id: uuid!): eventPassPendingOrder

  """
  fetch data from the table: "eventPassPricing"
  """
  eventPassPricing(
    """distinct select on columns"""
    distinct_on: [eventPassPricing_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [eventPassPricing_order_by!]

    """filter the rows returned"""
    where: eventPassPricing_bool_exp
  ): [eventPassPricing!]!

  """
  fetch aggregated fields from the table: "eventPassPricing"
  """
  eventPassPricing_aggregate(
    """distinct select on columns"""
    distinct_on: [eventPassPricing_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [eventPassPricing_order_by!]

    """filter the rows returned"""
    where: eventPassPricing_bool_exp
  ): eventPassPricing_aggregate!

  """
  fetch data from the table: "eventPassPricing" using primary key columns
  """
  eventPassPricing_by_pk(id: uuid!): eventPassPricing

  """Retrieve document version"""
  eventPassVersion(where: VersionWhereInput!): DocumentVersion

  """Retrieve multiple eventPasses"""
  eventPasses(
    after: String
    before: String
    first: Int
    last: Int

    """
    Defines which locales should be returned.
    
    Note that `EventPass` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, entries with non matching locales will be filtered out.
    
    This argument may be overwritten by another locales definition in a relational child field, this will effectively use the overwritten argument for the affected query's subtree.
    """
    locales: [Locale!]! = [en]
    orderBy: EventPassOrderByInput
    skip: Int
    stage: Stage! = PUBLISHED
    where: EventPassWhereInput
  ): [EventPass!]!

  """Retrieve multiple eventPasses using the Relay connection interface"""
  eventPassesConnection(
    after: String
    before: String
    first: Int
    last: Int

    """
    Defines which locales should be returned.
    
    Note that `EventPass` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, entries with non matching locales will be filtered out.
    
    This argument may be overwritten by another locales definition in a relational child field, this will effectively use the overwritten argument for the affected query's subtree.
    """
    locales: [Locale!]! = [en]
    orderBy: EventPassOrderByInput
    skip: Int
    stage: Stage! = PUBLISHED
    where: EventPassWhereInput
  ): EventPassConnection!

  """Retrieve multiple eventPassesDelayedRevealed"""
  eventPassesDelayedRevealed(
    after: String
    before: String
    first: Int
    last: Int

    """
    Defines which locales should be returned.
    
    Note that `EventPassDelayedRevealed` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, entries with non matching locales will be filtered out.
    
    This argument may be overwritten by another locales definition in a relational child field, this will effectively use the overwritten argument for the affected query's subtree.
    """
    locales: [Locale!]! = [en]
    orderBy: EventPassDelayedRevealedOrderByInput
    skip: Int
    stage: Stage! = PUBLISHED
    where: EventPassDelayedRevealedWhereInput
  ): [EventPassDelayedRevealed!]!

  """
  Retrieve multiple eventPassesDelayedRevealed using the Relay connection interface
  """
  eventPassesDelayedRevealedConnection(
    after: String
    before: String
    first: Int
    last: Int

    """
    Defines which locales should be returned.
    
    Note that `EventPassDelayedRevealed` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, entries with non matching locales will be filtered out.
    
    This argument may be overwritten by another locales definition in a relational child field, this will effectively use the overwritten argument for the affected query's subtree.
    """
    locales: [Locale!]! = [en]
    orderBy: EventPassDelayedRevealedOrderByInput
    skip: Int
    stage: Stage! = PUBLISHED
    where: EventPassDelayedRevealedWhereInput
  ): EventPassDelayedRevealedConnection!

  """Retrieve document version"""
  eventVersion(where: VersionWhereInput!): DocumentVersion

  """Retrieve multiple events"""
  events(
    after: String
    before: String
    first: Int
    last: Int

    """
    Defines which locales should be returned.
    
    Note that `Event` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, entries with non matching locales will be filtered out.
    
    This argument may be overwritten by another locales definition in a relational child field, this will effectively use the overwritten argument for the affected query's subtree.
    """
    locales: [Locale!]! = [en]
    orderBy: EventOrderByInput
    skip: Int
    stage: Stage! = PUBLISHED
    where: EventWhereInput
  ): [Event!]!

  """Retrieve multiple events using the Relay connection interface"""
  eventsConnection(
    after: String
    before: String
    first: Int
    last: Int

    """
    Defines which locales should be returned.
    
    Note that `Event` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, entries with non matching locales will be filtered out.
    
    This argument may be overwritten by another locales definition in a relational child field, this will effectively use the overwritten argument for the affected query's subtree.
    """
    locales: [Locale!]! = [en]
    orderBy: EventOrderByInput
    skip: Int
    stage: Stage! = PUBLISHED
    where: EventWhereInput
  ): EventConnection!

  """
  fetch data from the table: "follow"
  """
  follow(
    """distinct select on columns"""
    distinct_on: [follow_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [follow_order_by!]

    """filter the rows returned"""
    where: follow_bool_exp
  ): [follow!]!

  """
  fetch aggregated fields from the table: "follow"
  """
  follow_aggregate(
    """distinct select on columns"""
    distinct_on: [follow_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [follow_order_by!]

    """filter the rows returned"""
    where: follow_bool_exp
  ): follow_aggregate!

  """fetch data from the table: "follow" using primary key columns"""
  follow_by_pk(
    """
    References the unique identifier of the account that is following an organizer.
    """
    accountId: uuid!

    """
    Represents the unique slug of the organizer being followed. Slugs are user-friendly identifiers that uniquely identify organizers.
    """
    organizerSlug: String!
  ): follow

  """
  fetch data from the table: "kyc"
  """
  kyc(
    """distinct select on columns"""
    distinct_on: [kyc_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [kyc_order_by!]

    """filter the rows returned"""
    where: kyc_bool_exp
  ): [kyc!]!

  """
  fetch data from the table: "kycLevelName"
  """
  kycLevelName(
    """distinct select on columns"""
    distinct_on: [kycLevelName_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [kycLevelName_order_by!]

    """filter the rows returned"""
    where: kycLevelName_bool_exp
  ): [kycLevelName!]!

  """
  fetch aggregated fields from the table: "kycLevelName"
  """
  kycLevelName_aggregate(
    """distinct select on columns"""
    distinct_on: [kycLevelName_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [kycLevelName_order_by!]

    """filter the rows returned"""
    where: kycLevelName_bool_exp
  ): kycLevelName_aggregate!

  """fetch data from the table: "kycLevelName" using primary key columns"""
  kycLevelName_by_pk(
    """Level name for KYC verification."""
    value: String!
  ): kycLevelName

  """
  fetch data from the table: "kycStatus"
  """
  kycStatus(
    """distinct select on columns"""
    distinct_on: [kycStatus_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [kycStatus_order_by!]

    """filter the rows returned"""
    where: kycStatus_bool_exp
  ): [kycStatus!]!

  """
  fetch aggregated fields from the table: "kycStatus"
  """
  kycStatus_aggregate(
    """distinct select on columns"""
    distinct_on: [kycStatus_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [kycStatus_order_by!]

    """filter the rows returned"""
    where: kycStatus_bool_exp
  ): kycStatus_aggregate!

  """fetch data from the table: "kycStatus" using primary key columns"""
  kycStatus_by_pk(
    """Status value."""
    value: String!
  ): kycStatus

  """
  fetch aggregated fields from the table: "kyc"
  """
  kyc_aggregate(
    """distinct select on columns"""
    distinct_on: [kyc_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [kyc_order_by!]

    """filter the rows returned"""
    where: kyc_bool_exp
  ): kyc_aggregate!

  """fetch data from the table: "kyc" using primary key columns"""
  kyc_by_pk(
    """UUID referencing to the user ID in the existing accounts table."""
    externalUserId: uuid!
  ): kyc

  """
  fetch data from the table: "nftTransfer"
  """
  nftTransfer(
    """distinct select on columns"""
    distinct_on: [nftTransfer_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [nftTransfer_order_by!]

    """filter the rows returned"""
    where: nftTransfer_bool_exp
  ): [nftTransfer!]!

  """
  fetch aggregated fields from the table: "nftTransfer"
  """
  nftTransfer_aggregate(
    """distinct select on columns"""
    distinct_on: [nftTransfer_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [nftTransfer_order_by!]

    """filter the rows returned"""
    where: nftTransfer_bool_exp
  ): nftTransfer_aggregate!

  """fetch data from the table: "nftTransfer" using primary key columns"""
  nftTransfer_by_pk(id: uuid!): nftTransfer

  """Fetches an object given its ID"""
  node(
    """The ID of an object"""
    id: ID!

    """
    Defines which locales should be returned.
    
    Note that `Node` is a model without localized fields and will not be affected directly by this argument, however the locales will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument may be overwritten by another locales definition in a relational child field, this will effectively use the overwritten argument for the affected query's subtree.
    """
    locales: [Locale!]! = [en]
    stage: Stage! = PUBLISHED
  ): Node

  """
  fetch data from the table: "orderStatus"
  """
  orderStatus(
    """distinct select on columns"""
    distinct_on: [orderStatus_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [orderStatus_order_by!]

    """filter the rows returned"""
    where: orderStatus_bool_exp
  ): [orderStatus!]!

  """
  fetch aggregated fields from the table: "orderStatus"
  """
  orderStatus_aggregate(
    """distinct select on columns"""
    distinct_on: [orderStatus_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [orderStatus_order_by!]

    """filter the rows returned"""
    where: orderStatus_bool_exp
  ): orderStatus_aggregate!

  """fetch data from the table: "orderStatus" using primary key columns"""
  orderStatus_by_pk(value: String!): orderStatus

  """Retrieve a single organizer"""
  organizer(
    """
    Defines which locales should be returned.
    
    Note that `Organizer` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, entries with non matching locales will be filtered out.
    
    This argument may be overwritten by another locales definition in a relational child field, this will effectively use the overwritten argument for the affected query's subtree.
    """
    locales: [Locale!]! = [en]
    stage: Stage! = PUBLISHED
    where: OrganizerWhereUniqueInput!
  ): Organizer

  """Retrieve document version"""
  organizerVersion(where: VersionWhereInput!): DocumentVersion

  """Retrieve multiple organizers"""
  organizers(
    after: String
    before: String
    first: Int
    last: Int

    """
    Defines which locales should be returned.
    
    Note that `Organizer` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, entries with non matching locales will be filtered out.
    
    This argument may be overwritten by another locales definition in a relational child field, this will effectively use the overwritten argument for the affected query's subtree.
    """
    locales: [Locale!]! = [en]
    orderBy: OrganizerOrderByInput
    skip: Int
    stage: Stage! = PUBLISHED
    where: OrganizerWhereInput
  ): [Organizer!]!

  """Retrieve multiple organizers using the Relay connection interface"""
  organizersConnection(
    after: String
    before: String
    first: Int
    last: Int

    """
    Defines which locales should be returned.
    
    Note that `Organizer` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, entries with non matching locales will be filtered out.
    
    This argument may be overwritten by another locales definition in a relational child field, this will effectively use the overwritten argument for the affected query's subtree.
    """
    locales: [Locale!]! = [en]
    orderBy: OrganizerOrderByInput
    skip: Int
    stage: Stage! = PUBLISHED
    where: OrganizerWhereInput
  ): OrganizerConnection!

  """
  fetch data from the table: "packNftContract"
  """
  packNftContract(
    """distinct select on columns"""
    distinct_on: [packNftContract_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [packNftContract_order_by!]

    """filter the rows returned"""
    where: packNftContract_bool_exp
  ): [packNftContract!]!

  """
  fetch aggregated fields from the table: "packNftContract"
  """
  packNftContract_aggregate(
    """distinct select on columns"""
    distinct_on: [packNftContract_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [packNftContract_order_by!]

    """filter the rows returned"""
    where: packNftContract_bool_exp
  ): packNftContract_aggregate!

  """fetch data from the table: "packNftContract" using primary key columns"""
  packNftContract_by_pk(id: uuid!): packNftContract

  """
  fetch data from the table: "roleAssignments"
  """
  roleAssignments(
    """distinct select on columns"""
    distinct_on: [roleAssignments_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [roleAssignments_order_by!]

    """filter the rows returned"""
    where: roleAssignments_bool_exp
  ): [roleAssignments!]!

  """
  fetch aggregated fields from the table: "roleAssignments"
  """
  roleAssignments_aggregate(
    """distinct select on columns"""
    distinct_on: [roleAssignments_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [roleAssignments_order_by!]

    """filter the rows returned"""
    where: roleAssignments_bool_exp
  ): roleAssignments_aggregate!

  """
  fetch data from the table: "roles"
  """
  roles(
    """distinct select on columns"""
    distinct_on: [roles_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [roles_order_by!]

    """filter the rows returned"""
    where: roles_bool_exp
  ): [roles!]!

  """
  fetch aggregated fields from the table: "roles"
  """
  roles_aggregate(
    """distinct select on columns"""
    distinct_on: [roles_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [roles_order_by!]

    """filter the rows returned"""
    where: roles_bool_exp
  ): roles_aggregate!

  """fetch data from the table: "roles" using primary key columns"""
  roles_by_pk(
    "\n    organizer_super_admin: Full Read & Write permissions on web2 and web3 components. Can assign roles and access system configurations.\n    organizer_admin: Full Read & Write permissions on web2 and web3 components.\n    organizer_operations_manager: Read & Write access to web2 components. Handles event setup, monitoring, analytics, etc.\n    organizer_finance_manager: Read & Write access to web3 components. Manages fund transfers, balance checks, and transaction approvals within limits.\n    organizer_content_manager: Read & Write access to web2 components. Manages content creation, editing, media uploads, and metadata modifications.\n    organizer_validator: Read & Write access on web2 and web3. Updates NFT traits and validates tickets and exclusive access during events.\n    organizer_auditor: Read-only access on web2 and web3. Conducts compliance checks and reviews transactions and operations.\n    organizer_guest: Limited access to web2. Can view public content without web3 permissions.\n    organizer_human_resources: Administrative permissions. Can invite new members for the organization and assign roles (except super admin and human resources).\n"
    value: String!
  ): roles

  """Retrieve a single scheduledOperation"""
  scheduledOperation(
    """
    Defines which locales should be returned.
    
    Note that `ScheduledOperation` is a model without localized fields and will not be affected directly by this argument, however the locales will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument may be overwritten by another locales definition in a relational child field, this will effectively use the overwritten argument for the affected query's subtree.
    """
    locales: [Locale!]! = [en]
    stage: Stage! = PUBLISHED
    where: ScheduledOperationWhereUniqueInput!
  ): ScheduledOperation

  """Retrieve multiple scheduledOperations"""
  scheduledOperations(
    after: String
    before: String
    first: Int
    last: Int

    """
    Defines which locales should be returned.
    
    Note that `ScheduledOperation` is a model without localized fields and will not be affected directly by this argument, however the locales will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument may be overwritten by another locales definition in a relational child field, this will effectively use the overwritten argument for the affected query's subtree.
    """
    locales: [Locale!]! = [en]
    orderBy: ScheduledOperationOrderByInput
    skip: Int
    stage: Stage! = PUBLISHED
    where: ScheduledOperationWhereInput
  ): [ScheduledOperation!]!

  """
  Retrieve multiple scheduledOperations using the Relay connection interface
  """
  scheduledOperationsConnection(
    after: String
    before: String
    first: Int
    last: Int

    """
    Defines which locales should be returned.
    
    Note that `ScheduledOperation` is a model without localized fields and will not be affected directly by this argument, however the locales will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument may be overwritten by another locales definition in a relational child field, this will effectively use the overwritten argument for the affected query's subtree.
    """
    locales: [Locale!]! = [en]
    orderBy: ScheduledOperationOrderByInput
    skip: Int
    stage: Stage! = PUBLISHED
    where: ScheduledOperationWhereInput
  ): ScheduledOperationConnection!

  """Retrieve a single scheduledRelease"""
  scheduledRelease(
    """
    Defines which locales should be returned.
    
    Note that `ScheduledRelease` is a model without localized fields and will not be affected directly by this argument, however the locales will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument may be overwritten by another locales definition in a relational child field, this will effectively use the overwritten argument for the affected query's subtree.
    """
    locales: [Locale!]! = [en]
    stage: Stage! = PUBLISHED
    where: ScheduledReleaseWhereUniqueInput!
  ): ScheduledRelease

  """Retrieve multiple scheduledReleases"""
  scheduledReleases(
    after: String
    before: String
    first: Int
    last: Int

    """
    Defines which locales should be returned.
    
    Note that `ScheduledRelease` is a model without localized fields and will not be affected directly by this argument, however the locales will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument may be overwritten by another locales definition in a relational child field, this will effectively use the overwritten argument for the affected query's subtree.
    """
    locales: [Locale!]! = [en]
    orderBy: ScheduledReleaseOrderByInput
    skip: Int
    stage: Stage! = PUBLISHED
    where: ScheduledReleaseWhereInput
  ): [ScheduledRelease!]!

  """
  Retrieve multiple scheduledReleases using the Relay connection interface
  """
  scheduledReleasesConnection(
    after: String
    before: String
    first: Int
    last: Int

    """
    Defines which locales should be returned.
    
    Note that `ScheduledRelease` is a model without localized fields and will not be affected directly by this argument, however the locales will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument may be overwritten by another locales definition in a relational child field, this will effectively use the overwritten argument for the affected query's subtree.
    """
    locales: [Locale!]! = [en]
    orderBy: ScheduledReleaseOrderByInput
    skip: Int
    stage: Stage! = PUBLISHED
    where: ScheduledReleaseWhereInput
  ): ScheduledReleaseConnection!

  """
  fetch data from the table: "stripeCheckoutSession"
  """
  stripeCheckoutSession(
    """distinct select on columns"""
    distinct_on: [stripeCheckoutSession_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [stripeCheckoutSession_order_by!]

    """filter the rows returned"""
    where: stripeCheckoutSession_bool_exp
  ): [stripeCheckoutSession!]!

  """
  fetch data from the table: "stripeCheckoutSessionType"
  """
  stripeCheckoutSessionType(
    """distinct select on columns"""
    distinct_on: [stripeCheckoutSessionType_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [stripeCheckoutSessionType_order_by!]

    """filter the rows returned"""
    where: stripeCheckoutSessionType_bool_exp
  ): [stripeCheckoutSessionType!]!

  """
  fetch aggregated fields from the table: "stripeCheckoutSessionType"
  """
  stripeCheckoutSessionType_aggregate(
    """distinct select on columns"""
    distinct_on: [stripeCheckoutSessionType_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [stripeCheckoutSessionType_order_by!]

    """filter the rows returned"""
    where: stripeCheckoutSessionType_bool_exp
  ): stripeCheckoutSessionType_aggregate!

  """
  fetch data from the table: "stripeCheckoutSessionType" using primary key columns
  """
  stripeCheckoutSessionType_by_pk(
    """Type value."""
    value: String!
  ): stripeCheckoutSessionType

  """
  fetch aggregated fields from the table: "stripeCheckoutSession"
  """
  stripeCheckoutSession_aggregate(
    """distinct select on columns"""
    distinct_on: [stripeCheckoutSession_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [stripeCheckoutSession_order_by!]

    """filter the rows returned"""
    where: stripeCheckoutSession_bool_exp
  ): stripeCheckoutSession_aggregate!

  """
  fetch data from the table: "stripeCheckoutSession" using primary key columns
  """
  stripeCheckoutSession_by_pk(
    """Unique identifier for the Stripe Checkout Session."""
    stripeSessionId: String!
  ): stripeCheckoutSession

  """
  fetch data from the table: "stripeCustomer"
  """
  stripeCustomer(
    """distinct select on columns"""
    distinct_on: [stripeCustomer_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [stripeCustomer_order_by!]

    """filter the rows returned"""
    where: stripeCustomer_bool_exp
  ): [stripeCustomer!]!

  """
  fetch aggregated fields from the table: "stripeCustomer"
  """
  stripeCustomer_aggregate(
    """distinct select on columns"""
    distinct_on: [stripeCustomer_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [stripeCustomer_order_by!]

    """filter the rows returned"""
    where: stripeCustomer_bool_exp
  ): stripeCustomer_aggregate!

  """fetch data from the table: "stripeCustomer" using primary key columns"""
  stripeCustomer_by_pk(
    """Unique identifier for the Stripe Customer."""
    stripeCustomerId: String!
  ): stripeCustomer

  """
  fetch data from the table: "timezone"
  """
  timezone(
    """distinct select on columns"""
    distinct_on: [timezone_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [timezone_order_by!]

    """filter the rows returned"""
    where: timezone_bool_exp
  ): [timezone!]!

  """
  fetch aggregated fields from the table: "timezone"
  """
  timezone_aggregate(
    """distinct select on columns"""
    distinct_on: [timezone_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [timezone_order_by!]

    """filter the rows returned"""
    where: timezone_bool_exp
  ): timezone_aggregate!

  """fetch data from the table: "timezone" using primary key columns"""
  timezone_by_pk(value: String!): timezone

  """Retrieve a single user"""
  user(
    """
    Defines which locales should be returned.
    
    Note that `User` is a model without localized fields and will not be affected directly by this argument, however the locales will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument may be overwritten by another locales definition in a relational child field, this will effectively use the overwritten argument for the affected query's subtree.
    """
    locales: [Locale!]! = [en]
    stage: Stage! = PUBLISHED
    where: UserWhereUniqueInput!
  ): User

  """Retrieve multiple users"""
  users(
    after: String
    before: String
    first: Int
    last: Int

    """
    Defines which locales should be returned.
    
    Note that `User` is a model without localized fields and will not be affected directly by this argument, however the locales will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument may be overwritten by another locales definition in a relational child field, this will effectively use the overwritten argument for the affected query's subtree.
    """
    locales: [Locale!]! = [en]
    orderBy: UserOrderByInput
    skip: Int
    stage: Stage! = PUBLISHED
    where: UserWhereInput
  ): [User!]!

  """Retrieve multiple users using the Relay connection interface"""
  usersConnection(
    after: String
    before: String
    first: Int
    last: Int

    """
    Defines which locales should be returned.
    
    Note that `User` is a model without localized fields and will not be affected directly by this argument, however the locales will be passed on to any relational fields in the query's subtree for filtering.
    For related models with localized fields in the query's subtree, the first locale matching the provided list of locales will be returned, entries with non matching locales will be filtered out.
    
    This argument may be overwritten by another locales definition in a relational child field, this will effectively use the overwritten argument for the affected query's subtree.
    """
    locales: [Locale!]! = [en]
    orderBy: UserOrderByInput
    skip: Int
    stage: Stage! = PUBLISHED
    where: UserWhereInput
  ): UserConnection!
}

"""
Table to assign roles to accounts, allowing a many-to-many relationship. Each account can have multiple roles and each role can be assigned to multiple accounts. This is part of the RBAC system integration.
"""
type roleAssignments {
  accountId: uuid!
  created_at: timestamptz!
  eventId: String!
  id: uuid!
  invitedById: uuid!

  """An object relationship"""
  inviter: account!
  organizer(
    """
    Defines which locales should be returned.
    
    Note that `Organizer` will be affected directly by this argument, as well as any other related models with localized fields in the query's subtree.
    The first locale matching the provided list will be returned, entries with non matching locales will be filtered out.
    
    This argument may be overwritten by another locales definition in a relational child field, this will effectively use the overwritten argument for the affected query's subtree.
    """
    locales: [Locale!]! = [en]
    stage: Stage! = PUBLISHED
    where: OrganizerWhereUniqueInput_remote_rel_roleAssignmentsorganizer!
  ): Organizer
  organizerId: String!
  role: roles_enum!
}

"""
aggregated selection of "roleAssignments"
"""
type roleAssignments_aggregate {
  aggregate: roleAssignments_aggregate_fields
  nodes: [roleAssignments!]!
}

input roleAssignments_aggregate_bool_exp {
  count: roleAssignments_aggregate_bool_exp_count
}

input roleAssignments_aggregate_bool_exp_count {
  arguments: [roleAssignments_select_column!]
  distinct: Boolean
  filter: roleAssignments_bool_exp
  predicate: Int_comparison_exp!
}

"""
aggregate fields of "roleAssignments"
"""
type roleAssignments_aggregate_fields {
  count(columns: [roleAssignments_select_column!], distinct: Boolean): Int!
  max: roleAssignments_max_fields
  min: roleAssignments_min_fields
}

"""
order by aggregate values of table "roleAssignments"
"""
input roleAssignments_aggregate_order_by {
  count: order_by
  max: roleAssignments_max_order_by
  min: roleAssignments_min_order_by
}

"""
input type for inserting array relation for remote table "roleAssignments"
"""
input roleAssignments_arr_rel_insert_input {
  data: [roleAssignments_insert_input!]!

  """upsert condition"""
  on_conflict: roleAssignments_on_conflict
}

"""
Boolean expression to filter rows from the table "roleAssignments". All fields are combined with a logical 'AND'.
"""
input roleAssignments_bool_exp {
  _and: [roleAssignments_bool_exp!]
  _not: roleAssignments_bool_exp
  _or: [roleAssignments_bool_exp!]
  accountId: uuid_comparison_exp
  created_at: timestamptz_comparison_exp
  eventId: String_comparison_exp
  id: uuid_comparison_exp
  invitedById: uuid_comparison_exp
  inviter: account_bool_exp
  organizerId: String_comparison_exp
  role: roles_enum_comparison_exp
}

"""
unique or primary key constraints on table "roleAssignments"
"""
enum roleAssignments_constraint {
  """
  unique or primary key constraint on columns "organizerId", "accountId", "role", "eventId"
  """
  unique_role_assignment
}

"""
input type for inserting data into table "roleAssignments"
"""
input roleAssignments_insert_input {
  accountId: uuid
  created_at: timestamptz
  eventId: String
  id: uuid
  invitedById: uuid
  inviter: account_obj_rel_insert_input
  organizerId: String
  role: roles_enum
}

"""aggregate max on columns"""
type roleAssignments_max_fields {
  accountId: uuid
  created_at: timestamptz
  eventId: String
  id: uuid
  invitedById: uuid
  organizerId: String
}

"""
order by max() on columns of table "roleAssignments"
"""
input roleAssignments_max_order_by {
  accountId: order_by
  created_at: order_by
  eventId: order_by
  id: order_by
  invitedById: order_by
  organizerId: order_by
}

"""aggregate min on columns"""
type roleAssignments_min_fields {
  accountId: uuid
  created_at: timestamptz
  eventId: String
  id: uuid
  invitedById: uuid
  organizerId: String
}

"""
order by min() on columns of table "roleAssignments"
"""
input roleAssignments_min_order_by {
  accountId: order_by
  created_at: order_by
  eventId: order_by
  id: order_by
  invitedById: order_by
  organizerId: order_by
}

"""
response of any mutation on the table "roleAssignments"
"""
type roleAssignments_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [roleAssignments!]!
}

"""
on_conflict condition type for table "roleAssignments"
"""
input roleAssignments_on_conflict {
  constraint: roleAssignments_constraint!
  update_columns: [roleAssignments_update_column!]! = []
  where: roleAssignments_bool_exp
}

"""Ordering options when selecting data from "roleAssignments"."""
input roleAssignments_order_by {
  accountId: order_by
  created_at: order_by
  eventId: order_by
  id: order_by
  invitedById: order_by
  inviter: account_order_by
  organizerId: order_by
  role: order_by
}

"""
select columns of table "roleAssignments"
"""
enum roleAssignments_select_column {
  """column name"""
  accountId

  """column name"""
  created_at

  """column name"""
  eventId

  """column name"""
  id

  """column name"""
  invitedById

  """column name"""
  organizerId

  """column name"""
  role
}

"""
input type for updating data in table "roleAssignments"
"""
input roleAssignments_set_input {
  accountId: uuid
  created_at: timestamptz
  eventId: String
  id: uuid
  invitedById: uuid
  organizerId: String
  role: roles_enum
}

"""
Streaming cursor of the table "roleAssignments"
"""
input roleAssignments_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: roleAssignments_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input roleAssignments_stream_cursor_value_input {
  accountId: uuid
  created_at: timestamptz
  eventId: String
  id: uuid
  invitedById: uuid
  organizerId: String
  role: roles_enum
}

"""
update columns of table "roleAssignments"
"""
enum roleAssignments_update_column {
  """column name"""
  accountId

  """column name"""
  created_at

  """column name"""
  eventId

  """column name"""
  id

  """column name"""
  invitedById

  """column name"""
  organizerId

  """column name"""
  role
}

input roleAssignments_updates {
  """sets the columns of the filtered rows to the given values"""
  _set: roleAssignments_set_input

  """filter the rows which have to be updated"""
  where: roleAssignments_bool_exp!
}

"""
Stores user roles defining access levels and permissions within the Offline platform.
"""
type roles {
  "\n    organizer_super_admin: Full Read & Write permissions on web2 and web3 components. Can assign roles and access system configurations.\n    organizer_admin: Full Read & Write permissions on web2 and web3 components.\n    organizer_operations_manager: Read & Write access to web2 components. Handles event setup, monitoring, analytics, etc.\n    organizer_finance_manager: Read & Write access to web3 components. Manages fund transfers, balance checks, and transaction approvals within limits.\n    organizer_content_manager: Read & Write access to web2 components. Manages content creation, editing, media uploads, and metadata modifications.\n    organizer_validator: Read & Write access on web2 and web3. Updates NFT traits and validates tickets and exclusive access during events.\n    organizer_auditor: Read-only access on web2 and web3. Conducts compliance checks and reviews transactions and operations.\n    organizer_guest: Limited access to web2. Can view public content without web3 permissions.\n    organizer_human_resources: Administrative permissions. Can invite new members for the organization and assign roles (except super admin and human resources).\n"
  value: String!
}

"""
aggregated selection of "roles"
"""
type roles_aggregate {
  aggregate: roles_aggregate_fields
  nodes: [roles!]!
}

"""
aggregate fields of "roles"
"""
type roles_aggregate_fields {
  count(columns: [roles_select_column!], distinct: Boolean): Int!
  max: roles_max_fields
  min: roles_min_fields
}

"""
Boolean expression to filter rows from the table "roles". All fields are combined with a logical 'AND'.
"""
input roles_bool_exp {
  _and: [roles_bool_exp!]
  _not: roles_bool_exp
  _or: [roles_bool_exp!]
  value: String_comparison_exp
}

"""
unique or primary key constraints on table "roles"
"""
enum roles_constraint {
  """
  unique or primary key constraint on columns "value"
  """
  roles_pkey
}

enum roles_enum {
  organizer_admin
  organizer_auditor
  organizer_content_manager
  organizer_finance_manager
  organizer_guest
  organizer_human_resources
  organizer_operations_manager
  organizer_super_admin
  organizer_validator
}

"""
Boolean expression to compare columns of type "roles_enum". All fields are combined with logical 'AND'.
"""
input roles_enum_comparison_exp {
  _eq: roles_enum
  _in: [roles_enum!]
  _is_null: Boolean
  _neq: roles_enum
  _nin: [roles_enum!]
}

"""
input type for inserting data into table "roles"
"""
input roles_insert_input {
  "\n    organizer_super_admin: Full Read & Write permissions on web2 and web3 components. Can assign roles and access system configurations.\n    organizer_admin: Full Read & Write permissions on web2 and web3 components.\n    organizer_operations_manager: Read & Write access to web2 components. Handles event setup, monitoring, analytics, etc.\n    organizer_finance_manager: Read & Write access to web3 components. Manages fund transfers, balance checks, and transaction approvals within limits.\n    organizer_content_manager: Read & Write access to web2 components. Manages content creation, editing, media uploads, and metadata modifications.\n    organizer_validator: Read & Write access on web2 and web3. Updates NFT traits and validates tickets and exclusive access during events.\n    organizer_auditor: Read-only access on web2 and web3. Conducts compliance checks and reviews transactions and operations.\n    organizer_guest: Limited access to web2. Can view public content without web3 permissions.\n    organizer_human_resources: Administrative permissions. Can invite new members for the organization and assign roles (except super admin and human resources).\n"
  value: String
}

"""aggregate max on columns"""
type roles_max_fields {
  "\n    organizer_super_admin: Full Read & Write permissions on web2 and web3 components. Can assign roles and access system configurations.\n    organizer_admin: Full Read & Write permissions on web2 and web3 components.\n    organizer_operations_manager: Read & Write access to web2 components. Handles event setup, monitoring, analytics, etc.\n    organizer_finance_manager: Read & Write access to web3 components. Manages fund transfers, balance checks, and transaction approvals within limits.\n    organizer_content_manager: Read & Write access to web2 components. Manages content creation, editing, media uploads, and metadata modifications.\n    organizer_validator: Read & Write access on web2 and web3. Updates NFT traits and validates tickets and exclusive access during events.\n    organizer_auditor: Read-only access on web2 and web3. Conducts compliance checks and reviews transactions and operations.\n    organizer_guest: Limited access to web2. Can view public content without web3 permissions.\n    organizer_human_resources: Administrative permissions. Can invite new members for the organization and assign roles (except super admin and human resources).\n"
  value: String
}

"""aggregate min on columns"""
type roles_min_fields {
  "\n    organizer_super_admin: Full Read & Write permissions on web2 and web3 components. Can assign roles and access system configurations.\n    organizer_admin: Full Read & Write permissions on web2 and web3 components.\n    organizer_operations_manager: Read & Write access to web2 components. Handles event setup, monitoring, analytics, etc.\n    organizer_finance_manager: Read & Write access to web3 components. Manages fund transfers, balance checks, and transaction approvals within limits.\n    organizer_content_manager: Read & Write access to web2 components. Manages content creation, editing, media uploads, and metadata modifications.\n    organizer_validator: Read & Write access on web2 and web3. Updates NFT traits and validates tickets and exclusive access during events.\n    organizer_auditor: Read-only access on web2 and web3. Conducts compliance checks and reviews transactions and operations.\n    organizer_guest: Limited access to web2. Can view public content without web3 permissions.\n    organizer_human_resources: Administrative permissions. Can invite new members for the organization and assign roles (except super admin and human resources).\n"
  value: String
}

"""
response of any mutation on the table "roles"
"""
type roles_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [roles!]!
}

"""
on_conflict condition type for table "roles"
"""
input roles_on_conflict {
  constraint: roles_constraint!
  update_columns: [roles_update_column!]! = []
  where: roles_bool_exp
}

"""Ordering options when selecting data from "roles"."""
input roles_order_by {
  value: order_by
}

"""primary key columns input for table: roles"""
input roles_pk_columns_input {
  "\n    organizer_super_admin: Full Read & Write permissions on web2 and web3 components. Can assign roles and access system configurations.\n    organizer_admin: Full Read & Write permissions on web2 and web3 components.\n    organizer_operations_manager: Read & Write access to web2 components. Handles event setup, monitoring, analytics, etc.\n    organizer_finance_manager: Read & Write access to web3 components. Manages fund transfers, balance checks, and transaction approvals within limits.\n    organizer_content_manager: Read & Write access to web2 components. Manages content creation, editing, media uploads, and metadata modifications.\n    organizer_validator: Read & Write access on web2 and web3. Updates NFT traits and validates tickets and exclusive access during events.\n    organizer_auditor: Read-only access on web2 and web3. Conducts compliance checks and reviews transactions and operations.\n    organizer_guest: Limited access to web2. Can view public content without web3 permissions.\n    organizer_human_resources: Administrative permissions. Can invite new members for the organization and assign roles (except super admin and human resources).\n"
  value: String!
}

"""
select columns of table "roles"
"""
enum roles_select_column {
  """column name"""
  value
}

"""
input type for updating data in table "roles"
"""
input roles_set_input {
  "\n    organizer_super_admin: Full Read & Write permissions on web2 and web3 components. Can assign roles and access system configurations.\n    organizer_admin: Full Read & Write permissions on web2 and web3 components.\n    organizer_operations_manager: Read & Write access to web2 components. Handles event setup, monitoring, analytics, etc.\n    organizer_finance_manager: Read & Write access to web3 components. Manages fund transfers, balance checks, and transaction approvals within limits.\n    organizer_content_manager: Read & Write access to web2 components. Manages content creation, editing, media uploads, and metadata modifications.\n    organizer_validator: Read & Write access on web2 and web3. Updates NFT traits and validates tickets and exclusive access during events.\n    organizer_auditor: Read-only access on web2 and web3. Conducts compliance checks and reviews transactions and operations.\n    organizer_guest: Limited access to web2. Can view public content without web3 permissions.\n    organizer_human_resources: Administrative permissions. Can invite new members for the organization and assign roles (except super admin and human resources).\n"
  value: String
}

"""
Streaming cursor of the table "roles"
"""
input roles_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: roles_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input roles_stream_cursor_value_input {
  "\n    organizer_super_admin: Full Read & Write permissions on web2 and web3 components. Can assign roles and access system configurations.\n    organizer_admin: Full Read & Write permissions on web2 and web3 components.\n    organizer_operations_manager: Read & Write access to web2 components. Handles event setup, monitoring, analytics, etc.\n    organizer_finance_manager: Read & Write access to web3 components. Manages fund transfers, balance checks, and transaction approvals within limits.\n    organizer_content_manager: Read & Write access to web2 components. Manages content creation, editing, media uploads, and metadata modifications.\n    organizer_validator: Read & Write access on web2 and web3. Updates NFT traits and validates tickets and exclusive access during events.\n    organizer_auditor: Read-only access on web2 and web3. Conducts compliance checks and reviews transactions and operations.\n    organizer_guest: Limited access to web2. Can view public content without web3 permissions.\n    organizer_human_resources: Administrative permissions. Can invite new members for the organization and assign roles (except super admin and human resources).\n"
  value: String
}

"""
update columns of table "roles"
"""
enum roles_update_column {
  """column name"""
  value
}

input roles_updates {
  """sets the columns of the filtered rows to the given values"""
  _set: roles_set_input

  """filter the rows which have to be updated"""
  where: roles_bool_exp!
}

"""
Table to store Stripe Checkout Sessions for tracking user checkout processes. Sessions are deleted once they are successful or expired.
"""
type stripeCheckoutSession {
  """Timestamp automatically set when the row is created."""
  created_at: timestamptz!

  """Stripe Customer ID referencing to the stripeCustomer table."""
  stripeCustomerId: String!

  """Unique identifier for the Stripe Checkout Session."""
  stripeSessionId: String!

  """
  Type of the Stripe Checkout Session. Default is event_pass_order. References to the stripeCheckoutSessionType table.
  """
  type: stripeCheckoutSessionType_enum!

  """Timestamp automatically updated whenever the row changes."""
  updated_at: timestamptz!
}

"""Types of Stripe Checkout Sessions."""
type stripeCheckoutSessionType {
  """Type value."""
  value: String!
}

"""
aggregated selection of "stripeCheckoutSessionType"
"""
type stripeCheckoutSessionType_aggregate {
  aggregate: stripeCheckoutSessionType_aggregate_fields
  nodes: [stripeCheckoutSessionType!]!
}

"""
aggregate fields of "stripeCheckoutSessionType"
"""
type stripeCheckoutSessionType_aggregate_fields {
  count(columns: [stripeCheckoutSessionType_select_column!], distinct: Boolean): Int!
  max: stripeCheckoutSessionType_max_fields
  min: stripeCheckoutSessionType_min_fields
}

"""
Boolean expression to filter rows from the table "stripeCheckoutSessionType". All fields are combined with a logical 'AND'.
"""
input stripeCheckoutSessionType_bool_exp {
  _and: [stripeCheckoutSessionType_bool_exp!]
  _not: stripeCheckoutSessionType_bool_exp
  _or: [stripeCheckoutSessionType_bool_exp!]
  value: String_comparison_exp
}

"""
unique or primary key constraints on table "stripeCheckoutSessionType"
"""
enum stripeCheckoutSessionType_constraint {
  """
  unique or primary key constraint on columns "value"
  """
  stripeCheckoutSessionType_pkey
}

enum stripeCheckoutSessionType_enum {
  event_pass_order
}

"""
Boolean expression to compare columns of type "stripeCheckoutSessionType_enum". All fields are combined with logical 'AND'.
"""
input stripeCheckoutSessionType_enum_comparison_exp {
  _eq: stripeCheckoutSessionType_enum
  _in: [stripeCheckoutSessionType_enum!]
  _is_null: Boolean
  _neq: stripeCheckoutSessionType_enum
  _nin: [stripeCheckoutSessionType_enum!]
}

"""
input type for inserting data into table "stripeCheckoutSessionType"
"""
input stripeCheckoutSessionType_insert_input {
  """Type value."""
  value: String
}

"""aggregate max on columns"""
type stripeCheckoutSessionType_max_fields {
  """Type value."""
  value: String
}

"""aggregate min on columns"""
type stripeCheckoutSessionType_min_fields {
  """Type value."""
  value: String
}

"""
response of any mutation on the table "stripeCheckoutSessionType"
"""
type stripeCheckoutSessionType_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [stripeCheckoutSessionType!]!
}

"""
on_conflict condition type for table "stripeCheckoutSessionType"
"""
input stripeCheckoutSessionType_on_conflict {
  constraint: stripeCheckoutSessionType_constraint!
  update_columns: [stripeCheckoutSessionType_update_column!]! = []
  where: stripeCheckoutSessionType_bool_exp
}

"""Ordering options when selecting data from "stripeCheckoutSessionType"."""
input stripeCheckoutSessionType_order_by {
  value: order_by
}

"""primary key columns input for table: stripeCheckoutSessionType"""
input stripeCheckoutSessionType_pk_columns_input {
  """Type value."""
  value: String!
}

"""
select columns of table "stripeCheckoutSessionType"
"""
enum stripeCheckoutSessionType_select_column {
  """column name"""
  value
}

"""
input type for updating data in table "stripeCheckoutSessionType"
"""
input stripeCheckoutSessionType_set_input {
  """Type value."""
  value: String
}

"""
Streaming cursor of the table "stripeCheckoutSessionType"
"""
input stripeCheckoutSessionType_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: stripeCheckoutSessionType_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input stripeCheckoutSessionType_stream_cursor_value_input {
  """Type value."""
  value: String
}

"""
update columns of table "stripeCheckoutSessionType"
"""
enum stripeCheckoutSessionType_update_column {
  """column name"""
  value
}

input stripeCheckoutSessionType_updates {
  """sets the columns of the filtered rows to the given values"""
  _set: stripeCheckoutSessionType_set_input

  """filter the rows which have to be updated"""
  where: stripeCheckoutSessionType_bool_exp!
}

"""
aggregated selection of "stripeCheckoutSession"
"""
type stripeCheckoutSession_aggregate {
  aggregate: stripeCheckoutSession_aggregate_fields
  nodes: [stripeCheckoutSession!]!
}

"""
aggregate fields of "stripeCheckoutSession"
"""
type stripeCheckoutSession_aggregate_fields {
  count(columns: [stripeCheckoutSession_select_column!], distinct: Boolean): Int!
  max: stripeCheckoutSession_max_fields
  min: stripeCheckoutSession_min_fields
}

"""
Boolean expression to filter rows from the table "stripeCheckoutSession". All fields are combined with a logical 'AND'.
"""
input stripeCheckoutSession_bool_exp {
  _and: [stripeCheckoutSession_bool_exp!]
  _not: stripeCheckoutSession_bool_exp
  _or: [stripeCheckoutSession_bool_exp!]
  created_at: timestamptz_comparison_exp
  stripeCustomerId: String_comparison_exp
  stripeSessionId: String_comparison_exp
  type: stripeCheckoutSessionType_enum_comparison_exp
  updated_at: timestamptz_comparison_exp
}

"""
unique or primary key constraints on table "stripeCheckoutSession"
"""
enum stripeCheckoutSession_constraint {
  """
  unique or primary key constraint on columns "stripeSessionId"
  """
  stripeCheckoutSession_pkey
}

"""
input type for inserting data into table "stripeCheckoutSession"
"""
input stripeCheckoutSession_insert_input {
  """Timestamp automatically set when the row is created."""
  created_at: timestamptz

  """Stripe Customer ID referencing to the stripeCustomer table."""
  stripeCustomerId: String

  """Unique identifier for the Stripe Checkout Session."""
  stripeSessionId: String

  """
  Type of the Stripe Checkout Session. Default is event_pass_order. References to the stripeCheckoutSessionType table.
  """
  type: stripeCheckoutSessionType_enum

  """Timestamp automatically updated whenever the row changes."""
  updated_at: timestamptz
}

"""aggregate max on columns"""
type stripeCheckoutSession_max_fields {
  """Timestamp automatically set when the row is created."""
  created_at: timestamptz

  """Stripe Customer ID referencing to the stripeCustomer table."""
  stripeCustomerId: String

  """Unique identifier for the Stripe Checkout Session."""
  stripeSessionId: String

  """Timestamp automatically updated whenever the row changes."""
  updated_at: timestamptz
}

"""aggregate min on columns"""
type stripeCheckoutSession_min_fields {
  """Timestamp automatically set when the row is created."""
  created_at: timestamptz

  """Stripe Customer ID referencing to the stripeCustomer table."""
  stripeCustomerId: String

  """Unique identifier for the Stripe Checkout Session."""
  stripeSessionId: String

  """Timestamp automatically updated whenever the row changes."""
  updated_at: timestamptz
}

"""
response of any mutation on the table "stripeCheckoutSession"
"""
type stripeCheckoutSession_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [stripeCheckoutSession!]!
}

"""
on_conflict condition type for table "stripeCheckoutSession"
"""
input stripeCheckoutSession_on_conflict {
  constraint: stripeCheckoutSession_constraint!
  update_columns: [stripeCheckoutSession_update_column!]! = []
  where: stripeCheckoutSession_bool_exp
}

"""Ordering options when selecting data from "stripeCheckoutSession"."""
input stripeCheckoutSession_order_by {
  created_at: order_by
  stripeCustomerId: order_by
  stripeSessionId: order_by
  type: order_by
  updated_at: order_by
}

"""primary key columns input for table: stripeCheckoutSession"""
input stripeCheckoutSession_pk_columns_input {
  """Unique identifier for the Stripe Checkout Session."""
  stripeSessionId: String!
}

"""
select columns of table "stripeCheckoutSession"
"""
enum stripeCheckoutSession_select_column {
  """column name"""
  created_at

  """column name"""
  stripeCustomerId

  """column name"""
  stripeSessionId

  """column name"""
  type

  """column name"""
  updated_at
}

"""
input type for updating data in table "stripeCheckoutSession"
"""
input stripeCheckoutSession_set_input {
  """Timestamp automatically set when the row is created."""
  created_at: timestamptz

  """Stripe Customer ID referencing to the stripeCustomer table."""
  stripeCustomerId: String

  """Unique identifier for the Stripe Checkout Session."""
  stripeSessionId: String

  """
  Type of the Stripe Checkout Session. Default is event_pass_order. References to the stripeCheckoutSessionType table.
  """
  type: stripeCheckoutSessionType_enum

  """Timestamp automatically updated whenever the row changes."""
  updated_at: timestamptz
}

"""
Streaming cursor of the table "stripeCheckoutSession"
"""
input stripeCheckoutSession_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: stripeCheckoutSession_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input stripeCheckoutSession_stream_cursor_value_input {
  """Timestamp automatically set when the row is created."""
  created_at: timestamptz

  """Stripe Customer ID referencing to the stripeCustomer table."""
  stripeCustomerId: String

  """Unique identifier for the Stripe Checkout Session."""
  stripeSessionId: String

  """
  Type of the Stripe Checkout Session. Default is event_pass_order. References to the stripeCheckoutSessionType table.
  """
  type: stripeCheckoutSessionType_enum

  """Timestamp automatically updated whenever the row changes."""
  updated_at: timestamptz
}

"""
update columns of table "stripeCheckoutSession"
"""
enum stripeCheckoutSession_update_column {
  """column name"""
  created_at

  """column name"""
  stripeCustomerId

  """column name"""
  stripeSessionId

  """column name"""
  type

  """column name"""
  updated_at
}

input stripeCheckoutSession_updates {
  """sets the columns of the filtered rows to the given values"""
  _set: stripeCheckoutSession_set_input

  """filter the rows which have to be updated"""
  where: stripeCheckoutSession_bool_exp!
}

"""
Table to store Stripe Customer IDs for tracking user payment processes.
"""
type stripeCustomer {
  """UUID referencing to the account ID in the existing accounts table."""
  accountId: uuid!

  """Timestamp automatically set when the row is created."""
  created_at: timestamptz!

  """Unique identifier for the Stripe Customer."""
  stripeCustomerId: String!

  """Timestamp automatically updated whenever the row changes."""
  updated_at: timestamptz!
}

"""
aggregated selection of "stripeCustomer"
"""
type stripeCustomer_aggregate {
  aggregate: stripeCustomer_aggregate_fields
  nodes: [stripeCustomer!]!
}

"""
aggregate fields of "stripeCustomer"
"""
type stripeCustomer_aggregate_fields {
  count(columns: [stripeCustomer_select_column!], distinct: Boolean): Int!
  max: stripeCustomer_max_fields
  min: stripeCustomer_min_fields
}

"""
Boolean expression to filter rows from the table "stripeCustomer". All fields are combined with a logical 'AND'.
"""
input stripeCustomer_bool_exp {
  _and: [stripeCustomer_bool_exp!]
  _not: stripeCustomer_bool_exp
  _or: [stripeCustomer_bool_exp!]
  accountId: uuid_comparison_exp
  created_at: timestamptz_comparison_exp
  stripeCustomerId: String_comparison_exp
  updated_at: timestamptz_comparison_exp
}

"""
unique or primary key constraints on table "stripeCustomer"
"""
enum stripeCustomer_constraint {
  """
  unique or primary key constraint on columns "stripeCustomerId"
  """
  stripeCustomer_pkey
}

"""
input type for inserting data into table "stripeCustomer"
"""
input stripeCustomer_insert_input {
  """UUID referencing to the account ID in the existing accounts table."""
  accountId: uuid

  """Timestamp automatically set when the row is created."""
  created_at: timestamptz

  """Unique identifier for the Stripe Customer."""
  stripeCustomerId: String

  """Timestamp automatically updated whenever the row changes."""
  updated_at: timestamptz
}

"""aggregate max on columns"""
type stripeCustomer_max_fields {
  """UUID referencing to the account ID in the existing accounts table."""
  accountId: uuid

  """Timestamp automatically set when the row is created."""
  created_at: timestamptz

  """Unique identifier for the Stripe Customer."""
  stripeCustomerId: String

  """Timestamp automatically updated whenever the row changes."""
  updated_at: timestamptz
}

"""aggregate min on columns"""
type stripeCustomer_min_fields {
  """UUID referencing to the account ID in the existing accounts table."""
  accountId: uuid

  """Timestamp automatically set when the row is created."""
  created_at: timestamptz

  """Unique identifier for the Stripe Customer."""
  stripeCustomerId: String

  """Timestamp automatically updated whenever the row changes."""
  updated_at: timestamptz
}

"""
response of any mutation on the table "stripeCustomer"
"""
type stripeCustomer_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [stripeCustomer!]!
}

"""
input type for inserting object relation for remote table "stripeCustomer"
"""
input stripeCustomer_obj_rel_insert_input {
  data: stripeCustomer_insert_input!

  """upsert condition"""
  on_conflict: stripeCustomer_on_conflict
}

"""
on_conflict condition type for table "stripeCustomer"
"""
input stripeCustomer_on_conflict {
  constraint: stripeCustomer_constraint!
  update_columns: [stripeCustomer_update_column!]! = []
  where: stripeCustomer_bool_exp
}

"""Ordering options when selecting data from "stripeCustomer"."""
input stripeCustomer_order_by {
  accountId: order_by
  created_at: order_by
  stripeCustomerId: order_by
  updated_at: order_by
}

"""primary key columns input for table: stripeCustomer"""
input stripeCustomer_pk_columns_input {
  """Unique identifier for the Stripe Customer."""
  stripeCustomerId: String!
}

"""
select columns of table "stripeCustomer"
"""
enum stripeCustomer_select_column {
  """column name"""
  accountId

  """column name"""
  created_at

  """column name"""
  stripeCustomerId

  """column name"""
  updated_at
}

"""
input type for updating data in table "stripeCustomer"
"""
input stripeCustomer_set_input {
  """UUID referencing to the account ID in the existing accounts table."""
  accountId: uuid

  """Timestamp automatically set when the row is created."""
  created_at: timestamptz

  """Unique identifier for the Stripe Customer."""
  stripeCustomerId: String

  """Timestamp automatically updated whenever the row changes."""
  updated_at: timestamptz
}

"""
Streaming cursor of the table "stripeCustomer"
"""
input stripeCustomer_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: stripeCustomer_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input stripeCustomer_stream_cursor_value_input {
  """UUID referencing to the account ID in the existing accounts table."""
  accountId: uuid

  """Timestamp automatically set when the row is created."""
  created_at: timestamptz

  """Unique identifier for the Stripe Customer."""
  stripeCustomerId: String

  """Timestamp automatically updated whenever the row changes."""
  updated_at: timestamptz
}

"""
update columns of table "stripeCustomer"
"""
enum stripeCustomer_update_column {
  """column name"""
  accountId

  """column name"""
  created_at

  """column name"""
  stripeCustomerId

  """column name"""
  updated_at
}

input stripeCustomer_updates {
  """sets the columns of the filtered rows to the given values"""
  _set: stripeCustomer_set_input

  """filter the rows which have to be updated"""
  where: stripeCustomer_bool_exp!
}

type subscription_root {
  """
  fetch data from the table: "account"
  """
  account(
    """distinct select on columns"""
    distinct_on: [account_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [account_order_by!]

    """filter the rows returned"""
    where: account_bool_exp
  ): [account!]!

  """
  fetch aggregated fields from the table: "account"
  """
  account_aggregate(
    """distinct select on columns"""
    distinct_on: [account_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [account_order_by!]

    """filter the rows returned"""
    where: account_bool_exp
  ): account_aggregate!

  """fetch data from the table: "account" using primary key columns"""
  account_by_pk(id: uuid!): account

  """
  fetch data from the table in a streaming manner: "account"
  """
  account_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [account_stream_cursor_input]!

    """filter the rows returned"""
    where: account_bool_exp
  ): [account!]!

  """
  fetch data from the table: "audit.logged_actions"
  """
  audit_logged_actions(
    """distinct select on columns"""
    distinct_on: [audit_logged_actions_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [audit_logged_actions_order_by!]

    """filter the rows returned"""
    where: audit_logged_actions_bool_exp
  ): [audit_logged_actions!]!

  """
  fetch aggregated fields from the table: "audit.logged_actions"
  """
  audit_logged_actions_aggregate(
    """distinct select on columns"""
    distinct_on: [audit_logged_actions_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [audit_logged_actions_order_by!]

    """filter the rows returned"""
    where: audit_logged_actions_bool_exp
  ): audit_logged_actions_aggregate!

  """
  fetch data from the table: "audit.logged_actions" using primary key columns
  """
  audit_logged_actions_by_pk(
    """Unique identifier for each auditable event"""
    event_id: bigint!
  ): audit_logged_actions

  """
  fetch data from the table in a streaming manner: "audit.logged_actions"
  """
  audit_logged_actions_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [audit_logged_actions_stream_cursor_input]!

    """filter the rows returned"""
    where: audit_logged_actions_bool_exp
  ): [audit_logged_actions!]!

  """
  fetch data from the table: "currency"
  """
  currency(
    """distinct select on columns"""
    distinct_on: [currency_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [currency_order_by!]

    """filter the rows returned"""
    where: currency_bool_exp
  ): [currency!]!

  """
  fetch aggregated fields from the table: "currency"
  """
  currency_aggregate(
    """distinct select on columns"""
    distinct_on: [currency_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [currency_order_by!]

    """filter the rows returned"""
    where: currency_bool_exp
  ): currency_aggregate!

  """fetch data from the table: "currency" using primary key columns"""
  currency_by_pk(value: String!): currency

  """
  fetch data from the table in a streaming manner: "currency"
  """
  currency_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [currency_stream_cursor_input]!

    """filter the rows returned"""
    where: currency_bool_exp
  ): [currency!]!

  """
  fetch data from the table: "eventParameters"
  """
  eventParameters(
    """distinct select on columns"""
    distinct_on: [eventParameters_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [eventParameters_order_by!]

    """filter the rows returned"""
    where: eventParameters_bool_exp
  ): [eventParameters!]!

  """
  fetch aggregated fields from the table: "eventParameters"
  """
  eventParameters_aggregate(
    """distinct select on columns"""
    distinct_on: [eventParameters_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [eventParameters_order_by!]

    """filter the rows returned"""
    where: eventParameters_bool_exp
  ): eventParameters_aggregate!

  """fetch data from the table: "eventParameters" using primary key columns"""
  eventParameters_by_pk(id: uuid!): eventParameters

  """
  fetch data from the table in a streaming manner: "eventParameters"
  """
  eventParameters_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [eventParameters_stream_cursor_input]!

    """filter the rows returned"""
    where: eventParameters_bool_exp
  ): [eventParameters!]!

  """
  fetch data from the table: "eventPassNft"
  """
  eventPassNft(
    """distinct select on columns"""
    distinct_on: [eventPassNft_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [eventPassNft_order_by!]

    """filter the rows returned"""
    where: eventPassNft_bool_exp
  ): [eventPassNft!]!

  """
  fetch data from the table: "eventPassNftContract"
  """
  eventPassNftContract(
    """distinct select on columns"""
    distinct_on: [eventPassNftContract_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [eventPassNftContract_order_by!]

    """filter the rows returned"""
    where: eventPassNftContract_bool_exp
  ): [eventPassNftContract!]!

  """
  fetch data from the table: "eventPassNftContractType"
  """
  eventPassNftContractType(
    """distinct select on columns"""
    distinct_on: [eventPassNftContractType_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [eventPassNftContractType_order_by!]

    """filter the rows returned"""
    where: eventPassNftContractType_bool_exp
  ): [eventPassNftContractType!]!

  """
  fetch aggregated fields from the table: "eventPassNftContractType"
  """
  eventPassNftContractType_aggregate(
    """distinct select on columns"""
    distinct_on: [eventPassNftContractType_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [eventPassNftContractType_order_by!]

    """filter the rows returned"""
    where: eventPassNftContractType_bool_exp
  ): eventPassNftContractType_aggregate!

  """
  fetch data from the table: "eventPassNftContractType" using primary key columns
  """
  eventPassNftContractType_by_pk(
    """Type name for event pass NFT contract."""
    value: String!
  ): eventPassNftContractType

  """
  fetch data from the table in a streaming manner: "eventPassNftContractType"
  """
  eventPassNftContractType_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [eventPassNftContractType_stream_cursor_input]!

    """filter the rows returned"""
    where: eventPassNftContractType_bool_exp
  ): [eventPassNftContractType!]!

  """
  fetch aggregated fields from the table: "eventPassNftContract"
  """
  eventPassNftContract_aggregate(
    """distinct select on columns"""
    distinct_on: [eventPassNftContract_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [eventPassNftContract_order_by!]

    """filter the rows returned"""
    where: eventPassNftContract_bool_exp
  ): eventPassNftContract_aggregate!

  """
  fetch data from the table in a streaming manner: "eventPassNftContract"
  """
  eventPassNftContract_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [eventPassNftContract_stream_cursor_input]!

    """filter the rows returned"""
    where: eventPassNftContract_bool_exp
  ): [eventPassNftContract!]!

  """
  fetch aggregated fields from the table: "eventPassNft"
  """
  eventPassNft_aggregate(
    """distinct select on columns"""
    distinct_on: [eventPassNft_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [eventPassNft_order_by!]

    """filter the rows returned"""
    where: eventPassNft_bool_exp
  ): eventPassNft_aggregate!

  """fetch data from the table: "eventPassNft" using primary key columns"""
  eventPassNft_by_pk(id: uuid!): eventPassNft

  """
  fetch data from the table in a streaming manner: "eventPassNft"
  """
  eventPassNft_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [eventPassNft_stream_cursor_input]!

    """filter the rows returned"""
    where: eventPassNft_bool_exp
  ): [eventPassNft!]!

  """
  fetch data from the table: "eventPassOrder"
  """
  eventPassOrder(
    """distinct select on columns"""
    distinct_on: [eventPassOrder_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [eventPassOrder_order_by!]

    """filter the rows returned"""
    where: eventPassOrder_bool_exp
  ): [eventPassOrder!]!

  """
  fetch data from the table: "eventPassOrderSums"
  """
  eventPassOrderSums(
    """distinct select on columns"""
    distinct_on: [eventPassOrderSums_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [eventPassOrderSums_order_by!]

    """filter the rows returned"""
    where: eventPassOrderSums_bool_exp
  ): [eventPassOrderSums!]!

  """
  fetch aggregated fields from the table: "eventPassOrderSums"
  """
  eventPassOrderSums_aggregate(
    """distinct select on columns"""
    distinct_on: [eventPassOrderSums_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [eventPassOrderSums_order_by!]

    """filter the rows returned"""
    where: eventPassOrderSums_bool_exp
  ): eventPassOrderSums_aggregate!

  """
  fetch data from the table: "eventPassOrderSums" using primary key columns
  """
  eventPassOrderSums_by_pk(eventPassId: String!): eventPassOrderSums

  """
  fetch data from the table in a streaming manner: "eventPassOrderSums"
  """
  eventPassOrderSums_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [eventPassOrderSums_stream_cursor_input]!

    """filter the rows returned"""
    where: eventPassOrderSums_bool_exp
  ): [eventPassOrderSums!]!

  """
  fetch aggregated fields from the table: "eventPassOrder"
  """
  eventPassOrder_aggregate(
    """distinct select on columns"""
    distinct_on: [eventPassOrder_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [eventPassOrder_order_by!]

    """filter the rows returned"""
    where: eventPassOrder_bool_exp
  ): eventPassOrder_aggregate!

  """fetch data from the table: "eventPassOrder" using primary key columns"""
  eventPassOrder_by_pk(id: uuid!): eventPassOrder

  """
  fetch data from the table in a streaming manner: "eventPassOrder"
  """
  eventPassOrder_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [eventPassOrder_stream_cursor_input]!

    """filter the rows returned"""
    where: eventPassOrder_bool_exp
  ): [eventPassOrder!]!

  """
  fetch data from the table: "eventPassPendingOrder"
  """
  eventPassPendingOrder(
    """distinct select on columns"""
    distinct_on: [eventPassPendingOrder_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [eventPassPendingOrder_order_by!]

    """filter the rows returned"""
    where: eventPassPendingOrder_bool_exp
  ): [eventPassPendingOrder!]!

  """
  fetch aggregated fields from the table: "eventPassPendingOrder"
  """
  eventPassPendingOrder_aggregate(
    """distinct select on columns"""
    distinct_on: [eventPassPendingOrder_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [eventPassPendingOrder_order_by!]

    """filter the rows returned"""
    where: eventPassPendingOrder_bool_exp
  ): eventPassPendingOrder_aggregate!

  """
  fetch data from the table: "eventPassPendingOrder" using primary key columns
  """
  eventPassPendingOrder_by_pk(id: uuid!): eventPassPendingOrder

  """
  fetch data from the table in a streaming manner: "eventPassPendingOrder"
  """
  eventPassPendingOrder_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [eventPassPendingOrder_stream_cursor_input]!

    """filter the rows returned"""
    where: eventPassPendingOrder_bool_exp
  ): [eventPassPendingOrder!]!

  """
  fetch data from the table: "eventPassPricing"
  """
  eventPassPricing(
    """distinct select on columns"""
    distinct_on: [eventPassPricing_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [eventPassPricing_order_by!]

    """filter the rows returned"""
    where: eventPassPricing_bool_exp
  ): [eventPassPricing!]!

  """
  fetch aggregated fields from the table: "eventPassPricing"
  """
  eventPassPricing_aggregate(
    """distinct select on columns"""
    distinct_on: [eventPassPricing_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [eventPassPricing_order_by!]

    """filter the rows returned"""
    where: eventPassPricing_bool_exp
  ): eventPassPricing_aggregate!

  """
  fetch data from the table: "eventPassPricing" using primary key columns
  """
  eventPassPricing_by_pk(id: uuid!): eventPassPricing

  """
  fetch data from the table in a streaming manner: "eventPassPricing"
  """
  eventPassPricing_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [eventPassPricing_stream_cursor_input]!

    """filter the rows returned"""
    where: eventPassPricing_bool_exp
  ): [eventPassPricing!]!

  """
  fetch data from the table: "follow"
  """
  follow(
    """distinct select on columns"""
    distinct_on: [follow_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [follow_order_by!]

    """filter the rows returned"""
    where: follow_bool_exp
  ): [follow!]!

  """
  fetch aggregated fields from the table: "follow"
  """
  follow_aggregate(
    """distinct select on columns"""
    distinct_on: [follow_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [follow_order_by!]

    """filter the rows returned"""
    where: follow_bool_exp
  ): follow_aggregate!

  """fetch data from the table: "follow" using primary key columns"""
  follow_by_pk(
    """
    References the unique identifier of the account that is following an organizer.
    """
    accountId: uuid!

    """
    Represents the unique slug of the organizer being followed. Slugs are user-friendly identifiers that uniquely identify organizers.
    """
    organizerSlug: String!
  ): follow

  """
  fetch data from the table in a streaming manner: "follow"
  """
  follow_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [follow_stream_cursor_input]!

    """filter the rows returned"""
    where: follow_bool_exp
  ): [follow!]!

  """
  fetch data from the table: "kyc"
  """
  kyc(
    """distinct select on columns"""
    distinct_on: [kyc_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [kyc_order_by!]

    """filter the rows returned"""
    where: kyc_bool_exp
  ): [kyc!]!

  """
  fetch data from the table: "kycLevelName"
  """
  kycLevelName(
    """distinct select on columns"""
    distinct_on: [kycLevelName_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [kycLevelName_order_by!]

    """filter the rows returned"""
    where: kycLevelName_bool_exp
  ): [kycLevelName!]!

  """
  fetch aggregated fields from the table: "kycLevelName"
  """
  kycLevelName_aggregate(
    """distinct select on columns"""
    distinct_on: [kycLevelName_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [kycLevelName_order_by!]

    """filter the rows returned"""
    where: kycLevelName_bool_exp
  ): kycLevelName_aggregate!

  """fetch data from the table: "kycLevelName" using primary key columns"""
  kycLevelName_by_pk(
    """Level name for KYC verification."""
    value: String!
  ): kycLevelName

  """
  fetch data from the table in a streaming manner: "kycLevelName"
  """
  kycLevelName_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [kycLevelName_stream_cursor_input]!

    """filter the rows returned"""
    where: kycLevelName_bool_exp
  ): [kycLevelName!]!

  """
  fetch data from the table: "kycStatus"
  """
  kycStatus(
    """distinct select on columns"""
    distinct_on: [kycStatus_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [kycStatus_order_by!]

    """filter the rows returned"""
    where: kycStatus_bool_exp
  ): [kycStatus!]!

  """
  fetch aggregated fields from the table: "kycStatus"
  """
  kycStatus_aggregate(
    """distinct select on columns"""
    distinct_on: [kycStatus_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [kycStatus_order_by!]

    """filter the rows returned"""
    where: kycStatus_bool_exp
  ): kycStatus_aggregate!

  """fetch data from the table: "kycStatus" using primary key columns"""
  kycStatus_by_pk(
    """Status value."""
    value: String!
  ): kycStatus

  """
  fetch data from the table in a streaming manner: "kycStatus"
  """
  kycStatus_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [kycStatus_stream_cursor_input]!

    """filter the rows returned"""
    where: kycStatus_bool_exp
  ): [kycStatus!]!

  """
  fetch aggregated fields from the table: "kyc"
  """
  kyc_aggregate(
    """distinct select on columns"""
    distinct_on: [kyc_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [kyc_order_by!]

    """filter the rows returned"""
    where: kyc_bool_exp
  ): kyc_aggregate!

  """fetch data from the table: "kyc" using primary key columns"""
  kyc_by_pk(
    """UUID referencing to the user ID in the existing accounts table."""
    externalUserId: uuid!
  ): kyc

  """
  fetch data from the table in a streaming manner: "kyc"
  """
  kyc_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [kyc_stream_cursor_input]!

    """filter the rows returned"""
    where: kyc_bool_exp
  ): [kyc!]!

  """
  fetch data from the table: "nftTransfer"
  """
  nftTransfer(
    """distinct select on columns"""
    distinct_on: [nftTransfer_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [nftTransfer_order_by!]

    """filter the rows returned"""
    where: nftTransfer_bool_exp
  ): [nftTransfer!]!

  """
  fetch aggregated fields from the table: "nftTransfer"
  """
  nftTransfer_aggregate(
    """distinct select on columns"""
    distinct_on: [nftTransfer_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [nftTransfer_order_by!]

    """filter the rows returned"""
    where: nftTransfer_bool_exp
  ): nftTransfer_aggregate!

  """fetch data from the table: "nftTransfer" using primary key columns"""
  nftTransfer_by_pk(id: uuid!): nftTransfer

  """
  fetch data from the table in a streaming manner: "nftTransfer"
  """
  nftTransfer_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [nftTransfer_stream_cursor_input]!

    """filter the rows returned"""
    where: nftTransfer_bool_exp
  ): [nftTransfer!]!

  """
  fetch data from the table: "orderStatus"
  """
  orderStatus(
    """distinct select on columns"""
    distinct_on: [orderStatus_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [orderStatus_order_by!]

    """filter the rows returned"""
    where: orderStatus_bool_exp
  ): [orderStatus!]!

  """
  fetch aggregated fields from the table: "orderStatus"
  """
  orderStatus_aggregate(
    """distinct select on columns"""
    distinct_on: [orderStatus_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [orderStatus_order_by!]

    """filter the rows returned"""
    where: orderStatus_bool_exp
  ): orderStatus_aggregate!

  """fetch data from the table: "orderStatus" using primary key columns"""
  orderStatus_by_pk(value: String!): orderStatus

  """
  fetch data from the table in a streaming manner: "orderStatus"
  """
  orderStatus_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [orderStatus_stream_cursor_input]!

    """filter the rows returned"""
    where: orderStatus_bool_exp
  ): [orderStatus!]!

  """
  fetch data from the table: "packNftContract"
  """
  packNftContract(
    """distinct select on columns"""
    distinct_on: [packNftContract_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [packNftContract_order_by!]

    """filter the rows returned"""
    where: packNftContract_bool_exp
  ): [packNftContract!]!

  """
  fetch aggregated fields from the table: "packNftContract"
  """
  packNftContract_aggregate(
    """distinct select on columns"""
    distinct_on: [packNftContract_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [packNftContract_order_by!]

    """filter the rows returned"""
    where: packNftContract_bool_exp
  ): packNftContract_aggregate!

  """fetch data from the table: "packNftContract" using primary key columns"""
  packNftContract_by_pk(id: uuid!): packNftContract

  """
  fetch data from the table in a streaming manner: "packNftContract"
  """
  packNftContract_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [packNftContract_stream_cursor_input]!

    """filter the rows returned"""
    where: packNftContract_bool_exp
  ): [packNftContract!]!

  """
  fetch data from the table: "roleAssignments"
  """
  roleAssignments(
    """distinct select on columns"""
    distinct_on: [roleAssignments_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [roleAssignments_order_by!]

    """filter the rows returned"""
    where: roleAssignments_bool_exp
  ): [roleAssignments!]!

  """
  fetch aggregated fields from the table: "roleAssignments"
  """
  roleAssignments_aggregate(
    """distinct select on columns"""
    distinct_on: [roleAssignments_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [roleAssignments_order_by!]

    """filter the rows returned"""
    where: roleAssignments_bool_exp
  ): roleAssignments_aggregate!

  """
  fetch data from the table in a streaming manner: "roleAssignments"
  """
  roleAssignments_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [roleAssignments_stream_cursor_input]!

    """filter the rows returned"""
    where: roleAssignments_bool_exp
  ): [roleAssignments!]!

  """
  fetch data from the table: "roles"
  """
  roles(
    """distinct select on columns"""
    distinct_on: [roles_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [roles_order_by!]

    """filter the rows returned"""
    where: roles_bool_exp
  ): [roles!]!

  """
  fetch aggregated fields from the table: "roles"
  """
  roles_aggregate(
    """distinct select on columns"""
    distinct_on: [roles_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [roles_order_by!]

    """filter the rows returned"""
    where: roles_bool_exp
  ): roles_aggregate!

  """fetch data from the table: "roles" using primary key columns"""
  roles_by_pk(
    "\n    organizer_super_admin: Full Read & Write permissions on web2 and web3 components. Can assign roles and access system configurations.\n    organizer_admin: Full Read & Write permissions on web2 and web3 components.\n    organizer_operations_manager: Read & Write access to web2 components. Handles event setup, monitoring, analytics, etc.\n    organizer_finance_manager: Read & Write access to web3 components. Manages fund transfers, balance checks, and transaction approvals within limits.\n    organizer_content_manager: Read & Write access to web2 components. Manages content creation, editing, media uploads, and metadata modifications.\n    organizer_validator: Read & Write access on web2 and web3. Updates NFT traits and validates tickets and exclusive access during events.\n    organizer_auditor: Read-only access on web2 and web3. Conducts compliance checks and reviews transactions and operations.\n    organizer_guest: Limited access to web2. Can view public content without web3 permissions.\n    organizer_human_resources: Administrative permissions. Can invite new members for the organization and assign roles (except super admin and human resources).\n"
    value: String!
  ): roles

  """
  fetch data from the table in a streaming manner: "roles"
  """
  roles_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [roles_stream_cursor_input]!

    """filter the rows returned"""
    where: roles_bool_exp
  ): [roles!]!

  """
  fetch data from the table: "stripeCheckoutSession"
  """
  stripeCheckoutSession(
    """distinct select on columns"""
    distinct_on: [stripeCheckoutSession_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [stripeCheckoutSession_order_by!]

    """filter the rows returned"""
    where: stripeCheckoutSession_bool_exp
  ): [stripeCheckoutSession!]!

  """
  fetch data from the table: "stripeCheckoutSessionType"
  """
  stripeCheckoutSessionType(
    """distinct select on columns"""
    distinct_on: [stripeCheckoutSessionType_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [stripeCheckoutSessionType_order_by!]

    """filter the rows returned"""
    where: stripeCheckoutSessionType_bool_exp
  ): [stripeCheckoutSessionType!]!

  """
  fetch aggregated fields from the table: "stripeCheckoutSessionType"
  """
  stripeCheckoutSessionType_aggregate(
    """distinct select on columns"""
    distinct_on: [stripeCheckoutSessionType_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [stripeCheckoutSessionType_order_by!]

    """filter the rows returned"""
    where: stripeCheckoutSessionType_bool_exp
  ): stripeCheckoutSessionType_aggregate!

  """
  fetch data from the table: "stripeCheckoutSessionType" using primary key columns
  """
  stripeCheckoutSessionType_by_pk(
    """Type value."""
    value: String!
  ): stripeCheckoutSessionType

  """
  fetch data from the table in a streaming manner: "stripeCheckoutSessionType"
  """
  stripeCheckoutSessionType_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [stripeCheckoutSessionType_stream_cursor_input]!

    """filter the rows returned"""
    where: stripeCheckoutSessionType_bool_exp
  ): [stripeCheckoutSessionType!]!

  """
  fetch aggregated fields from the table: "stripeCheckoutSession"
  """
  stripeCheckoutSession_aggregate(
    """distinct select on columns"""
    distinct_on: [stripeCheckoutSession_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [stripeCheckoutSession_order_by!]

    """filter the rows returned"""
    where: stripeCheckoutSession_bool_exp
  ): stripeCheckoutSession_aggregate!

  """
  fetch data from the table: "stripeCheckoutSession" using primary key columns
  """
  stripeCheckoutSession_by_pk(
    """Unique identifier for the Stripe Checkout Session."""
    stripeSessionId: String!
  ): stripeCheckoutSession

  """
  fetch data from the table in a streaming manner: "stripeCheckoutSession"
  """
  stripeCheckoutSession_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [stripeCheckoutSession_stream_cursor_input]!

    """filter the rows returned"""
    where: stripeCheckoutSession_bool_exp
  ): [stripeCheckoutSession!]!

  """
  fetch data from the table: "stripeCustomer"
  """
  stripeCustomer(
    """distinct select on columns"""
    distinct_on: [stripeCustomer_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [stripeCustomer_order_by!]

    """filter the rows returned"""
    where: stripeCustomer_bool_exp
  ): [stripeCustomer!]!

  """
  fetch aggregated fields from the table: "stripeCustomer"
  """
  stripeCustomer_aggregate(
    """distinct select on columns"""
    distinct_on: [stripeCustomer_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [stripeCustomer_order_by!]

    """filter the rows returned"""
    where: stripeCustomer_bool_exp
  ): stripeCustomer_aggregate!

  """fetch data from the table: "stripeCustomer" using primary key columns"""
  stripeCustomer_by_pk(
    """Unique identifier for the Stripe Customer."""
    stripeCustomerId: String!
  ): stripeCustomer

  """
  fetch data from the table in a streaming manner: "stripeCustomer"
  """
  stripeCustomer_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [stripeCustomer_stream_cursor_input]!

    """filter the rows returned"""
    where: stripeCustomer_bool_exp
  ): [stripeCustomer!]!

  """
  fetch data from the table: "timezone"
  """
  timezone(
    """distinct select on columns"""
    distinct_on: [timezone_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [timezone_order_by!]

    """filter the rows returned"""
    where: timezone_bool_exp
  ): [timezone!]!

  """
  fetch aggregated fields from the table: "timezone"
  """
  timezone_aggregate(
    """distinct select on columns"""
    distinct_on: [timezone_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [timezone_order_by!]

    """filter the rows returned"""
    where: timezone_bool_exp
  ): timezone_aggregate!

  """fetch data from the table: "timezone" using primary key columns"""
  timezone_by_pk(value: String!): timezone

  """
  fetch data from the table in a streaming manner: "timezone"
  """
  timezone_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [timezone_stream_cursor_input]!

    """filter the rows returned"""
    where: timezone_bool_exp
  ): [timezone!]!
}

scalar timestamp

"""
Boolean expression to compare columns of type "timestamp". All fields are combined with logical 'AND'.
"""
input timestamp_comparison_exp {
  _eq: timestamp
  _gt: timestamp
  _gte: timestamp
  _in: [timestamp!]
  _is_null: Boolean
  _lt: timestamp
  _lte: timestamp
  _neq: timestamp
  _nin: [timestamp!]
}

scalar timestamptz

"""
Boolean expression to compare columns of type "timestamptz". All fields are combined with logical 'AND'.
"""
input timestamptz_comparison_exp {
  _eq: timestamptz
  _gt: timestamptz
  _gte: timestamptz
  _in: [timestamptz!]
  _is_null: Boolean
  _lt: timestamptz
  _lte: timestamptz
  _neq: timestamptz
  _nin: [timestamptz!]
}

"""IANA Time Zones fetched from pg_timezone_names in PostgreSQL"""
type timezone {
  value: String!
}

"""
aggregated selection of "timezone"
"""
type timezone_aggregate {
  aggregate: timezone_aggregate_fields
  nodes: [timezone!]!
}

"""
aggregate fields of "timezone"
"""
type timezone_aggregate_fields {
  count(columns: [timezone_select_column!], distinct: Boolean): Int!
  max: timezone_max_fields
  min: timezone_min_fields
}

"""
Boolean expression to filter rows from the table "timezone". All fields are combined with a logical 'AND'.
"""
input timezone_bool_exp {
  _and: [timezone_bool_exp!]
  _not: timezone_bool_exp
  _or: [timezone_bool_exp!]
  value: String_comparison_exp
}

"""
unique or primary key constraints on table "timezone"
"""
enum timezone_constraint {
  """
  unique or primary key constraint on columns "value"
  """
  timezone_pkey
}

"""
input type for inserting data into table "timezone"
"""
input timezone_insert_input {
  value: String
}

"""aggregate max on columns"""
type timezone_max_fields {
  value: String
}

"""aggregate min on columns"""
type timezone_min_fields {
  value: String
}

"""
response of any mutation on the table "timezone"
"""
type timezone_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [timezone!]!
}

"""
on_conflict condition type for table "timezone"
"""
input timezone_on_conflict {
  constraint: timezone_constraint!
  update_columns: [timezone_update_column!]! = []
  where: timezone_bool_exp
}

"""Ordering options when selecting data from "timezone"."""
input timezone_order_by {
  value: order_by
}

"""primary key columns input for table: timezone"""
input timezone_pk_columns_input {
  value: String!
}

"""
select columns of table "timezone"
"""
enum timezone_select_column {
  """column name"""
  value
}

"""
input type for updating data in table "timezone"
"""
input timezone_set_input {
  value: String
}

"""
Streaming cursor of the table "timezone"
"""
input timezone_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: timezone_stream_cursor_value_input!

  """cursor ordering"""
  ordering: cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input timezone_stream_cursor_value_input {
  value: String
}

"""
update columns of table "timezone"
"""
enum timezone_update_column {
  """column name"""
  value
}

input timezone_updates {
  """sets the columns of the filtered rows to the given values"""
  _set: timezone_set_input

  """filter the rows which have to be updated"""
  where: timezone_bool_exp!
}

scalar uuid

"""
Boolean expression to compare columns of type "uuid". All fields are combined with logical 'AND'.
"""
input uuid_comparison_exp {
  _eq: uuid
  _gt: uuid
  _gte: uuid
  _in: [uuid!]
  _is_null: Boolean
  _lt: uuid
  _lte: uuid
  _neq: uuid
  _nin: [uuid!]
}